{"meta":{"title":"Niraj Sonawane","subtitle":null,"description":null,"author":"Niraj Sonawane","url":"https://nirajsonawane.github.io"},"pages":[{"title":"About Me","date":"2018-05-19T11:17:06.000Z","updated":"2022-04-24T18:43:29.748Z","comments":true,"path":"about/index.html","permalink":"https://nirajsonawane.github.io/about/index.html","excerpt":"","text":"I am Software Developer from India. My Passion is to Write Clean,Elegant and Scalable Code. I love to follow latest trends and Best Practices in software engineering. This blog is my attempt to share my learning. DisclaimerThis is a personal blog. The opinions expressed here represent my own and not the organizations with whom i am associated with. My opinions might change from time to time :)"},{"title":"About Me","date":"2018-05-19T11:17:06.000Z","updated":"2018-05-19T21:17:08.000Z","comments":true,"path":"About-Me/index.html","permalink":"https://nirajsonawane.github.io/About-Me/index.html","excerpt":"","text":""},{"title":"Tags","date":"2021-02-07T16:23:28.616Z","updated":"2018-06-10T02:45:44.000Z","comments":true,"path":"tags/index.html","permalink":"https://nirajsonawane.github.io/tags/index.html","excerpt":"","text":""},{"title":"Categories","date":"2021-02-07T16:23:28.610Z","updated":"2018-06-10T02:45:44.000Z","comments":true,"path":"categories/index.html","permalink":"https://nirajsonawane.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"From Monolith to Microservices: A Gradual Approach with Modular Monolithic Architecture","slug":"From-Monolith-to-Microservices-A-Gradual-Approach-with-Modular-Monolithic-Architecture","date":"2023-04-16T11:25:47.000Z","updated":"2023-04-16T12:49:48.049Z","comments":true,"path":"2023/04/16/From-Monolith-to-Microservices-A-Gradual-Approach-with-Modular-Monolithic-Architecture/","link":"","permalink":"https://nirajsonawane.github.io/2023/04/16/From-Monolith-to-Microservices-A-Gradual-Approach-with-Modular-Monolithic-Architecture/","excerpt":"","text":"As software developers, we are always looking for better ways to build applications that are stable, maintainable, and scalable. In this blog post, I will share my experience with using the Modular Monolithic architecture. What is Modular Monolithic?Modular Monolithic architecture is an architectural pattern where the application is divided into separate modules that work together as a single, cohesive unit. In this pattern, each module is responsible for a specific set of features and has well-defined interfaces for communicating with other modules. Modules should be created based on business domains to ensure that each module has a clear and specific responsibility. When to Use Modular Monolithic ArchitectureModular Monolithic can be a good choice for quickly getting a project off the ground and adapting to changing business requirements. By starting with a modular monolithic architecture, it is possible to gradually move towards a microservices architecture without the need for a complete rewrite of the codebase. When building a new system, it is important to focus on understanding the business domain first. You need to identify the business capabilities, processes, and data that the system needs to support. Once you have a clear understanding of the business domain, you can then start thinking about how to partition the system into individual services. If you are not sure about the domain boundaries, you may want to start with a monolithic architecture and gradually move towards a microservices architecture as you gain more knowledge and experience. A monolithic architecture allows you to build the system as a single, cohesive unit, and it can be easier to refactor and break down into microservices later on. This approach can help you to identify the domain boundaries and dependencies between modules, which can then be used to guide the partitioning of the system into microservices. Interactions between ModulesIt is essential to decide on a consistent pattern for how modules should interact with each other. Otherwise, the lack of standardization may lead to code that is difficult to maintain. In general, there are several common patterns for module interaction: Function calls:One module calls functions or methods in another module to request some operation or data. However, this can lead to tight coupling, where one module relies heavily on another module’s functions or methods, leading to cascading effects on the calling module. Depending on the number of function calls, the performance of the system may be affected due to the overhead of the function calls. Events:One module publishes events to a message bus or event stream, and other modules subscribe to these events to react to them. However, when modules rely on events, there may be a lag between the time an event is generated and the time that other modules receive and process the event, leading to eventual consistency issues. HTTP APIs:Modules expose HTTP APIs that other modules can use to request data or trigger operations. However, since HTTP APIs rely on network calls, the latency of the system may be affected, leading to performance issues. As the system evolves, the APIs may need to change, leading to versioning challenges and backward compatibility issues. Databases in the Context of Modular MonolithicIt is essential to avoid allowing data owned by one module to be directly accessed by other modules. If this is not done correctly, we might end up creating a monolithic architecture.In general, we have two patterns for managing persistence state in Modular Monolithic architecture: Database per module:Each module has its database schema and interacts with it directly. This approach provides isolation between modules and can simplify data management. Database per bounded context:Each module has its database schema, but the schemas are organized by bounded contexts, which represent different areas of the system’s business domain. This pattern is common When to extract a module as a separate service:While modular monolithic architecture provides a flexible and adaptable approach to building applications, there may come a time when one or more modules outgrow the monolithic architecture and need to be extracted as separate services. One common reason for this is when a module becomes too large and requires more resources to scale than can be efficiently handled within the monolithic architecture. To determine if a module should be extracted as a separate service, consider the following: Is the module experiencing performance issues due to its size or resource requirements? Are there other modules in the system that depend heavily on the module in question? Are there clear boundaries around the module’s functionality and business domain that make it suitable for extraction as a separate service? Are there benefits to extracting the module as a separate service, such as improved scalability, fault tolerance, or the ability to independently deploy and maintain the module?","categories":[],"tags":[{"name":"monolithic","slug":"monolithic","permalink":"https://nirajsonawane.github.io/tags/monolithic/"},{"name":"microservice","slug":"microservice","permalink":"https://nirajsonawane.github.io/tags/microservice/"},{"name":"architecture","slug":"architecture","permalink":"https://nirajsonawane.github.io/tags/architecture/"},{"name":"modular monolithic","slug":"modular-monolithic","permalink":"https://nirajsonawane.github.io/tags/modular-monolithic/"}]},{"title":"Launching Spring Boot Apps on AWS ECS Fargate","slug":"Launching-Spring-Boot-Apps-on-AWS-ECS-Fargate","date":"2023-04-09T19:06:22.000Z","updated":"2023-04-09T20:32:51.658Z","comments":true,"path":"2023/04/09/Launching-Spring-Boot-Apps-on-AWS-ECS-Fargate/","link":"","permalink":"https://nirajsonawane.github.io/2023/04/09/Launching-Spring-Boot-Apps-on-AWS-ECS-Fargate/","excerpt":"","text":"Deploying Spring Boot applications can be challenging, especially when it comes to managing containers in a production environment. However, by using AWS ECS Fargate, you can easily deploy and manage your Spring Boot applications in a scalable and reliable way. In this blog post, we’ll explore the benefits of using AWS ECS Fargate for Spring Boot application deployment, and walk through the steps to prepare your application for deployment on ECS Fargate. We’ll cover creating a Docker image, setting up an ECS Fargate cluster and task definition Let’s get started! Quick Overview about ECSAWS ECS (Elastic Container Service) is a fully managed container orchestration service that makes it easy to run, manage, and scale Docker containers on AWS. ECS provides several key concepts for managing containerized applications: Cluster: An ECS cluster is a logical grouping of container instances that run your tasks. Each cluster can contain multiple container instances, and each instance can run multiple tasks. Task: An ECS task is a running instance of a Docker container that has been launched from a task definition. A task definition is a blueprint for how to run a Docker container, including the Docker image to use, the CPU and memory requirements, the network settings, and more. Service: An ECS service is a long-running task that runs continuously in the background, ensuring that your application is always available. A service is defined by a task definition, and it can be scaled up or down based on demand. ECS can automatically manage the load balancing and auto scaling of services. Batch: An ECS batch job is a task that is launched for a finite amount of time to perform a specific job, like running a batch script or processing a batch of data. Batch jobs are defined by a job definition, which specifies the Docker image to use, the CPU and memory requirements, and other parameters. Batch jobs can be run on demand or scheduled to run at specific times. By using ECS, you can easily deploy and manage containerized applications, while taking advantage of AWS features like load balancing, auto scaling, and monitoring. ECS vs ECS FargateWith ECS, you manage your own EC2 instances that run your containerized applications. AWS ECS Fargate is a serverless container orchestration service that allows you to run containers without having to manage the underlying EC2 instances. With Fargate, AWS takes care of the infrastructure for you, allowing you to focus on running and scaling your containers. Fargate provides the same key concepts as ECS, including clusters, tasks, services, and batch jobs. The main difference between ECS and ECS Fargate is that with ECS, you manage the EC2 instances that run your containers, whereas with Fargate, AWS manages the instances for you. This makes Fargate a more hands-off approach to container management, and can be beneficial if you don’t want to deal with the operational overhead of managing EC2 instances let’s Create Simple Spring Boot Application that we will deploy on ECS The code for this post is available on Github here 1 Create Simple Spring Boot APPCreate Rest API that will return simple String.12345678@RestControllerpublic class HelloController &#123; @GetMapping(\"/hello\") public String hello() &#123; return \"Hello Message from ECS Service\"; &#125;&#125; 2 Create Docker ImageAdd Simple Docker file.123FROM openjdk:11COPY target/spring-boot-ecs-Fargate-0.0.1-SNAPSHOT.jar spring-boot-ecs-Fargate-0.0.1-SNAPSHOT.jarENTRYPOINT [\"java\", \"-jar\", \"/spring-boot-ecs-Fargate-0.0.1-SNAPSHOT.jar\"] Run Below command from root of your project. This will create the docker image with name ‘spring-boot-ecs’docker build -t spring-boot-ecs .Run Below command to verify docker image is working. You should be able to access API on http://localhost:8080/hellodocker run -p 8080:8080 spring-boot-ecs 3 Create ECR repo for uploading ImageAWS ECR (Elastic Container Registry) is a fully-managed Docker container registry that makes it easy to store, manage, and deploy Docker container images. ECR is tightly integrated with ECS, making it easy to store and manage your Docker images for use in ECS tasks. Here are some key concepts to understand about ECR: Repository: An ECR repository is a collection of Docker images with the same name and tag. Each repository has a unique URL that you can use to access the images. Image: An ECR image is a Docker image that has been uploaded to an ECR repository. Images can have multiple tags, allowing you to have different versions of the same image. Registry: An ECR registry is a collection of ECR repositories that you own. Each AWS account can have one ECR registry. To use ECR with ECS, you first need to create an ECR repository to store your Docker images. You can then build your Docker image locally, tag it with the ECR repository URL and push it to ECR using the docker push command. Once your Docker image is in ECR, you can reference it in your ECS task definitions and services. ECR provides a secure and scalable way to manage your Docker images, and it integrates seamlessly with ECS to provide a complete container management solution. Create an ECR Repo by following step by step guide Upload ImageCreate Separate IAM User which will have access to upload image to ECR Repo. You can use AWS CLI for uploading images.docker push &lt;your-aws-account.your-aws-repo/spring-boot-ecs:latest 4 Setting up AWS ECS Fargate cluster and task definition Here are the steps to follow:Create an ECS cluster, which is a logical grouping of container instances. Define a task definition for your application, which specifies the Docker image to use, along with any required configuration. Configure the network settings and security groups for your task definition. Deploying your Spring Boot application on AWS ECS Fargate With your ECS cluster and task definition in place, you can now deploy your Spring Boot application on AWS ECS Fargate. Here are the steps to follow: Create an ECS service for your task definition, which specifies the number of tasks to run, along with the desired load balancing and auto scaling settings. Once’s the service is successfully deployed, You can access the API by using Public IP Address of running task","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"AWS","slug":"AWS","permalink":"https://nirajsonawane.github.io/tags/AWS/"},{"name":"ECS","slug":"ECS","permalink":"https://nirajsonawane.github.io/tags/ECS/"},{"name":"ECR","slug":"ECR","permalink":"https://nirajsonawane.github.io/tags/ECR/"},{"name":"FARGATE","slug":"FARGATE","permalink":"https://nirajsonawane.github.io/tags/FARGATE/"}]},{"title":"Spring Boot & AWS RDS Part 3- Secrets-Manager","slug":"Spring-Boot-AWS-RDS-Part-3-Secrets-Manager","date":"2022-04-27T19:40:50.000Z","updated":"2023-04-09T19:07:46.307Z","comments":true,"path":"2022/04/27/Spring-Boot-AWS-RDS-Part-3-Secrets-Manager/","link":"","permalink":"https://nirajsonawane.github.io/2022/04/27/Spring-Boot-AWS-RDS-Part-3-Secrets-Manager/","excerpt":"","text":"The Previous article was about using AWS RDS with Spring Boot &amp; RDS read replicas with Spring Boot. This post is continuation of same topic. In this post i will show you how to access RDS credentials from AWS Secrets Manager. Managing the application secrets like database credentials, API keys is always a very critical aspect of application security. Now days almost all the enterprise applications have strict constraints on not allowing storing any secrets in plain text. Secrets are also needed to be rotated in certain time intervals. AWS Secrets Manager helps us to easily manage and rotate credentials from a central place. Secrets Manager enables us to easily rotate, manage, and retrieve database credentials, API keys, and other secrets throughout their lifecycle. Users and applications retrieve secrets with a call to Secrets Manager APIs, eliminating the need to hard code sensitive information in plain text. Secrets Manager has the built-in integration with AWS Services like RDS, Redshift and DocumentDB. The code for this post is available on Github here Creating Secrets for RDS InstanceOn AWS Console go to AWS Secrets Manager-&gt;Secrets-&gt;Store a new secret and then select Credentials for Amazon RDS database. And create secret as shown. Retrieving secrets from secrets-managerNow let’s update our Spring Boot app to retrieve the secrets from secrets-manager. Fortunately Spring &amp; AWS team has created very nice and easy to use aws-secretsmanager-jdbc library for this. 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-aws-jdbc&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; Updating Data source configurationsNow we have to update data source configurations in application.properties so that the application can pick up the database credentials. configuration without secret manager123spring.datasource.url=jdbc:postgresql://&lt;database-endpoint-url&gt;:&lt;port&gt;/&lt;database&gt; spring.datasource.username=admin1spring.datasource.password=Admin123 configuration with secret manager123spring.datasource.url=jdbc-secretsmanager:postgresql://&lt;database-endpoint-url&gt;:&lt;port&gt;/&lt;database&gt; spring.datasource.username=dev/test-rds-secret-1spring.datasource.driver-class-name=com.amazonaws.secretsmanager.sql.AWSSecretsManagerPostgreSQLDriver Observe thatJDBC URL prefix changed to jdbc-secretmanager.secret name is used username.The driver class is from spring-cloud-aws-jdbc. Other driver classes123com.amazonaws.secretsmanager.sql.AWSSecretsManagerMySQLDrivercom.amazonaws.secretsmanager.sql.AWSSecretsManagerOracleDrivercom.amazonaws.secretsmanager.sql.AWSSecretsManagerMSSQLServerDriver Now if you Run the application, Application should connect to database. NoteFor running the application locally, AWS Profile should have been configured correctly &amp; user should access to read secrets from secretsmanager. config credentials123[default]aws_access_key_id = XXXXXaws_secret_access_key = XXXXX How the magic happens?Magic fo connecting to the database is done by the the JDBC driver class provided by the aws-secretsmanager-jdbc. When the application request the connection the wrapper class AWSSecretsManagerPostgreSQLDriver makes and API call to Secrets Manager to retrieve the credentials. Whats happens when secrets are Rotated?The aws-secretsmanager-jdbc library does not calls AWS Secrets Manager API every time when connection is requested.As accessing Secrets Manager API is expensive hence it uses cache. The cache policy is Least Recently Used (LRU), so when the cache must discard a secret, it discards the least recently used secret. By default, the cache refreshes secrets every hour. When the cached has not expired but the Secrets in AWS Secrets Manager is rotated or changed,Driver uses fallback mechanism. If the database returns an error for the wrong username/password, Driver class makes an fresh API to AWS Secrets Manager to get the new credentials. The code for this post is available on Github here","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"AWS","slug":"AWS","permalink":"https://nirajsonawane.github.io/tags/AWS/"},{"name":"RDS","slug":"RDS","permalink":"https://nirajsonawane.github.io/tags/RDS/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://nirajsonawane.github.io/tags/PostgreSQL/"},{"name":"ReadReplica","slug":"ReadReplica","permalink":"https://nirajsonawane.github.io/tags/ReadReplica/"},{"name":"SecretsManager","slug":"SecretsManager","permalink":"https://nirajsonawane.github.io/tags/SecretsManager/"}]},{"title":"Spring Boot & AWS RDS Part 2 - Read Replicas","slug":"Spring-Boot-AWS-RDS-Read-Replica-Part-2","date":"2022-04-24T10:14:14.000Z","updated":"2022-04-28T20:10:18.793Z","comments":true,"path":"2022/04/24/Spring-Boot-AWS-RDS-Read-Replica-Part-2/","link":"","permalink":"https://nirajsonawane.github.io/2022/04/24/Spring-Boot-AWS-RDS-Read-Replica-Part-2/","excerpt":"","text":"In Previous post we discuss, How to use spring boot to access AWS RDS service. This post is continuation of same topic and we will explore, How we can configure &amp; use ReadReplicas. What is Database Read Replicas?In General read replica is a copy of the primary database instance and it automatically reflects changes made in primary database in almost real time. Read Replicas can improve the performance of read-heavy database workloads by offloading read workload from primary instance. How AWS RDS read replica works?Amazon RDS uses the MariaDB, Microsoft SQL Server, MySQL, Oracle, and PostgreSQL DB engines’ built-in replication functionality to create a read replica. Any Updates made to the primary DB instance are asynchronously copied to the read replica. AWS allows to create read replicas in same availability zone or in different availability zone. It Also allows to create read replicas in different regions. Creating up to 5 read replicas are allowed. Why to use read replica? Read replicas can significantly improve the performance by redirecting read traffic to one or more read replicas. Read replicas are Ideal for implementing Business reporting or data warehousing work loads, Without impacting normal business flows. In some cases read replica can be used for implementing disaster recovery. Read replicas can be promoted as primary database instance. How to create read replicas in AWS Console?While creating a read replicas we need to specify an existing DB instance as the source. Then Amazon RDS takes a snapshot of the source instance and creates a read-only instance from the snapshot. The read replica operates as a DB instance that allows only read-only connections.Applications connect to a read replica the same way they do to any DB instance. On AWS Console choose the DB instance that you want to use as the source for a read replica.Then Go to action, choose Create read replica. Then Follow the same steps explained In Previous post All the data from the main table will also be available in replicated instance. We can verify the data by connecting to replicated instance using PGAdmin or any other similar tool. How to use read replicas with Spring Boot AppIn Previous post we used spring-boot-starter-data-jpa, To use the full power for read replicas , In this example we will use Spring Cloud AWS JDBC as it provides some useful features. Spring cloud aws automatically detects the read-replica instance and If the read replica support is enabled, It will automatically send the requests to e replica instance. As an application developer we do not have to configure multiple data sources. Spring cloud aws does the Automatic retry incase of database failure. It attempts to send the same request to different availability zone. As an application developer, We do not need to worry about how many read replicas are configured. Setting up Spring Boot AppLet’s create simple small Spring Boot app that will interact with primary database and read replicas.Apart form other needed dependency, We need to add spring-cloud-aws-jdbc as dependency 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-aws-jdbc&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; The code for this post is available on Github here Configuring data sourceThe data sources can be configured using the Spring Boot configuration files. Because of the dynamic number of data sources inside one application, the Spring Boot properties must be configured for each data source. data source configuration properties123cloud.aws.rds.&lt;DB-Instance-ID&gt;.username=admin1cloud.aws.rds.&lt;DB-Instance-ID&gt;.password=Admin123cloud.aws.rds.&lt;DB-Instance-ID&gt;.databaseName=employee How to enable read-replicaenable read replica1cloud.aws.rds.employee-db.readReplicaSupport=true How To redirect read traffic to read replica instanceFor redirecting traffic to replicated instance we just need to use Transactions and set Transactional property as readOnly = true12345678910111213141516@Service@RequiredArgsConstructorpublic class EmployeeService &#123; private final EmployeeRepository repository; @Transactional public void saveEmployeeToDatabase(Employee employee)&#123; repository.save(employee); &#125; @Transactional(readOnly = true) public List&lt;Employee&gt; findAll()&#123; return repository.findAll(); &#125;&#125; Write work load and replicationAll Write transactions will be redirected to the primary DB Instance and AWS will handle the replication asynchronously without impacting the performance of primary DB Instance. Points to keep in mind before using read replicasRead-replica feature of RDS can increase throughput and performance but replication is not exactly realtime. There will be some lag in coping with data from primary instance to replicated instance and Read replica might return outdated data in some scenarios. The code for this post is available on Github here","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"AWS","slug":"AWS","permalink":"https://nirajsonawane.github.io/tags/AWS/"},{"name":"RDS","slug":"RDS","permalink":"https://nirajsonawane.github.io/tags/RDS/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://nirajsonawane.github.io/tags/PostgreSQL/"},{"name":"ReadReplica","slug":"ReadReplica","permalink":"https://nirajsonawane.github.io/tags/ReadReplica/"}]},{"title":"Spring Boot & AWS RDS - Part 1","slug":"Spring-Boot-AWS-RDS","date":"2022-04-18T09:56:34.000Z","updated":"2022-04-24T18:05:59.753Z","comments":true,"path":"2022/04/18/Spring-Boot-AWS-RDS/","link":"","permalink":"https://nirajsonawane.github.io/2022/04/18/Spring-Boot-AWS-RDS/","excerpt":"","text":"What is AWS RDS?AWS RDS is a collection of managed services that makes it simple to set up, operate, and scale databases in the cloud. AWS RDS provides multiple DB Engines options like MySQL, PostgreSQL,MariaDB, Oracle SQL Server. As Amazon RDS handles routine database tasks such as provisioning, patching, backup, recovery, failure detection, and repair. This brings a lot of convenience to RDS users and provides. RDS also provides other features like replication, enhance availability and reliability. In this article we will examine how to use Spring boot to access AWS RDS PostgreSQL. Amazon RDS for PostgreSQL provides access to the capabilities of the familiar PostgreSQL database engine. Creating PostgreSQL DB Instance on AWSGo to RDS-&gt;Databases-&gt;Create Database for creating new database instance. Select PostgreSQL as engine type.For this demo i am using below setting. (These configurations are not recommended for production usage) Free tier, DB instance identifier : employee-db Credential: Master username VPC : Default Public Access:True Security Group:Default Initial database name:employee NoteOnly specifying Public Access:True for your Databases might not work. The Security group should allow Inbound traffic from your IP address or All IP address. Onces the database is ready, Note the Endpoint url which we will use as spring.datasource.url Setting up Spring Boot ProjectLet’s create simple small Spring Boot app that will interact with RDS. We do not need any AWS specific dependancy, Only JPA,spring-web &amp; postgresql dependancy are needed.12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.postgresql&lt;/groupId&gt; &lt;artifactId&gt;postgresql&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; Data source configurations123456spring.datasource.url=jdbc:postgresql://&lt;database-endpoint-url&gt;:&lt;port&gt;/&lt;database&gt; spring.datasource.username=admin1spring.datasource.password=Admin123spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialectspring.jpa.hibernate.ddl-auto=updatespring.jpa.hibernate.show-sql=true Onces the database connection is done, We can simply use the JAP Repository to interact with database. Controller12345678910111213141516171819@RestController@Slf4j@RequestMapping(\"/employee\")@RequiredArgsConstructorpublic class EmployeeController &#123; private final EmployeeRepository repository; @PostMapping public ResponseEntity createEmployee(@RequestBody CreateEmployeeRequest request) &#123; repository.save(new Employee(request.getId(), request.getFirstName(), request.getLastName())); return ResponseEntity .status(HttpStatus.CREATED) .build(); &#125; @GetMapping public List&lt;Employee&gt; getAllEmployee() &#123; return repository.findAll(); &#125;&#125; Entity And Repository1234567891011121314@Entity@AllArgsConstructor@NoArgsConstructor@Datapublic class Employee &#123; @Id private UUID id; private String firstName; private String lastName;&#125;public interface EmployeeRepository extends JpaRepository&lt;Employee, UUID&gt; &#123;&#125; The code for this post is available on Github here","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"AWS","slug":"AWS","permalink":"https://nirajsonawane.github.io/tags/AWS/"},{"name":"RDS","slug":"RDS","permalink":"https://nirajsonawane.github.io/tags/RDS/"},{"name":"PostgreSQL","slug":"PostgreSQL","permalink":"https://nirajsonawane.github.io/tags/PostgreSQL/"}]},{"title":"Spring Boot With AWS S3","slug":"Spring-Boot-with-AWS-S3","date":"2021-05-16T20:17:01.000Z","updated":"2021-05-16T21:33:39.049Z","comments":true,"path":"2021/05/16/Spring-Boot-with-AWS-S3/","link":"","permalink":"https://nirajsonawane.github.io/2021/05/16/Spring-Boot-with-AWS-S3/","excerpt":"","text":"In previous post we discuss, How to use spring boot to access AWS SQS service. In this article we will examine how to use Spring boot to access AWS S3. Spring Cloud provides convenient way to interact with AWS S3 service. With the help of spring cloud S3 support we can use all well-known Spring Boot features. It also offers multiple useful features compare to SDK provided by AWS. The code for this post is available on Github here Using Spring cloudTo use S3 support we just need to add below dependancy1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-aws&lt;/artifactId&gt;&lt;/dependency&gt; Providing AWS credential and SDK configurationsIn order to make calls to the AWS Services the credentials must be configured for the the Amazon SDK. In order to access S3 service we can configure access key and secret key using yaml or properties files12345678910document: bucket-name: spring-boot-s3-poccloud: aws: region: static: us-east-1 auto: false credentials: access-key: XXX secret-key: XXXXX Creating AmazonS3 Client beanAmazonS3 Client bean can be use to perform different operation on AWS S3 service.AmazonS3 Client Configuration1234567891011121314151617181920212223@Configurationpublic class Config &#123; @Value(\"$&#123;cloud.aws.credentials.access-key&#125;\") private String awsAccessKey; @Value(\"$&#123;cloud.aws.credentials.secret-key&#125;\") private String awsSecretKey; @Value(\"$&#123;cloud.aws.region.static&#125;\") private String region; @Primary @Bean public AmazonS3 amazonS3Client() &#123; return AmazonS3ClientBuilder .standard() .withRegion(region) .withCredentials(new AWSStaticCredentialsProvider( new BasicAWSCredentials(awsAccessKey, awsSecretKey))) .build(); &#125;&#125; Find all objects in bucketlistObjectsV2 method can be use to get all object keys from the bucket123456@GetMapping public List&lt;String&gt; getAllDocuments() &#123; return amazonS3.listObjectsV2(bucketName).getObjectSummaries().stream() .map(S3ObjectSummary::getKey) .collect(Collectors.toList()); &#125; Upload object to S3 bucketWe can use putObject method on our AmazonS3 client bean to upload object in S3 bucket. It provides multiple overloaded methods to upload object as File, String, InputStream etc.lets take example of uploading MultipartFile to S3 bucket. Uploading MultipartFile to S3 bucket12345678910@PostMapping public ResponseEntity uploadDocument(@RequestParam(value = \"file\") MultipartFile file) throws IOException &#123; String tempFileName = UUID.randomUUID() + file.getName(); File tempFile = new File(System.getProperty(\"java.io.tmpdir\") + \"/\" + tempFileName); file.transferTo(tempFile); // Convert multipart file to File String key UID.randomUUID() + file.getName() // unique key for the file amazonS3.putObject(bucketName, key, tempFile); // Upload file tempFile.deleteOnExit(); //delete temp file return ResponseEntity.created(URI.create(tempFileName)).build(); &#125; Download object from S3 bucketWe can use getObject method on our AmazonS3 client bean to get object from S3 bucket. getObject returns an S3Objectwhich can be converted to ByteArrayResource .Download object from S3 bucket1234567891011121314@GetMapping(\"/&#123;fileName&#125;\") public ResponseEntity&lt;ByteArrayResource&gt; downloadFile(@PathVariable String fileName) throws IOException &#123; S3Object data = amazonS3.getObject(bucketName, fileName); // fileName is key which is used while uploading the object S3ObjectInputStream objectContent = data.getObjectContent(); byte[] bytes = IOUtils.toByteArray(objectContent); ByteArrayResource resource = new ByteArrayResource(bytes); objectContent.close(); return ResponseEntity .ok() .contentLength(bytes.length) .header(\"Content-type\", \"application/octet-stream\") .header(\"Content-disposition\", \"attachment; filename=\\\"\" + fileName + \"\\\"\") .body(resource); &#125; Deleting object from S3 bucketWe can use deleteObject method on our AmazonS3 client bean to delete object from bucket.Delete Object123456@DeleteMapping(\"/&#123;fileName&#125;\")public ResponseEntity deleteDocument(@PathVariable String fileName) &#123; log.info(\"Deleting file &#123;&#125;\", fileName); amazonS3.deleteObject(bucketName, fileName); // fileName is key which is used while uploading the object return ResponseEntity.ok().build();&#125; Creating presigned-url for accessing objects for limited time.We can use generatePresignedUrl method on our AmazonS3 client bean to generate PresignedUrl which will be valid till provided time.get presignedUrl1234567@GetMapping(\"/presigned-url/&#123;fileName&#125;\") public String presignedUrl(@PathVariable String fileName) throws IOException &#123; return amazonS3 .generatePresignedUrl(bucketName, fileName, convertToDateViaInstant(LocalDate.now().plusDays(1))) .toString();// URL will be valid for 24hrs &#125; Note:On application startup, you might see exception related to Metadata or RegistryFactoryBean. You need to exclude some auto configuration. You can find more detailshttps://stackoverflow.com/a/67409356/320087exclude autoconfigure1234567 spring: autoconfigure: exclude: - org.springframework.cloud.aws.autoconfigure.context.ContextInstanceDataAutoConfiguration - org.springframework.cloud.aws.autoconfigure.context.ContextStackAutoConfiguration - org.springframework.cloud.aws.autoconfigure.context.ContextRegionProviderAutoConfiguration The code for this post is available on Github here","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"AWS","slug":"AWS","permalink":"https://nirajsonawane.github.io/tags/AWS/"},{"name":"S3","slug":"S3","permalink":"https://nirajsonawane.github.io/tags/S3/"}]},{"title":"Spring Boot With AWS SQS","slug":"Spring-Boot-with-AWS-sqs","date":"2021-05-09T15:09:52.000Z","updated":"2021-05-09T17:33:49.970Z","comments":true,"path":"2021/05/09/Spring-Boot-with-AWS-sqs/","link":"","permalink":"https://nirajsonawane.github.io/2021/05/09/Spring-Boot-with-AWS-sqs/","excerpt":"","text":"Spring Cloud messaging support provides a convenient way to interact with AWS SQS service, With the help of spring cloud messaging support we can use all well-known Spring Boot features. It also offers multiple useful features compare to SDK provided by AWS. The code for this post is available on Github here Create a standard AWS SQS queueNavigate to aws consol -&gt; Simple queue service -&gt; create queue. Then select standard queue and provide name to queue.Click on create queue. Create IAM Role and IAM Group, Which will have access to our queue. Using Spring cloud messagingThe Spring Cloud AWS messaging module comes as a standalone module and can be imported with the following dependency1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-aws-messaging&lt;/artifactId&gt;&lt;/dependency&gt; Providing AWS credential and SDK configurationsIn order to make calls to the AWS Services the credentials must be configured for the the Amazon SDK. In order to access SQS service we can configure access key and secret key using yaml or properties files12345678910cloud: aws: region: static: us-east-1 auto: false credentials: access-key: XXXX secret-key: XXXX end-point: uri: https://sqs.us-east-1.amazonaws.com/549485575026/spring-boot-poc Sending message to SQS. In order to send messages to SQS queue, Spring boot provides QueueMessagingTemplate which uses AmazonSQSAsyncConfiguration for QueueMessagingTemplate1234567891011121314151617181920@Configurationpublic class SQSConfig &#123; @Value(\"$&#123;cloud.aws.region.static&#125;\") private String region; @Value(\"$&#123;cloud.aws.credentials.access-key&#125;\") private String accessKey; @Value(\"$&#123;cloud.aws.credentials.secret-key&#125;\") private String secretKey; @Bean public QueueMessagingTemplate queueMessagingTemplate() &#123; return new QueueMessagingTemplate(amazonSQSAsync()); &#125; @Bean @Primary public AmazonSQSAsync amazonSQSAsync() &#123; return AmazonSQSAsyncClientBuilder.standard().withRegion(Regions.US_EAST_1) .withCredentials(new AWSStaticCredentialsProvider(new BasicAWSCredentials(accessKey, secretKey))) .build(); &#125;&#125; QueueMessagingTemplate Provides a convenient method convertAndSend which can be used to send domain objects as message. QueueMessagingTemplate delegate the conversion process to an instance of the MessageConverter interface. This interface defines a simple contract to convert between Java objects and SQS messages.Message Publisher1234567891011121314@Component@Slf4jpublic class Publisher &#123; @Autowired private QueueMessagingTemplate queueMessagingTemplate; @Value(\"$&#123;cloud.aws.end-point.uri&#125;\") private String endpoint; @Scheduled(fixedRate = 1000) public void scheduleFixedRateTask() &#123; log.info(\"Sending Message to SQS \"); //queueMessagingTemplate.send(endpoint, MessageBuilder.withPayload(\"Niraj\").build()); queueMessagingTemplate.convertAndSend(endpoint, new Pojo(\"SomeRandomValue\")); &#125;&#125; Consuming Messages from SQS Spring boot provides a convenient Annotation @SqsListener. In below example a queue listener container is started that polls the spring-boot-poc queue. The incoming messages is converted to the type of method argument, in this case Pojo. As the deletionPolicy is provided as ON_SUCCESS it means, Message will be Deleted from Queue only when successfully executed by listener method (no exception thrown). We can set the Global deletion policy for all the queues which are consumed bySqsListener by using property cloud.aws.sqs.handler.default-deletion-policy=ON_SUCCESSMessage Consumer12345678@Component@Slf4jpublic class Consumer &#123; @SqsListener(value = \"spring-boot-poc\",deletionPolicy = SqsMessageDeletionPolicy.ON_SUCCESS) public void processMessage(Pojo message) &#123; log.info(\"Message from SQS &#123;&#125;\", message); &#125;&#125; Note:On application startup, you might see exception related to Metadata or RegistryFactoryBean. You need to exclude some auto configuration. You can find more detailshttps://stackoverflow.com/a/67409356/320087exclude autoconfigure1234567 spring: autoconfigure: exclude: - org.springframework.cloud.aws.autoconfigure.context.ContextInstanceDataAutoConfiguration - org.springframework.cloud.aws.autoconfigure.context.ContextStackAutoConfiguration - org.springframework.cloud.aws.autoconfigure.context.ContextRegionProviderAutoConfiguration The code for this post is available on Github here","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"AWS","slug":"AWS","permalink":"https://nirajsonawane.github.io/tags/AWS/"},{"name":"SQS","slug":"SQS","permalink":"https://nirajsonawane.github.io/tags/SQS/"}]},{"title":"Spring Boot With Hibernate Envers","slug":"spring-boot-with-hibernate-envers","date":"2021-04-25T19:30:36.000Z","updated":"2021-04-26T19:50:42.940Z","comments":true,"path":"2021/04/25/spring-boot-with-hibernate-envers/","link":"","permalink":"https://nirajsonawane.github.io/2021/04/25/spring-boot-with-hibernate-envers/","excerpt":"","text":"Hibernate Envers provides an easy &amp; flexible way to implement database auditing and versioning. Database Auditing in the context of JPA means tracking and logging the changes on persisted entities. The database audit logs are important from compliance perspectives and also provides grate helps to identify how and what data has been changed. Hibernate Envers can be integrated very easyly with Spring Boot JPA. The code for this post is available on Github here To use Envers in Spring boot application, We need to add below dependency.12345&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-envers&lt;/artifactId&gt; &lt;version&gt;5.4.30.Final&lt;/version&gt;&lt;/dependency&gt; To Audit changes that are performed on an entity, we need to add @Audited annotation on the entity.Considering we have a UserDetails entity,for which we want to enable Auditing.12345678@Entity@Auditedpublic class UserDetails &#123; @Id private Integer userId; private String firstName; private String lastName;&#125; In order to log all the changes to entity, Envers needs REVINFO and Entity_aud table, In this case it will be USER_DETAILS_AUD.The REVINFO table contains revision id and revision timestamp. A row is inserted into this table on each new revision, that is, on each commit of a transaction, which changes audited data.flyway migration scripts for the the audit table and revinfo table will look like below.123456789101112131415161718192021CREATE TABLE REVINFO ( REV INTEGER GENERATED BY DEFAULT AS IDENTITY, REVTSTMP BIGINT, PRIMARY KEY (REV));CREATE TABLE USER_DETAILS ( USER_ID INTEGER PRIMARY KEY, FIRST_NAME VARCHAR(50) NOT NULL, LAST_NAME VARCHAR(50) NOT NULL );CREATE TABLE USER_DETAILS_AUD ( USER_ID INTEGER NOT NULL, FIRST_NAME VARCHAR(50), LAST_NAME VARCHAR(50), REV INTEGER NOT NULL, REVTYPE INTEGER NOT NULL, PRIMARY KEY (USER_ID, REV)); Now when we insert,update and delete UserDetails entity, audit log will be saved in USER_DETAILS_AUD table. for below code we should expect 4 rows in USER_DETAILS_AUD table123456789101112private void dataSetup(UserDetailsRepository userRepository) &#123; UserDetails userDetails = new UserDetails(1, \"NIRAJ\", \"SONAWANE\"); userRepository.save(userDetails); // Create userDetails.setFirstName(\"Updated Name\"); userRepository.save(userDetails); // Update-1 userDetails.setLastName(\"Updated Last name\"); // Update-2 userRepository.save(userDetails); userRepository.delete(userDetails); // Delete&#125; The REVTYPE column value is taken from the RevisionType Enum. Which has values0-Add1-Update2-Delete The code for this post is available on Github here","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"JPA","slug":"JPA","permalink":"https://nirajsonawane.github.io/tags/JPA/"},{"name":"Hibernate Envers","slug":"Hibernate-Envers","permalink":"https://nirajsonawane.github.io/tags/Hibernate-Envers/"}]},{"title":"Consumer Driven Contract Test Using Spring Cloud Contract","slug":"Contract-Testing-Using-Spring-Cloud-Contract","date":"2021-02-20T20:00:29.000Z","updated":"2021-02-22T06:07:02.695Z","comments":true,"path":"2021/02/20/Contract-Testing-Using-Spring-Cloud-Contract/","link":"","permalink":"https://nirajsonawane.github.io/2021/02/20/Contract-Testing-Using-Spring-Cloud-Contract/","excerpt":"","text":"Photo by Beatriz Pérez Moya on Unsplash This post discusses, What is Consumer Driven Contract test? and How to implement it using Spring Cloud Contract. The code for this post is available on Github here Contract TestingContract test are set of automated test, That verifies two separate services are adhering to predefine contracts and are compatible with each other.Aim of contract test is to make sure that, Contract are always kept up to date and each service ( Provider &amp; Consumer) can be tested independently. Consumer Driven Contract testIn consumer driven contract testing, Consumers are responsible for providing the contract details. In this strategy consumers of API are at the heart of API design process.In consumer driven API design process providers are forced to complete their consumer obligations. Frameworks like pact and Spring Cloud Contracts provides set of tools to implement Consumer Driven Contract test. Spring Cloud ContractSpring Cloud Contract provides set of tool for implementing Consumer Driven Contract test for Spring based applications. It has two major component Contract Verifier for Producers &amp; Stub Runner for consumer Sample applicationLet’s write some contract test. Assume we got an requirement from Consumer application Service-A for status API for Provider application Service-B, Which will provide Current Status of user. In consumer driven contract strategy, as consumer of service, consumers need to define what exactly they want from producer in the form of written contracts. You can provide contract in groovy or yaml format Provider : Service-B1234567891011121314151617181920import org.springframework.cloud.contract.spec.ContractContract.make &#123; description \"should return user status\" request &#123; url \"/status\" method GET() &#125; response &#123; status OK() headers &#123; contentType applicationJson() &#125; body ( id: 1, status: \"CREATED\" ) &#125;&#125; Implement Contract1234567891011121314151617@RestControllerclass UserStatusController(private val userStatusService: UserStatusService) &#123; @GetMapping(\"/status\") fun getStatus(): ResponseEntity&lt;UserStatus&gt; &#123; return ResponseEntity.ok(userStatusService.getUserStatus(1)) &#125;&#125;data class UserStatus(val id: Int, val status: String)@Serviceclass UserStatusService &#123; fun getUserStatus(userId:Int):UserStatus&#123; return UserStatus(1,\"ACTIVATED\") &#125;&#125; How to verify contracts ?spring-cloud-starter-contract-verifier helps us to automatically verify the contracts, It’s generates the test cases during the build phase and verify the API response against the contract. Add below dependency in pom 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-contract-verifier&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; To auto-generated tests classes, Add below plugin inside build tag.12345678910&lt;plugin&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-contract-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;configuration&gt; &lt;testFramework&gt;JUNIT5&lt;/testFramework&gt; &lt;baseClassForTests&gt;com.ns.producer.BaseClass&lt;/baseClassForTests&gt; &lt;/configuration&gt;&lt;/plugin&gt; We also need to provide BaseClassForTest, which will be extended by all generated classes. Base class is responsible for providing all needed mocking &amp; spring beans needed for the generated test classes.In out cases this is how base class will look like. BaseClass1234567891011121314@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)public abstract class BaseClass &#123; @Autowired private UserStatusController userStatusController; @MockBean private UserStatusService userStatusService; @BeforeEach public void setup() &#123; Mockito.when(userStatusService.getUserStatus(1)).thenReturn(new UserStatus(1, \"CREATED\")); RestAssuredMockMvc.standaloneSetup(userStatusController); &#125;&#125; Now if we run the build, ContractVerifierTest test class will be generated inside /target/generated-test-source/contract generated class will be look like below Generated Test Class1234567891011121314151617public class ContractVerifierTest &#123; @Test public void validate_get_status_by_id() throws Exception &#123; // given: MockMvcRequestSpecification request = given(); // when: ResponseOptions response = given().spec(request) .get(\"/status\"); // then: assertThat(response.statusCode()).isEqualTo(200); assertThat(response.header(\"Content-Type\")).matches(\"application/json.*\"); // and: DocumentContext parsedJson = JsonPath.parse(response.getBody().asString()); assertThatJson(parsedJson).field(\"['id']\").isEqualTo(1); assertThatJson(parsedJson).field(\"['status']\").isEqualTo(\"CREATED\"); &#125;&#125; Consumer : Service-AOn the consumer side , We can use stub generated by Producer application to test the interaction from consumer to producer.To use stub generated by producer add below dependancy in consumer pom12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-contract-stub-runner&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; the Unit test to test interaction with Producer will look like belowpom123456789101112131415161718192021222324@SpringBootTestclass StatusServiceTests &#123; @Autowired lateinit var underTest: StatusService @JvmField @RegisterExtension final val stubRunner = StubRunnerExtension() .downloadStub(\"com.ns\", \"producer\", \"0.0.1-SNAPSHOT\", \"stubs\") .withPort(8080) .stubsMode(StubRunnerProperties.StubsMode.LOCAL) @Test fun getStatus() &#123; val status = underTest.getStatus() assertEquals(status, \"CREATED\") &#125; @Test fun getPactStatus() &#123; val status = underTest.getPactStatus() assertEquals(status, \"CREATED\") &#125;&#125; The code for this post is available on Github here Reference Spring Cloud Contract Reference Documentation","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Contract Testing","slug":"Contract-Testing","permalink":"https://nirajsonawane.github.io/tags/Contract-Testing/"},{"name":"Spring Cloud Contract","slug":"Spring-Cloud-Contract","permalink":"https://nirajsonawane.github.io/tags/Spring-Cloud-Contract/"},{"name":"pact","slug":"pact","permalink":"https://nirajsonawane.github.io/tags/pact/"}]},{"title":"Monitoring Spring Boot Application with Prometheus and Grafana on Kubernetes","slug":"Monitoring-Spring-Boot-Application-with-Prometheus-and-Grafana-on-Kubernetes","date":"2020-05-17T17:37:36.000Z","updated":"2020-05-17T21:51:20.000Z","comments":true,"path":"2020/05/17/Monitoring-Spring-Boot-Application-with-Prometheus-and-Grafana-on-Kubernetes/","link":"","permalink":"https://nirajsonawane.github.io/2020/05/17/Monitoring-Spring-Boot-Application-with-Prometheus-and-Grafana-on-Kubernetes/","excerpt":"","text":"unsplash-logoCarlos Muza Welcome to the second post on Prometheus &amp; Grafana. In last post Monitoring Spring Boot Application with Prometheus and Grafana we Integrated Prometheus , Spring Boot and Grafana using docker. In this post we will discuss, How to setup Prometheus and Grafana on Kubernetes using Helm Charts The code for this post is available on Github here If you’re new to Kubernetes &amp; Prometheus I recommend reading the following hands-on guide on Kubernetes. Deploy React, Spring Boot & MongoDB Fullstack application on Kubernetes Monitoring Spring Boot Application with Prometheus and Grafana PrerequisitesYou need to have Kubectl, Helm, Minikube installed on your machine. To Follow along this post, Basic knowledge of Kubernetes is needed. Step 1 : Deploy a Spring Boot application on Kubernetes and expose actuator endpoints How to deploy Spring boot application on Kubernetes is explained in detail here How to expose actuator endpoints for Prometheus is explained here. In Kubernetes environment , we can configure annotations which will be used by prometheus to scrap data.Below is the complete deployment.yaml file spring-boot-prometheus-deployment.yaml123456789101112131415161718192021222324252627apiVersion: apps/v1kind: Deploymentmetadata: name: spring-boot-prometheusspec: selector: matchLabels: app: spring-boot-prometheus replicas: 1 template: metadata: labels: app: spring-boot-prometheus annotations: prometheus.io/scrape: \"true\" prometheus.io/port: \"8080\" prometheus.io/path: \"/actuator/prometheus\" spec: containers: - name: spring-boot-prometheus image: nirajsonawane/spring-boot-prometheus:0.0.1-SNAPSHOT imagePullPolicy: Always ports: - containerPort: 8080 resources: limits: memory: 294Mi Step 2 : Create separate namespace for Monitoringit’s always good idea to keep related things together, We will create separate namespace in Kubernetes for monitoring and will deploy all monitoring related application under that namespace.namespace.yml1234kind: NamespaceapiVersion: v1metadata: name: monitoring Helm ChartHelm uses a packaging format called charts. A chart is a collection of files that describe a related set of Kubernetes resources. A single chart might be used to deploy something simple, like a memcached pod, or something complex, like a full web app stack with HTTP servers, databases, caches, and so on.Charts are created as files laid out in a particular directory tree, then they can be packaged into versioned archives to be deployed. Step 3: Deploy Prometheus using Helm ChartWith the help of Helm, We can deploy prometheus using single command.1helm install prometheus stable/prometheus --namespace monitoringThis will deploy Prometheus into your cluster in the monitoring namespace and mark the release with the name prometheus. let’s check if prometheus is running or not1kubectl get pods -n monitoring Step 4: Deploy Grafana using Helm ChartIn Previous post we have manually created the data sources. Here we can create the config map for Prometheus data source and grafana deployment can use these config maps. After Grafana Helm chart deployment, it looks for any config maps that contain a grafana_datasource label. config.yml12345678910111213141516apiVersion: v1kind: ConfigMapmetadata: name: prometheus-grafana-datasource namespace: monitoring labels: grafana_datasource: '1'data: datasource.yaml: |- apiVersion: 1 datasources: - name: Prometheus type: prometheus access: proxy orgId: 1 url: http://prometheus-server.monitoring.svc.cluster.local values.yml123456sidecar: image: xuxinkun/k8s-sidecar:0.0.7 imagePullPolicy: IfNotPresent datasources: enabled: true label: grafana_datasource Config map & Grafana deployment12kubectl apply -f helm/monitoring/grafana/config.yml helm install grafana stable/grafana -f helm/monitoring/grafana/values.yml --namespace monitoring Password protected Grafana instance will be be deployed, To know the password run the below command.print password1kubectl get secret --namespace monitoring grafana -o jsonpath=&quot;&#123;.data.admin-password&#125;&quot; | base64 --decode ; echoNow let’s do port-forward for accessing grafanaport-forward deployment1kubectl --namespace monitoring port-forward grafana-5c6bbf7f4c-n5pqb 3000 Now if you goto http://localhost:3000 grafana interface will be available. Now lets add JVM chart which wil be using our Prometheus datasource. The code for this post is available on Github here","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://nirajsonawane.github.io/tags/Prometheus/"},{"name":"Grafana","slug":"Grafana","permalink":"https://nirajsonawane.github.io/tags/Grafana/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://nirajsonawane.github.io/tags/kubernetes/"},{"name":"Helm","slug":"Helm","permalink":"https://nirajsonawane.github.io/tags/Helm/"}]},{"title":"Monitoring Spring Boot Application with Prometheus and Grafana","slug":"monitoring-spring-boot-application-with-prometheus-and-grafana","date":"2020-05-03T14:49:18.000Z","updated":"2020-05-04T20:31:00.000Z","comments":true,"path":"2020/05/03/monitoring-spring-boot-application-with-prometheus-and-grafana/","link":"","permalink":"https://nirajsonawane.github.io/2020/05/03/monitoring-spring-boot-application-with-prometheus-and-grafana/","excerpt":"","text":"unsplash-logoCarlos Muza In this post we will discuss how to integrate Prometheus monitoring system with Spring Boot and Grafana. The code for this post is available on Github here This setup has three major components. Spring Boot and MicrometerSpring Boot Actuator provides number of features to help us monitor and manage spring boot application. Spring Boot Actuator also provides dependency management and auto-configuration for Micrometer. Micrometer is an application metrics facade that supports numerous monitoring systems.To integrate Prometheus with spring boot we just need to add micrometer-registry-prometheus dependancy in class path.Once spring boot detects this dependancy it will expose /actuator/prometheus endpoint. pom File12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt; Along with this dependancy we need to set below property. application.properties1management.endpoints.web.exposure.include=health,info,metrics,prometheus Now if we run the application and check http://localhost:8080/actuator/prometheus PrometheusPrometheus is an open-source monitoring and alerting toolkit originally built at SoundCloud.Prometheus does one thing and it does it well. It has a simple yet powerful data model and a query language that lets you analyse how your applications and infrastructure are performing. Prometheus has a data scraper that pulls metrics data over HTTP periodically at a configured interval. It stores metric data in A time-series Database. It has simple user interface that can be used to run query and visualize data. It also has powerful Altering system. let’s try to run Prometheus on docker.We need to configure Prometheus to scrape our spring boot application.prometheus.yml123456789global: scrape_interval: 10sscrape_configs: - job_name: 'spring_micrometer' metrics_path: '/actuator/prometheus' scrape_interval: 5s static_configs: - targets: ['YOUR-MACHINE-IP:8080'] configuration is very much self explanatory. We have created job ‘spring_micrometer’ for scraping our spring boot application and provided the endpoint where prometheus can get the data. As we are runing Prometheus from docker in targets we need to provide IP of local machine. Run Prometheus on docker1docker run -d -p 9090:9090 -v &lt;File path of prometheus.yml&gt;:/etc/prometheus/prometheus.yml prom/prometheus Now if you goto http://localhost:9090/targets it should show our spring boot application. GrafanaGrafana is open source visualization and analytics software. It allows you to query, visualize, alert on, and explore your metrics no matter where they are stored. It provides you with tools to turn your time-series database (TSDB) data into beautiful graphs and visualizations. Grafana supports querying Prometheus from very initial version let’s try to setup grafana using docker. docker run1docker run -d -p 3000:3000 grafana/grafana Now if you goto http://localhost:3000 grafana interface will be available. Default username password is admin/admin.you can add Prometheus data source and dashboard by following below steps. Your browser does not support the video tag. The code for this post is available on Github here","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Prometheus","slug":"Prometheus","permalink":"https://nirajsonawane.github.io/tags/Prometheus/"},{"name":"Grafana","slug":"Grafana","permalink":"https://nirajsonawane.github.io/tags/Grafana/"}]},{"title":"Deploy React, Spring Boot & MongoDB Fullstack application on Kubernetes","slug":"Deploy-React-Spring-Boot-MongoDB-Fullstack-application-on-Kubernetes","date":"2020-04-25T20:21:19.000Z","updated":"2020-05-17T21:48:38.000Z","comments":true,"path":"2020/04/25/Deploy-React-Spring-Boot-MongoDB-Fullstack-application-on-Kubernetes/","link":"","permalink":"https://nirajsonawane.github.io/2020/04/25/Deploy-React-Spring-Boot-MongoDB-Fullstack-application-on-Kubernetes/","excerpt":"","text":"unsplash-logoKeith Misner In this post we will discuss how to Deploy Full stack application on Kubernetes. We will build small Student CRUD application using React as Front end, Spring Boot as back end and MongoDB as persistance layer and we also configure PersistentVolumeClaim. The code for this post is available on Github here PrerequisitesTo Follow along this post, You need to have minikube and kubectl installed on your system. Basic knowledge of Docker,Kubernetes &amp; Spring Boot is needed. The sample application that we will be deploying on Kubernetes allows user to perform CRUD operations and the final deployment structure will be below. let’s start Step 1 : Deploy a React application on KubernetesThe React app is created by create-react-app and then docker image is available on Ducker hub. You can also this image to follow along docker pull nirajsonawane/student-app-client Deployment configurationstudent-app-client-deployment File1234567891011121314151617181920apiVersion: apps/v1kind: Deploymentmetadata: name: student-app-clientspec: selector: matchLabels: app: student-app-client replicas: 1 template: metadata: labels: app: student-app-client spec: containers: - name: student-app-client image: nirajsonawane/student-app-client imagePullPolicy: Always ports: - containerPort: 80 Deployments in Kubernetes is declarative way of creating and updating pods. In above configurations we created student-app-client deployment indicated by name, with 1 number of replicas. The containers sections provides details about Which &amp; How the containers should get created. Service configurationstudent-app-client-service File123456789101112apiVersion: v1kind: Servicemetadata: name: student-app-client-servicespec: selector: app: student-app-client ports: - port: 80 protocol: TCP targetPort: 80 type: ClusterIPService in Kubernetes is way to expose application running on a set of Pods (Deployments) as network service. The above configurations creates a new Service object named student-app-client-service, which targets TCP port 80 on any Pod with the app=student-app-client label. Kubernetes ServiceTypes allow you to specify what kind of Service you want. The default is ClusterIP. Please Check the documentation for more details. let’s deploy it on our local Kubernetes clusterStart minikube minikube start Check minikube status minikube status Apply deployment and service for client kubectl apply -f &lt;file-name.yaml&gt; Tip: If you want to check if client pod is getting correctly deployed and want to access URL, Change the service type to NodePort and then runminikube service student-app-client-service Step 2 : Deploy MongoDB persistance layer on KubernetesFor Managing storage Kubernetes PersistentVolume subsystem provides API which defines how storage is provided and how it is consumed. For this we need to create two kubernetes resources A PersistentVolume (PV) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes. lifecycle of PV is independent of any individual Pod that uses the PV. In simple words PV are user-provisioned storage volumes assigned to a Kubernetes cluster. A PersistentVolumeClaim (PVC) is a request for storage by a user that deployment needs. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. In order to deploy the the database component we need to define below resource configurations : PersistentVolumeClaim Deployment Service PersistentVolumeClaimPersistentVolumeClaim config File12345678910apiVersion: v1kind: PersistentVolumeClaimmetadata: name: mongo-pvcspec: accessModes: - ReadWriteOnce resources: requests: storage: 256MiThe access modes are:ReadWriteOnce – the volume can be mounted as read-write by a single nodeReadOnlyMany – the volume can be mounted read-only by many nodesReadWriteMany – the volume can be mounted as read-write by many nodes DeploymentDeployment Config File12345678910111213141516171819202122232425apiVersion: apps/v1kind: Deploymentmetadata: name: mongospec: selector: matchLabels: app: mongo template: metadata: labels: app: mongo spec: containers: - name: mongo image: mongo:3.6.17-xenial ports: - containerPort: 27017 volumeMounts: - name: storage mountPath: /data/db volumes: - name: storage persistentVolumeClaim: claimName: mongo-pvcDeployment is requesting volume defined by claim Name mongo-pvc ServiceService Config File12345678910apiVersion: v1kind: Servicemetadata: name: mongospec: selector: app: mongo ports: - port: 27017 targetPort: 27017 let’s apply all these new configurations.Apply PersistentVolumeClaim , deployment and service for MongoDB kubectl apply -f &lt;file-name.yaml&gt; Step 3 : Deploy Spring Boot Backend API on KubernetesOur Backend api is simple spring boot application and it is using doing CRUD using MongoRepository complete code is available on Github here Spring boot app is dockerized and docker image is available docker hub. docker pull nirajsonawane/student-app-api:0.0.1-SNAPSHOTDeploymentAPI Deployment Config File1234567891011121314151617181920212223apiVersion: apps/v1kind: Deploymentmetadata: name: student-app-apispec: selector: matchLabels: app: student-app-api replicas: 1 template: metadata: labels: app: student-app-api spec: containers: - name: student-app-api image: nirajsonawane/student-app-api:0.0.1-SNAPSHOT imagePullPolicy: Always ports: - containerPort: 8080 env: - name: MONGO_URL value: mongodb://mongo:27017/devin above yaml file The env: is used to define environment variables for the POD. Our API expects MONGO_URL for configuration of spring.data.mongodb.uriapplication.properties1spring.data.mongodb.uri=$&#123;MONGO_URL:mongodb://localhost:27017/dev&#125;Now let’s talk about MONGO_URL. mongodb url is configured like mongodb://someHost:27017/dev so what is mongo in our url? mongo is name defined in service config file of mongo.Pods within a cluster can talk to each other through the names of the Services exposing them. ServiceService Config File for API1234567891011apiVersion: v1kind: Servicemetadata: name: student-app-apispec: selector: app: student-app-api ports: - port: 8080 protocol: TCP targetPort: 8080Apply deployment and service for API kubectl apply -f &lt;file-name.yaml&gt; Step 4 : Deploy Ingress and connect frontend to backendIngress is an API object that manages external access to the services in a cluster. Ingress Resource123456789101112131415161718apiVersion: networking.k8s.io/v1beta1 # for versions before 1.14 use extensions/v1beta1kind: Ingressmetadata: name: student-app-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: /$1spec: rules: - http: paths: - path: /?(.*) backend: serviceName: student-app-client-service servicePort: 80 - path: /api/?(.*) backend: serviceName: student-app-api servicePort: 8080 We can define different HTTP rule in ingress configuration. For our application we have configured two rules in backend section. A backend is a combination of Service and port names as described in the Service doc. HTTP (and HTTPS) requests to the Ingress that matches the host and path of the rule are sent to the listed backend. Note While making call to backend API from react client we are prefixing request with api and then redirecting request to student-app-api thro our Ingress. We can also use service-name for direct making call to backend api. lets deploy the final resource.Fist we need to enable ingress by running minikube addons enable ingress and then ‘kubectl apply -f student-app-ingress.yaml’ let’s try to access the application from minikube ip The code for this post is available on Github here","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://nirajsonawane.github.io/tags/Kubernetes/"},{"name":"React","slug":"React","permalink":"https://nirajsonawane.github.io/tags/React/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://nirajsonawane.github.io/tags/MongoDB/"},{"name":"Minikube","slug":"Minikube","permalink":"https://nirajsonawane.github.io/tags/Minikube/"}]},{"title":"Project Reactor [Part 3]  Error Handling","slug":"Project-Reactor-Part-3-Error-Handling","date":"2020-01-04T16:18:19.000Z","updated":"2020-01-04T18:06:04.000Z","comments":true,"path":"2020/01/04/Project-Reactor-Part-3-Error-Handling/","link":"","permalink":"https://nirajsonawane.github.io/2020/01/04/Project-Reactor-Part-3-Error-Handling/","excerpt":"","text":"unsplash-logoDaniil SilantevThis is the third article on a series of articles on Project Reactor. In previous article we discussed different operators in Project Reactor. In this article, I’ll show you how to do error handling in reactor. We’ll do this through examples. In Reactive programming errors are also consider as terminal events. When an error occurs, event is sent to onError method of Subscriber.Before we start looking at how we handle errors, you must keep in mind that any error in a reactive sequence is a terminal event. Even if an error-handling operator is used, it does not let the original sequence continue. Rather, it converts the onError signal into the start of a new sequence (the fallback one). In other words, it replaces the terminated sequence upstream of it. The code for this post is available on my Github account here OnErrorIn below code blok, subscriber will print values from 1,2,3,4,5 and after that onError code block will get executed. Note that number 6 will never be printed as Error is terminal event. subscriber Completed line will also not be printed on console as in case of error we do not get onComplete event.OnError12345678910111213141516public void testErrorFlowFlux() &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3,4,5) .concatWith(Flux.error(new RuntimeException(\"Test\"))) .concatWith(Flux.just(6)); fluxFromJust.subscribe( (it)-&gt; System.out.println(\"Number is \" + it), // OnNext (e) -&gt; e.printStackTrace(), //OnError () -&gt; System.out.println(\"subscriber Completed\") //onComplete ); //To Unit test this code StepVerifier .create(fluxFromJust) .expectNext(1, 2,3,4,5) .expectError(RuntimeException.class); onErrorResumeIf you want to report exception and then want to return some fallback value you can use ‘onErrorResume’ onErrorResume123456789101112131415161718192021 @Testpublic void testOnErrorResume() throws InterruptedException &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3,4,5) .concatWith(Flux.error(new RuntimeException(\"Test\"))) .concatWith(Flux.just(6)) .onErrorResume(e-&gt;&#123; log.info(\"**************\"); System.out.println(\"Exception occured \" + e.getMessage()); //Return Some Fallback Values return Flux.just(7,8); &#125;); StepVerifier .create(fluxFromJust) .expectNext(1, 2,3,4,5) .expectNext(7,8) .verifyComplete();&#125; onErrorReturnonErrorReturn can be used if you just want to return some fallback value for error itemonErrorResume12345678910111213141516 @Testpublic void testOnErrorReturn() throws InterruptedException &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3,4,5) .concatWith(Flux.error(new RuntimeException(\"Test\"))) .concatWith(Flux.just(6)) .onErrorReturn(99) ; StepVerifier .create(fluxFromJust) .expectNext(1, 2,3,4,5) .expectNext(99) .verifyComplete();&#125; OnErrorContinueIf you want to ignore error produce by any operator onErrorContinue can be use.onErrorContinue will ignore the error element and continue the sequence.in below example for number 3 we are getting some exception, onErrorContinue will simply ignore that exception.onErrorContinue1234567891011121314151617181920212223 @Testpublic void testOnErrorContinue() throws InterruptedException &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3,4,5) .map(i-&gt;mapSomeValue(i)) .onErrorContinue((e,i)-&gt;&#123; System.out.println(\"Error For Item +\" + i ); &#125;) ; StepVerifier .create(fluxFromJust) .expectNext(1, 2,4,5) .verifyComplete();&#125;private int mapSomeValue(Integer i) &#123; if( i==3) throw new RuntimeException(\"Exception From Map\"); return i;&#125; OnErrorMapTo Map Exception to any custom exceptionOnErrorMap123456789101112131415 @Testpublic void testOnErrorMap() throws InterruptedException &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3,4,5) .concatWith(Flux.error(new RuntimeException(\"Test\"))) .concatWith(Flux.just(6)) .map(i-&gt;i*2) .onErrorMap(e -&gt; new CustomeException(e) ) ; StepVerifier .create(fluxFromJust) .expectNext(2, 4,6,8,10) .expectError(CustomeException.class);&#125; retryYou can add retry on error. But keep in mind the retry will be started from first element.retry1234567891011121314151617@Testpublic void testOnRetry() throws InterruptedException &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3) .map(i-&gt;i*2) .onErrorMap(e -&gt; new CustomeException(e) ) .retry(2); StepVerifier .create(fluxFromJust) .expectNext(2, 4,6) .expectNext(2, 4,6) .expectNext(2, 4,6) .expectError(CustomeException.class) .verify();&#125; onErrorStop onErrorStop will stop the execution onErrorStop1234567891011121314151617@Testpublic void testOnErrorStop() throws InterruptedException &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3) .concatWith(Flux.error(new RuntimeException(\"Test\"))) .concatWith(Flux.just(6)) .map(i-&gt;doubleValue(i)) .onErrorStop(); StepVerifier .create(fluxFromJust) .expectNext(2, 4,6) .verifyError();&#125; private Integer doubleValue(Integer i) &#123; System.out.println(\"Doing Multiple\"); return i*2;&#125; doOnErrorIt you want to execute side effect on errordoOnError1234567891011121314 @Testpublic void testDoOnError() throws InterruptedException &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3,4,5) .concatWith(Flux.error(new RuntimeException(\"Test\"))) .doOnError(e -&gt; System.out.println(\"Rum some Side effect!!\")); StepVerifier .create(fluxFromJust) .expectNext(1, 2,3,4,5) .expectError() .verify(); TimeUnit.SECONDS.sleep(2);&#125; doFinallydoFinally is similar to finally block of try catch.doOnError123456789101112131415161718192021 @Testpublic void testDoFinally() throws InterruptedException &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3,4,5) .concatWith(Flux.error(new RuntimeException(\"Test\"))) .doFinally( i-&gt;&#123; if (SignalType.ON_ERROR.equals(i)) &#123; System.out.println(\"Completed with Error \"); &#125; if (SignalType.ON_COMPLETE.equals(i)) &#123; System.out.println(\"Completed without Error \"); &#125; &#125;); StepVerifier .create(fluxFromJust) .expectNext(1, 2,3,4,5) .expectError() .verify(); TimeUnit.SECONDS.sleep(2);&#125;The code for this post is available on my Github account here","categories":[],"tags":[{"name":"Reactive Programming","slug":"Reactive-Programming","permalink":"https://nirajsonawane.github.io/tags/Reactive-Programming/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Project Reactor","slug":"Project-Reactor","permalink":"https://nirajsonawane.github.io/tags/Project-Reactor/"},{"name":"WebFlux","slug":"WebFlux","permalink":"https://nirajsonawane.github.io/tags/WebFlux/"}]},{"title":"Project Reactor [Part 2]  Exploring Operators in Flux & Mono","slug":"Part-2-Process-and-Transform-Flux-Mono","date":"2020-01-01T16:17:37.000Z","updated":"2020-01-04T18:06:36.000Z","comments":true,"path":"2020/01/01/Part-2-Process-and-Transform-Flux-Mono/","link":"","permalink":"https://nirajsonawane.github.io/2020/01/01/Part-2-Process-and-Transform-Flux-Mono/","excerpt":"","text":"unsplash-logoDaniil Silantev This is the second article on a series of Project Reactor. In previous article we discussed basic of Flux an Mono. In this second article, I’ll show you how to use Operators to modified and transform flux. We’ll do this through examples.The code for this post is available on my Github account here FilterThis is similar to java 8 stream filter. It takes predicates, the elements which satisfies predicate condition will be pass thro.Filtering12345678910@Testpublic void testFilteringFlux() &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3,4,5,6,7,8,9,10).log(); Flux&lt;Integer&gt; filter = fluxFromJust.filter(i -&gt; i % 2 == 0);//filter the even numbers only StepVerifier .create(filter) .expectNext(2,4,6,8,10) .verifyComplete();&#125; Distinctit filter out duplicates.Distinct12345678910@Testpublic void distinct() &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3,4,5,1,2,3,4,5).log(); Flux&lt;Integer&gt; distinct = fluxFromJust.distinct(); StepVerifier .create(distinct) .expectNext(1, 2,3,4,5) .verifyComplete();&#125; takeWhileConsumes values from flux until predicate returns TRUE for the valuestakeWhile12345678910@Testpublic void takeWhile() &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3,4,5,6,7,8,9,10).log(); Flux&lt;Integer&gt; takeWhile = fluxFromJust.takeWhile(i -&gt; i &lt;=5); StepVerifier .create(takeWhile) .expectNext(1, 2,3,4,5) .verifyComplete();&#125; skipWhileSkips elements until predicate returns TRUE for the valuesskipWhile12345678910@Test public void skipWhile() &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2,3,4,5,6,7,8,9,10).log(); Flux&lt;Integer&gt; takeWhile = fluxFromJust.skipWhile(i -&gt; i &lt;=5); StepVerifier .create(takeWhile) .expectNext(6,7,8,9,10) .verifyComplete(); &#125; mapMap operation is similar to java 8 stream map operation. Map operation is use for transforming element from one Type to another.Convert String Flux To Integer Flux12345678910@Test public void testMapOperationFlux() &#123; Flux&lt;String&gt; fluxFromJust = Flux.just(\"RandomString\", \"SecondString\",\"XCDFRG\").log(); Flux&lt;Integer&gt; filter = fluxFromJust.map(i-&gt; i.length()); StepVerifier .create(filter) .expectNext(12,12,6) .verifyComplete(); &#125; flatMapFlatMap Transform the elements emitted by this Flux asynchronously into Publishers, then flatten these inner publishers into a single Flux through merging, which allow them to interleave.FlatMap12345678910111213141516@Test public void testFlatMapFlux() &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1,2,3).log(); Flux&lt;Integer&gt; integerFlux = fluxFromJust .flatMap(i -&gt; getSomeFlux(i));//getSomeFlux returns flux of range , // then we do flatMap on all Flux to convert them in to single Flux StepVerifier .create(integerFlux) .expectNextCount(30) .verifyComplete(); &#125; private Flux&lt;Integer&gt; getSomeFlux(Integer i) &#123; return Flux.range(i,10); &#125; IndexKeep information about the order in which source values were received by indexing them with a 0-based incrementing longindex123456789101112public void maintainIndex()&#123; Flux&lt;Tuple2&lt;Long, String&gt;&gt; index = Flux .just(\"First\", \"Second\", \"Third\") .index(); StepVerifier.create(index) .expectNext(Tuples.of(0L,\"First\")) .expectNext(Tuples.of(1L,\"Second\")) .expectNext(Tuples.of(2L,\"Third\")) .verifyComplete(); &#125; flatMapManyThis operator is very useful if you want to convert mono to flux.flatMapMany transforms the signals emitted by this Mono into signal-specific Publishers, then forward the applicable Publisher’s emissions into the returned Flux.flatMapMany123456789@Test public void flatMapManyTest() &#123; Mono&lt;List&lt;Integer&gt;&gt; just = Mono.just(Arrays.asList(1, 2, 3)); Flux&lt;Integer&gt; integerFlux = just.flatMapMany(it -&gt; Flux.fromIterable(it)); StepVerifier .create(integerFlux) .expectNext(1, 2, 3) .verifyComplete(); &#125; startWithstartWith12345678@Test public void startWith()&#123; Flux&lt;Integer&gt; just = Flux.just(1, 2, 3); Flux&lt;Integer&gt; integerFlux = just.startWith(0); StepVerifier.create(integerFlux) .expectNext(0,1,2,3) .verifyComplete(); &#125; concatWithThe concatWith method does concatenation of two flux sequentially subscribing to the first flux then waits for completion and then subscribes to the next.concatWith12345678@Test public void concatWith()&#123; Flux&lt;Integer&gt; just = Flux.just(1, 2, 3); Flux&lt;Integer&gt; integerFlux = just.concatWith(Flux.just(4,5)); StepVerifier.create(integerFlux) .expectNext(1,2,3,4,5) .verifyComplete(); &#125; mergeMerge data from Publisher sequences contained in an array / vararg into an interleaved merged sequence. Unlike concat, sources are subscribed to eagerly.Merge123456789@Test public void zip() throws InterruptedException &#123; Flux&lt;Integer&gt; firsFlux = Flux.just(1, 2, 3,4,5).delayElements(Duration.ofSeconds(1)); Flux&lt;Integer&gt; secondFlux = Flux.just(10, 20, 30, 40).delayElements(Duration.ofSeconds(1)); firsFlux.mergeWith(secondFlux) .subscribe(System.out::println); //This will print numbers received from firsFlux and secondFlux in random order TimeUnit.SECONDS.sleep(11); &#125; CollectListCollect all elements emitted by this Flux into a List that is emitted by the resulting Mono when this sequence completes. CollectList123456789@Test public void CollectList()&#123; Mono&lt;List&lt;Integer&gt;&gt; listMono = Flux .just(1, 2, 3) .collectList(); StepVerifier.create(listMono) .expectNext(Arrays.asList(1,2,3)) .verifyComplete(); &#125; CollectSortedList123456789@Test public void CollectSortedListList()&#123; Mono&lt;List&lt;Integer&gt;&gt; listMono = Flux .just(1, 2, 3,9,8) .collectSortedList(); StepVerifier.create(listMono) .expectNext(Arrays.asList(1,2,3,8,9)) .verifyComplete(); &#125; zipZip multiple sources together, that is to say wait for all the sources to emit one element and combine these elements once into an output value (constructed by the provided combinator). The operator will continue doing so until any of the sources completes. Errors will immediately be forwarded. This “Step-Merge” processing is especially useful in Scatter-Gather scenarios. Zip12345678910@Test public void zip() &#123; Flux&lt;Integer&gt; firsFlux = Flux.just(1, 2, 3); Flux&lt;Integer&gt; secondFlux = Flux.just(10, 20, 30, 40); Flux&lt;Integer&gt; zip = Flux.zip(firsFlux, secondFlux, (num1, num2) -&gt; num1 + num2); StepVerifier .create(zip) .expectNext(11, 22, 33) .verifyComplete(); &#125; bufferCollect all incoming values into a single List buffer that will be emitted by the returned Flux once this Flux completes.buffer123456789101112131415@Test public void bufferTest() &#123; Flux&lt;List&lt;Integer&gt;&gt; buffer = Flux .just(1, 2, 3, 4, 5, 6, 7) .buffer(2); StepVerifier .create(buffer) .expectNext(Arrays.asList(1, 2)) .expectNext(Arrays.asList(3, 4)) .expectNext(Arrays.asList(5, 6)) .expectNext(Arrays.asList(7)) .verifyComplete(); &#125; You can check all available operators here It the next article, I’ll show you how to handel errors while processing data in Mono and Flux. The code for this post is available on my Github account here","categories":[],"tags":[{"name":"Reactive Programming","slug":"Reactive-Programming","permalink":"https://nirajsonawane.github.io/tags/Reactive-Programming/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Project Reactor","slug":"Project-Reactor","permalink":"https://nirajsonawane.github.io/tags/Project-Reactor/"},{"name":"WebFlux","slug":"WebFlux","permalink":"https://nirajsonawane.github.io/tags/WebFlux/"}]},{"title":"Project Reactor [Part 1] - Playing With Flux & Mono","slug":"Project-Reactor-Playing-With-Flux-Mono","date":"2019-12-28T16:11:27.000Z","updated":"2020-01-04T18:07:52.000Z","comments":true,"path":"2019/12/28/Project-Reactor-Playing-With-Flux-Mono/","link":"","permalink":"https://nirajsonawane.github.io/2019/12/28/Project-Reactor-Playing-With-Flux-Mono/","excerpt":"","text":"unsplash-logoDaniil Silantev What is ReactorProject Reactor implements the reactive programming model.It implements the Reactive Streams Specification a standard for building reactive applications.reactor integrates directly with the Java 8 functional APIs, notably CompletableFuture, Stream, and Duration. It offers composable asynchronous sequence APIs — Flux (for [N] elements) and Mono (for [0|1] elements). Key Components of Reactive Manifesto and Reactive Streams SpecificationReactive Streams is an initiative to provide a standard for asynchronous stream processing with non-blocking back pressure. This encompasses efforts aimed at runtime environments (JVM and JavaScript) as well as network protocols. Reactive Specification are based on Reactive Manifesto Reactive Specifications defines below key ContractsPublisher: Representing sources of data also called as Observables.Subscriber: Listening to the Publisher. Subscriber subscribes to publisherSubscription: Publisher will create a subscription for every Subscriber which will try to subscribe to it.Processor: A processor can be used as a publisher as well as subscriber. Processors are used for data transformation. these are set of methods for modifying and composing the data. Objective Of this postObjective of these series of post is to show, How to use Flux &amp; Mono. How to subscribe to them for consuming data. Different operation that we can perform on data while consuming data. I will be using Spring Webflux which internally used Project Reactor Let get started, We need spring-boot-starter-webflux to get started.Project rector also provides very handy library reactor-test for unit testing. The code for this post is available on my Github account here Pom File123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scop&gt;&lt;/dependency&gt; Creating Flux and MonoFlux A Reactive Streams Publisher with rx operators that emits 0 to N elements, and then completes(successfully or with an error). Few Example of creating Flux123456789 Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2, 3);//Create a Flux that emits the provided elements and then completes.Flux&lt;Integer&gt; integerFlux = Flux.fromIterable(Arrays.asList(1, 2, 3));//Create a Flux that emits the items contained in the provided Iterable.Flux.fromStream(Arrays.asList(1,2,3).stream());//Create a Flux that emits the items contained in the provided Stream.Integer[] num2 = &#123;1, 2, 3, 4, 5&#125;;Flux&lt;Integer&gt; integerFluxFromArray = Flux.fromArray(num2);//Create a Flux that emits the items contained in the provided array.Flux.generate(&lt;Consumer&gt;) ;//Programmatically create a Flux by generating signals one-by-one via a consumer callback. Flux.Creare(&lt;Consumer&gt;); //Programmatically create a Flux with the capability of emitting multiple elements in a synchronous or asynchronous manner through the FluxSink API. Mono A Reactive Streams Publisher with basic rx operators that completes successfully by emitting an element, or with an error. Few Examples of creating Mono12345678Mono&lt;Integer&gt; just = Mono.just(1);//Mono&lt;Object&gt; empty = Mono.empty();//Mono.create(); //Create a Mono that completes without emitting any item.Mono.from(&lt;Publisher&gt;)//Expose the specified Publisher with the Mono API, and ensure it will emit 0 or 1 item.//there are multiple options available for creating mono from Callable,CompletionStage,CompletableFuture etc Mono.fromCallable() &#125; Flux &amp; Mono are lazyLazy in context of reactive programming means, No Matter how many operation you do on the stream, They won’t be executed until you consume it. Flux &amp; Mono start emitting values only when subscriber is attached. Creating Subscriber and consuming valuesSubscriber has multiple overloaded methods, let’s check few of them. Subscriber with onNextSubscriber with consumer (onNext)12Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2, 3);fluxFromJust.subscribe(i-&gt;System.out.println(i));//It will print number 1,2,3 Subscriber with onNext &amp; onError. OnError will be get call in case of error.Flux has one handy concatWith which we can use to concat errorSubscriber with consumer and error handler (onError)1234567Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2, 3) .concatWith(Flux.error( new RuntimeException(\"Test Exception\")); fluxFromJust.subscribe( i-&gt;System.out.println(i),// onNext e-&gt;System.out.println(\"In Error Block \" + e.getMessage()) //onError );Subscriber with onNext, onError and onComplete. On Successful completion onComplete method get’s calledSubscriber with consumer, error handler and onComplete12345678Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2, 3) .concatWith(Flux.error( new RuntimeException(\"Test Exception\")); fluxFromJust.subscribe( i-&gt;System.out.println(i),//Will Print 1,2,3 //onNext e-&gt;System.out.println(\"In Error Block \" + e.getMessage())//OnError ()-&gt; System.out.println(\"Process Completed\") //OnComplete ); To Log the activities on Flux / Mono. We can use log method and it will start logging all events.Log Events123Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2, 3) .log() Lets write some Unit test using reactor-testStepVerifier can be use like below to validate the expectationsStepVerifier123456789101112@Test public void testCreateFluxAndSubscribe() &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2, 3).log(); StepVerifier .create(fluxFromJust) .expectNext(1) .expectNext(2) .expectNext(3) .verifyComplete(); &#125;IF You want to verify only count then we can use expectNextCountStepVerifier123456789@Test public void testCreateFluxAndSubscribeVerifyCount() &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1, 2, 3).log(); StepVerifier .create(fluxFromJust) .expectNextCount(3) .verifyComplete(); &#125;To Assert on ErrorStepVerifier123456789@Test public void testCreateFluxAndSubscribeVerifyError() &#123; Flux&lt;Integer&gt; fluxFromJust = Flux.just(1).concatWith(Flux.error(new RuntimeException(\"Test\"))); StepVerifier .create(fluxFromJust) .expectNextCount(1) .verifyError(RuntimeException.class); &#125; It the next article, I’ll show you how to process and transform data in Mono and Flux.The code for this post is available on my Github account here","categories":[],"tags":[{"name":"Reactive Programming","slug":"Reactive-Programming","permalink":"https://nirajsonawane.github.io/tags/Reactive-Programming/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Project Reactor","slug":"Project-Reactor","permalink":"https://nirajsonawane.github.io/tags/Project-Reactor/"},{"name":"WebFlux","slug":"WebFlux","permalink":"https://nirajsonawane.github.io/tags/WebFlux/"}]},{"title":"Testcontainers With Spring Boot For Integration Testing","slug":"Testcontainers-With-Spring-Boot-For-Integration-Testing","date":"2019-12-25T16:25:48.000Z","updated":"2020-01-05T15:37:52.000Z","comments":true,"path":"2019/12/25/Testcontainers-With-Spring-Boot-For-Integration-Testing/","link":"","permalink":"https://nirajsonawane.github.io/2019/12/25/Testcontainers-With-Spring-Boot-For-Integration-Testing/","excerpt":"","text":"Take your Integration Tests to next level using TestcontainersNow days the modern application interacts with multiple systems like database, microservice within system ,external API, middleware systems etc.It’s become very critical for the success of project to have good Integration test strategy.In memory database like H2, HSQLDB are very popular for Integration testing of persistance layer but these are not close to production environment. If application has dependancy on Docker containers, Then it’s become more difficult to test that code in Integration environment. Testcontainers help us to handle these challenges What is Testcontainers?Testcontainers is a Java library that supports JUnit tests, providing lightweight, throwaway instances of common databases, Selenium web browsers, or anything else that can run in a Docker container. The code for this post is available on my Github account here Let’s Write some Integration Test using Testcontainers For Spring Boot AppIn previous Post We created simple Spring Boot application that uses Mongodb Database (containrized) let’s write integration test for that. It’s easy to add Testcontainers to your project - let’s walk through a quick example to see how. Add Testcontainer to projectPom File123456789101112&lt;dependency&gt; &lt;groupId&gt;org.testcontainers&lt;/groupId&gt; &lt;artifactId&gt;testcontainers&lt;/artifactId&gt; &lt;version&gt;1.12.3&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.testcontainers&lt;/groupId&gt; &lt;artifactId&gt;junit-jupiter&lt;/artifactId&gt; &lt;version&gt;1.12.3&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; Creating a generic container based on an imageFor Mongodb there is no special test container image available, But we can create one by extending GenericContainerMongoDbContainer12345678910111213141516public class MongoDbContainer extends GenericContainer&lt;MongoDbContainer&gt; &#123; public static final int MONGODB_PORT = 27017; public static final String DEFAULT_IMAGE_AND_TAG = \"mongo:3.2.4\"; public MongoDbContainer() &#123; this(DEFAULT_IMAGE_AND_TAG); &#125; public MongoDbContainer(@NotNull String image) &#123; super(image); addExposedPort(MONGODB_PORT); &#125; @NotNull public Integer getPort() &#123; return getMappedPort(MONGODB_PORT); &#125; &#125;You can also create generic container using ClassRule1234@ClassRule public static GenericContainer mongo = new GenericContainer(\"mongo:3.2.4\") .withExposedPorts(27017); Starting the container and using it in testMongoDbContainerTest123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@SpringBootTest@AutoConfigureMockMvc@ContextConfiguration(initializers = MongoDbContainerTest.MongoDbInitializer.class)@Slf4jpublic class MongoDbContainerTest &#123; @Autowired private MockMvc mockMvc; @Autowired private ObjectMapper objectMapper; @Autowired private FruitRepository fruitRepository; private static MongoDbContainer mongoDbContainer; @BeforeAll public static void startContainerAndPublicPortIsAvailable() &#123; mongoDbContainer = new MongoDbContainer(); mongoDbContainer.start(); &#125; @Test public void containerStartsAndPublicPortIsAvailable() throws Exception &#123; FruitModel build = FruitModel.builder().color(\"Red\").name(\"banana\").build(); mockMvc.perform(post(\"/fruits\") .contentType(\"application/json\") .content(objectMapper.writeValueAsString(build))) .andExpect(status().isCreated()); Assert.assertEquals(1, fruitRepository.findAll().size()); &#125; public static class MongoDbInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123; @Override public void initialize(ConfigurableApplicationContext configurableApplicationContext) &#123; log.info(\"Overriding Spring Properties for mongodb !!!!!!!!!\"); TestPropertyValues values = TestPropertyValues.of( \"spring.data.mongodb.host=\" + mongoDbContainer.getContainerIpAddress(), \"spring.data.mongodb.port=\" + mongoDbContainer.getPort() ); values.applyTo(configurableApplicationContext); &#125; &#125; &#125;&#125; lets see what we are doing in test line by line.@SpringBootTest As we want to write Integration test we are using @SpringBootTest which tells Spring to load complete application context. @AutoConfigureMockMvc configure auto-configuration of MockMvc. As we want to testcontroller-&gt;service-&gt;repository -&gt;database @ContextConfiguration Overriding Spring properties. We need to override host and port on which mongodb testcontainer has started. Starting Mongodb container in BeforeAll hook so that DB instance is available during the test.Then In test we are simpaly calling post method on controller and after that checking if actually data is getting inserted in database or not. Using Predefined TestcontainerThere are some predefined Testcontainer are available, Which are very useful and easy to usee.g MySQLContainer is available for mysql database. let’s see how to use thatMySQLContainerTest123456789101112@Testcontainerspublic class MySQLContainerTest &#123; @Container private final MySQLContainer mySQLContainer = new MySQLContainer(); @Test @DisplayName(\"Should start the container\") public void test() &#123; Assert.assertTrue(mySQLContainer.isRunning()); &#125;&#125; To use the Testcontainers extension annotate your test class with @Testcontainers. Note You need to think about how you want to use container Containers that are restarted for every test method Containers that are shared between all methods of a test class If you define Container like this@Container private MySQLContainer mySQLContainer = new MySQLContainer(); Then it will create new instance for each test case and it you use static like this@Container private static MySQLContainer mySQLContainer = new MySQLContainer(); then same Instance will be used for all tests. The code for this post is available on my Github account here","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Mongodb","slug":"Mongodb","permalink":"https://nirajsonawane.github.io/tags/Mongodb/"},{"name":"Docker","slug":"Docker","permalink":"https://nirajsonawane.github.io/tags/Docker/"},{"name":"testcontainers","slug":"testcontainers","permalink":"https://nirajsonawane.github.io/tags/testcontainers/"},{"name":"containers","slug":"containers","permalink":"https://nirajsonawane.github.io/tags/containers/"}]},{"title":"Spring Boot + Mongodb + Docker Compose","slug":"Spring-Boot-Mongodb-Docker-Compose","date":"2019-12-16T04:40:00.000Z","updated":"2019-12-19T21:11:32.000Z","comments":true,"path":"2019/12/16/Spring-Boot-Mongodb-Docker-Compose/","link":"","permalink":"https://nirajsonawane.github.io/2019/12/16/Spring-Boot-Mongodb-Docker-Compose/","excerpt":"","text":"unsplash-logoGabriel BarlettaIn this post we will discuss how to use Docker Compose to define and run multi-container Docker applications.The code for this post is available on my Github account here PrerequisitesTo Follow along this post basic knowledge of Docker, Container &amp; Spring Boot is Needed. docker and docker-compose should be install on your system. Docker ComposeDocker Compose is a tool for defining and running multi-container Docker applications. We define and configure all the services used in application in single file called as “docker-compose.yml” More details about docker compose can be found in documentation. Docker compose helps and reduces lot of overhead of managing apps that has dependancy on multiple containers.Docker compose significantly improves productivity as we can run complete application stack using single command. Docker compose runs all the containers on a single host by default. Docker Compose in ActionI will create simple hypothetical application that will expose rest endpoint to manage fruit information. Application is build using two containers. I will use docker compose to run this multi-container application. Spring Boot APPCreate very Spring Spring boot application using Spring initializr use below dependency. spring-boot-starter-web,spring-boot-starter-actuator,lombok and you should be able to run the application.Check http://localhost:8080/actuator/health point is returning status as “UP” Dokcrizeing spring boot appDockerizing Spring Boot app is very straightforward,below is sample Dockerfile file.12345FROM openjdk:8-jdk-alpineVOLUME /tmpARG JAR_FILE=target/*.jarCOPY $&#123;JAR_FILE&#125; app.jarENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;] Creating Docker Imagedocker build -t api-docker-image .Run above command to create docker image. There are maven plugins available for creating docker image during maven build. for simplicity i am using simple docker command to create image. Running Docker Imagedocker run -d -p 9090:8080 api-docker-imagewe are mapping 8080 container port to 9090 host machine port means the application will be available on host machine on port 9090. Now Spring boot application is running on docker and will be available onhttp://localhost:9090/actuator/health Now let’s add mongodbAdd below dependancy in pom file Pom File1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt; Rest endpoints to save and get Fruit information.Rest Controller1234567891011121314151617181920@RestController@Slf4jpublic class FruitController &#123; private final FruitService fruitService; public FruitController(FruitService fruitService) &#123;this.fruitService = fruitService;&#125; @PostMapping(\"/fruits\") public ResponseEntity addFruit(@RequestBody FruitRequest fruitRequest) &#123; log.info(\"Request : &#123;&#125;\", fruitRequest); fruitService.saveFruit(fruitRequest.toFruitModel()); return ResponseEntity.status(HttpStatus.CREATED).build(); &#125; @GetMapping(\"/fruits\") public List&lt;FruitModel&gt; getAllFruit() &#123; return fruitService.findAll(); &#125;&#125;&#125; Simple JPA MongoRepository for saving and getting data to/from mongodbJPA Repository & Fruit JPA Model123456789101112131415@Componentpublic interface FruitRepository extends MongoRepository&lt;FruitModel ,String&gt; &#123;&#125;@Document@Data@Builderpublic class FruitModel &#123; @Id private String id; private String name; private String color; &#125;&#125; Now we want to run mongodb database as separate container and spring boot app as separate container application. We can do this manually by running docker commands, But that’s very tedious task and lot of configurations needed for containers to talk to each other. docker compose simplifies these things for us Define services in a Compose fileWe Create a file called docker-compose.yml and starts defining all the containers needed for application as services.in below docker compose file we are defining two services one is for database and one for rest-api and we do all the needed configuration at single place. As our spring boot app (api) is dependent on database we are specifying that as link. There are lof configuration we can do in docker compose file. docker-compose123456789101112131415version: \"3\"services: api-database: image: mongo:3.2.4 container_name: \"api-database\" ports: - 27017:27017 command: --smallfiles api: image: api-docker-image ports: - 9091:8080 links: - api-database&#125; Configure mongodb host name using spring config property using service name defined in docker-compose.docker-compose1spring.data.mongodb.host=api-database Running Docker Composedocker-compose up single command is needed to start the application. command will create one container for database and one for spring-boot app as defined in docker-compose file. Summary Using Compose is basically a three-step process: Define your app’s environment with a Dockerfile so it can be reproduced anywhere. Define the services that make up your app in docker-compose.yml so they can be run together in an isolated environment. Run docker-compose up and Compose starts and runs your entire app. The code for this post is available on my Github account here","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Mongodb","slug":"Mongodb","permalink":"https://nirajsonawane.github.io/tags/Mongodb/"},{"name":"Docker","slug":"Docker","permalink":"https://nirajsonawane.github.io/tags/Docker/"}]},{"title":"Creating Custom Spring Boot Starter To Implement Cross-Cutting Concerns","slug":"Creating-Custom-Spring-Boot-Starter-To-implement-cross-cutting-concerns","date":"2019-10-21T14:29:52.000Z","updated":"2019-11-08T02:51:04.000Z","comments":true,"path":"2019/10/21/Creating-Custom-Spring-Boot-Starter-To-implement-cross-cutting-concerns/","link":"","permalink":"https://nirajsonawane.github.io/2019/10/21/Creating-Custom-Spring-Boot-Starter-To-implement-cross-cutting-concerns/","excerpt":"","text":"Now days Spring Boot has become de facto standard for numerous Web enterprise developments. Spring Boot helps to improve developer’s productivity by implementing lot of cross-cutting concerns as Starter Projects. We Just add these dependancy in our projects or configure few properties and Spring Boot does the magic for us by doing autoconfiguration. The starters projects automatically configure lof of stuff for us. This helps us to get started more quickly.However, With a lof magic happening in background, it’s very Important to know How things work. The code for this post is available for download here. How Spring Boot’s Starter WorksOn Startup, Spring Boot checks for spring.factories file. This file is located in the META-INF directory.12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ns.aop.LogMethodExecutionTimeAutoConfiguration All the classes with @Configuration should list under EnableAutoConfiguration key in the spring.factories file.Spring Will create Beans Based on configuration and Conditions defined in Configurations files. We will see this in detail with example. Let’s Create Library That logs Method Execution Timelets imagine, We want to log the method execution time for few methods in our project. We should be able to enable/disable this feature based on some property. Creating Our Custom Spring Boot Starter ProjectCreate Spring Boot Project with Below dependencies.Pom File1234567891011121314151617181920212223242526&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.boot.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; spring-boot-dependencies allows us to use any Spring dependency.spring-boot-autoconfigure for using autoconfigure featurespring-boot-configuration-processor to generate metadata for our configuration properties. IDEs can give us autocomplete. Use AOP to log method execution timeCreate simple annotation LogMethodExecutionTime to be used on method and aspect to log time. Annotation & Aspect1234567891011121314151617@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface LogMethodExecutionTime &#123;&#125; @Aspect@Slf4jpublic class LogMethodExecutionTimeAspect &#123; @Around(\"@annotation(LogMethodExecutionTime)\") public Object logExecutionTime(ProceedingJoinPoint joinPoint) throws Throwable &#123; final long start = System.currentTimeMillis(); final Object proceed = joinPoint.proceed(); final long executionTime = System.currentTimeMillis() - start; log.info(joinPoint.getSignature() + \" executed in \" + executionTime + \"ms\"); return proceed; &#125;&#125; Creating Our Own AutoconfigurationWe want to control the Method Execution Time logging to be enable based on certain properties. Spring provides lot of @Conditional annotations.Based on different conditions we can control Configurations of starter projects. For this example we can use ConditionalOnProperty.our starter will be activated only if logging.api.enabled property is present and has value trueConfiguration For our Starter12345678@Configuration@ConditionalOnProperty(name = \"logging.api.enabled\", havingValue = \"true\", matchIfMissing = true)public class LogMethodExecutionTimeAutoConfiguration &#123; @Bean public LogMethodExecutionTimeAspect getLogMethodExecutionTimeAspect()&#123; return new LogMethodExecutionTimeAspect(); &#125;&#125; spring.factories FileWe need to create special file called as spring.factories. Our custom starter to be pick by Spring boot, we have to create spring.factories. This file should be placed within the src/main/resources/META-INF folder. This file has list of all classes annotated with @Configuration.12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ns.aop.LogMethodExecutionTimeAutoConfiguration Note Naming ConventionYou should make sure to provide a proper namespace for your starter. Do not start your module names with spring-boot, even if you use a different Maven groupId.As a rule of thumb, you should name a combined module after the starter. For example, assume that you are creating a starter for “acme” and that you name the auto-configure module acme-spring-boot-autoconfigure and the starter acme-spring-boot-starter. If you only have one module that combines the two, name it acme-spring-boot-starter. Using the custom starterLet’s create a sample Spring Boot application client to use our custom starter.Client12345678910111213141516171819202122232425262728293031&lt;dependency&gt; &lt;groupId&gt;ns&lt;/groupId&gt; &lt;artifactId&gt;method-execution-time-logging-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;// define below property logging.api.enabled=true//Main Class@SpringBootApplicationpublic class ClientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ClientApplication.class, args); &#125; @Bean ApplicationRunner init(TestClass testClass) &#123; return (ApplicationArguments args) -&gt; dataSetup(testClass); &#125; private void dataSetup(TestClass testClass) throws InterruptedException &#123; testClass.run(); &#125;&#125;//Test Class@Componentpublic class TestClass &#123; @LogMethodExecutionTime public void run() throws InterruptedException &#123; Thread.sleep(3000); &#125;&#125; The code for this post is available for download here.","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Spring Boot Starter","slug":"Spring-Boot-Starter","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot-Starter/"},{"name":"AOP","slug":"AOP","permalink":"https://nirajsonawane.github.io/tags/AOP/"}]},{"title":"My AWS Solutions Architect Associate Certification Preparation Guide","slug":"My-AWS-Certified-Solutions-Architect-Associate-Certification-Preparation-Guide","date":"2019-09-13T05:53:58.000Z","updated":"2019-09-26T16:23:02.000Z","comments":true,"path":"2019/09/13/My-AWS-Certified-Solutions-Architect-Associate-Certification-Preparation-Guide/","link":"","permalink":"https://nirajsonawane.github.io/2019/09/13/My-AWS-Certified-Solutions-Architect-Associate-Certification-Preparation-Guide/","excerpt":"","text":"unsplash-logoBen White I Recently [September 2019 ] Completed AWS Architect Associate Certification in First Attempt with score of 89%. I want to share my experience and exam preparation tips with you. My Background about AWS and Cloud TechnologiesI had No prior AWS experience or knowledge. But I had previous work experience in Other IaaS Platform. I was well aware about the most of the cloud concepts covered in Exam. It was easy for me to relate the problem and Pain point Any AWS Service was trying to Solve. I think this is very important to understand any AWS Service and motivation behind creating such service. This helped me to understand bigger picture. Preparation TimelineAWS suggest you should have minimum One year of working experience on AWS Platform but it’s not mandatory. When i did my research, Most of the people recommending at lest Three to Four months of study (2 -3 hrs everyday). It’s obvious we cannot generalize this. It depends on individual. Please take your time to study and do not rush and Book the Exam. Give yourself enough time The platform has more than 140 different services and new services are launching every day. It can be very overwhelming and time consuming trying to understand Services. Architect Associate exam does not cover all Services but it still covers lot.I Personally made mistake by booking exam in advance, Giving myself only three weeks of time for preparation along with my Office work of 8-9 hrs. For last few days i have to push myself to cover all services. Preparation ResourcesI Use Udemy Platform for my regular study, For AWS I took below courses from Udemy. AWS Certified Solutions Architect - Associate 2019. By Ryan Kroonenburg, Faye EllisThis is one of the most popular course for CSAA Certification. Content of course is very good and up to date. I will surely recommend this course.I have rated this course as 4.5 Star on Udemy Ultimate AWS Certified Solutions Architect Associate 2019 by Stephane MaarekThis is also another very good course. This course provide more details and hands on compare to Ryan course. This was my primary source for preparation.I will definitely recommend this course. I have rated this course as 5 Star on Udemy **I would Suggest do not rely on any Single Course. Complete at lest two courses of your choice. Practice ExamsPractice Exams are equally Important. I Used below two practice exams. All Exam questions are scenario based, So it’s become very important to prepare your self for such questions. Both the below Practice Exams includes 6 Practice Tests and quality of question is also good. Real Exam also has similar (But Not exact same) questions. I have rated both these course as 5 Star on Udemy You might not do well in these practice exams. Read the explanation about the answers and repeat the the test again. Due to limited time i was not able to repeat the test. AWS Certified Solutions Architect Associate Practice Exams by Neal Davis, Digital Cloud TrainingMy First Attempt Scores in Test exams 46%,49%,60%,76%,53%,63%. I Was able to pass only 1 Test in my First Attempt AWS Certified Solutions Architect Associate Practice Exams By by Jon Bonso, Tutorials DojoMy First Attempt Scores in Test exams 75%,75%,68%,80%,86%,75%. I took these test at last. FAQ &amp; WhitepaperIt is Suggested that You should go through FAQ and White Papers before appearing to exam. I haven’t got time to read any White Papers or FAQ Preparation And Exam TipsThese are not some magical Tips and you must be knowing most of these. Just make sure you check all the boxes. Hands on using Free tier Do not start you preparation considering exam in mind. Do hands on whenever possible and consider it as you are implementing it for any enterprise level application. Exam will test you for such scenario only. Taking Note Start taking your notes as soon as possible. Exam covers lot of topics and it’s difficult to remember all stuff. Video tutorial needs lot of time and you might not able to repeat. Read questions carefully and Take your Time to Understand it Most of the questions are Descriptive and are up to 3 lines . Try to Find Keywords like Cost effective,Manage Service, Minimum Configurations,Availability, Durability etc Keywords will help to select Most appropriate Option. First Try to Eliminate Wrong Answer rather than finding correct one VPC is Very ImportantVPC is very important from Exam point of view and i got lot of question about VPC.You need to understand which service should be in a public subnet versus a private subnets And How Services deployed in Private subnets can interact with Internet and other services. Disaster recoveryDisaster recovery also covers good portion of exam. Try to Understand and memorize how each services works in case of failure, And How to configure services for Disaster recovery.E.g Does the service backups data, Where it copies, is it automatic or we need to configure it, How failover works etc. Reality Check After CertificationDoes it mean I am now great cloud architect after Certification? Of course not :)The real word Enterprise application Brings lof of complexity and different unknown challenges and No exam can test these scenarios. It’s very important to keep ourself updated with stuff happening around technology space. Any Certification can give me an edge over other candidates While getting job or Can Help me to get better salary But it does not guarantee that I Will be able to solve the Problem. I want to become good software architect and getting any such certification is Just the one Step Forward. Please let me know about your AWS Exam experience and Any tips that you want to share.","categories":[],"tags":[{"name":"AWS","slug":"AWS","permalink":"https://nirajsonawane.github.io/tags/AWS/"}]},{"title":"Securing Spring Boot Microservices Using JWT Token","slug":"Securing-Spring-Boot-Microservices-Using-JWT-Token","date":"2019-07-14T18:36:35.000Z","updated":"2019-07-15T02:02:58.000Z","comments":true,"path":"2019/07/14/Securing-Spring-Boot-Microservices-Using-JWT-Token/","link":"","permalink":"https://nirajsonawane.github.io/2019/07/14/Securing-Spring-Boot-Microservices-Using-JWT-Token/","excerpt":"","text":"unsplash-logoJR KorpaIn Last few articles, We Discuss Different aspects of Microservices. In this post we will add Security to our rest services using Json Web Token And Spring SecurityThere are multiple options available for adding Authentication and Authorization, Today we will be focusing on JSON Web Tokens, or JWT in short. What Is JSON Web Tokens (JWT)?JSON Web Tokens are an open, industry standard RFC 7519 method for representing claims securely between two parties. JWT Token has three Parts Header, Payload &amp; Signature Header of the JWT contains information about how the JWT signature should be computed. Header contains information about type and hashing algorithm used.Header1234&#123; \"alg\": \"HS256\", \"typ\": \"JWT\"&#125;Payload contains the data also referred as claims. The Internet drafts define the certain standard fields (“claims”) that can be used inside a JWT claim set. Such as Issuer, Subject, Issued at, JWT ID etc You can Find full list Here. We Can also pass other needed information using private claims.Payload123456&#123; \"sub\": \"1234567890\", \"name\": \"John Doe\", \"iat\": 1516239022, \"Roles\":\"Admin\"&#125; Signature Make sure that the token is not changed on the way. Signature is created by taking the header and payload together and passing it through the specified algorithm along with a known secret. For More Details about JWT Please check jwt.io The code for this post is available for download here. Sample Application Using JWT And Spring SecurityAn overview of the security mechanism that we will be using in our sample application. Client will call Authenticate Endpoint by providing valid Username and Password to get The TokenClients will send this JWT token in the Authorization header for all the requests to access any protected resources. For Valid Tokens, Access will be granted to resources.In Case of missing Token or invalid token, Response code 401 unauthorized will be return. We will also Add Role Base Authentication. Student Endpoint Will be accessible to Users having ADMIN or USER roles. And Subject Endpoint will be accessible to Users having ADMIN roles. This Will be long post, So I divided it into multiple Steps. Github repo has Branch corresponding to each Step Step 1: Create Spring Boot Rest EndpointsCreate Two Simple Rest endpoints For Our Student and Subject Domain objects. User Login Details are saved in User table using User Entity. Setting Up Things For playing with jWT12345678910111213141516171819202122232425262728//Student Resource@RestController@RequestMapping(\"/Student\")public class StudentResource &#123;private final StudentRepository studentRepository; public StudentResource(StudentRepository studentRepository) &#123; this.studentRepository=studentRepository; &#125; @GetMapping public List&lt;Student&gt; getAllStudents()&#123; return studentRepository.findAll(); &#125;&#125;//Subject Resource@RestController@RequestMapping(\"/Subject\")public class SubjectResource &#123; private final SubjectRepository subjectRepository; public SubjectResource(SubjectRepository subjectRepository) &#123; this.subjectRepository = subjectRepository; &#125; @GetMapping public List&lt;Subject&gt; getAllSubjects()&#123; return subjectRepository.findAll(); &#125;&#125; Add User Entity to Store userId &amp; password in in-memory database. Password are stored in BCrypt encrypted Format Setting Up Things For playing with jWT123456789101112@Entity@Data@AllArgsConstructor@NoArgsConstructor@ToStringpublic class User &#123; @Id private String email; private String password; private String role;&#125;&#125; Populate Database during application Startup using ApplicationRunnerSetting Up Things For playing with jWT12345678910111213141516171819202122232425262728@SpringBootApplicationpublic class GwtTokenApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GwtTokenApplication.class, args); &#125; @Bean ApplicationRunner init(UserRepository userRepository, StudentRepository studentRepository, SubjectRepository subjectRepository) &#123; return (ApplicationArguments args) -&gt; dataSetup(userRepository,studentRepository,subjectRepository); &#125; private void dataSetup(UserRepository userRepository, StudentRepository studentRepository, SubjectRepository subjectRepository) &#123; User niraj = new User(\"niraj.sonawane@gmail.com\", \"$2a$10$yRxRYK/s8vZCp.bgmZsD/uXmHjekuPU/duM0iPZw04ddt1ID9H7kK\", \"Admin\"); User test = new User(\"test@gmail.com\", \"$2a$10$YWDqYU0XJwwBogVycbfPFOnzU7vsG/XvAyQlrN34G/oA1SbhRW.W.\", \"User\"); userRepository.save(niraj); userRepository.save(test); Student student1 = new Student(1L,\"Ram\"); Student student2 = new Student(2L,\"Sham\"); studentRepository.save(student1); studentRepository.save(student2); Subject math = new Subject(1l,\"Math\"); Subject science = new Subject(2l,\"Science\"); subjectRepository.save(math); subjectRepository.save(science); &#125;&#125;At This point, We have Setup Two Reset endpoints and User Table to Store UserID and Password. Step 2: Add Authentication Endpoint To Return JWT Token and Secure All Other EndpointStudent and Subject endpoints should be accessible only if Valid token is provided. Authenticate endpoint Should be accessible to everyone.SecurityConfig123456789101112131415161718192021222324252627282930313233343536@Configuration@EnableWebSecuritypublic class SecurityConfig extends WebSecurityConfigurerAdapter&#123; @Autowired private UserAuthDetailsService userAuthDetailsService; @Autowired private InvalidLoginAttemptHandler invalidLoginAttemptHandler; @Override public void configure(AuthenticationManagerBuilder authenticationManagerBuilder) throws Exception &#123; authenticationManagerBuilder.userDetailsService(userAuthDetailsService) .passwordEncoder(passwordEncoder()); &#125; @Bean public PasswordEncoder passwordEncoder() &#123; return new BCryptPasswordEncoder(); &#125; @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception &#123; return super.authenticationManagerBean(); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; http .cors().and().csrf().disable() .exceptionHandling().authenticationEntryPoint(invalidLoginAttemptHandler) .and() .authorizeRequests() .antMatchers(\"/authenticate/**\") .permitAll() .anyRequest().authenticated(); &#125;&#125;lets discuss, What Configurations we have done here. @EnableWebSecurity This is main Spring annotation that is used to enable web security in a project. WebSecurityConfigurerAdapter This class provides default security configurations and allows other classes to extend it and customize the security configurations by overriding its methods. UserAuthDetailsService - This class is needed by Spring security to get the user details from Database, LDAP or other other user store.UserAuthDetailsService Service loads the user details from our User Table. AuthenticationManager This class uses UserAuthDetailsService to do user Authentication. InvalidLoginAttemptHandler This class is responsible for taking action if Authentication fails. .antMatchers(&quot;/authenticate/**&quot;).permitAll().anyRequest().authenticated() This Configuration allows any user to access our authenticate endpoint and all other Request need to be authenticated. Authenticate User and Create JWT TokenAuthResource1234567891011121314151617@RestController@RequestMapping(\"/authenticate\")@Slf4jpublic class AuthResource &#123; @Autowired private AuthenticationManager authenticationManager; @Autowired private JWTTokenProvider jwtTokenProvider; @PostMapping public ResponseEntity authenticateUser(@RequestBody AuthenticateRequest authenticateRequest) &#123; Authentication authentication = authenticationManager.authenticate(new UsernamePasswordAuthenticationToken(authenticateRequest.getUserName(), authenticateRequest.getPassword())); String token =jwtTokenProvider.generateToken((UserPrincipal)authentication.getPrincipal()); log.info(\"Token Created &#123;&#125;\",token); return ResponseEntity.ok(new JwtAuthenticationResponse(token)); &#125;&#125; JWTTokenProvider12345678910111213141516171819202122@Componentpublic class JWTTokenProvider &#123; @Value(\"$&#123;jwt.secret&#125;\") private String jwtSecret; @Value(\"$&#123;jwt.expirationInMs&#125;\") private int jwtExpirationInMs; public String generateToken(UserPrincipal userPrincipal)&#123; List&lt;String&gt; roles = userPrincipal .getAuthorities() .stream() .map(GrantedAuthority::getAuthority) .collect(Collectors.toList()); return Jwts.builder().setIssuer(\"Demo App\") .setIssuedAt(new Date()) .setExpiration(new Date(new Date().getTime() + jwtExpirationInMs)) .claim(\"Roles\",roles) .signWith(SignatureAlgorithm.HS512,jwtSecret).compact(); &#125;&#125; After successful authentication of User we create JWT Token using jsonwebtoken library. jsonwebtoken provides fluent api to create JWT Token.We are Adding Roles in Claim. We Can Use these role for role based authorization.In Case authentication fails, InvalidLoginAttemptHandler Will be called which we have configured in exceptionHandling section of our SecurityConfig. Now If we Call authenticate endpoints with Valid userid and password, JWT Token will send back in Response. curl -X POST http://localhost:8080/authenticate -H &quot;Content-Type:application/json&quot; -d &quot;{\\&quot;userName\\&quot;:\\&quot;niraj.sonawane@gmail.com\\&quot;,\\&quot;password\\&quot;:\\&quot;test\\&quot;}&quot; Step 3: Add AuthenticationFilter To Get JWT token from the request and Validate ItAfter receiving jwt token, Clients Need to pass this token in Authorization header to access the protected resource, in our case student or subject resource.Sample curl for samecurl12curl -X GET http://localhost:8080/Subject -H &quot;Authorization: Bearer eyJhbGciOiJIUzUxMiJ9.eyJpc3MiOiJEZW1vIEFwcCIsInN1YiI6InRlc3RAZ21haWwuY29tIiwiaWF0IjoxNTYzMTAwODk2LCJleHAiOjE1NjMxNTA4OTYsIlJvbGVzIjpbIlJPTEVfVVNFUiJdfQ.XSUpdBhRkXL0b1U5gD0y-siCrSMMzQaJupV4bJOTnAA7txYmDNTZ8O18ueCG72K7XdwueLZGXWX5C2NtCWghaA&quot;&#125; JwtAuthenticationFilter Filter will be called OncePerRequest and will validate the provided token. After Successful Validation of Token We need to pass on UsernamePasswordAuthenticationToken to filter chain using SecurityContextHolderJwtAuthenticationFilter123456789101112131415161718192021222324252627282930public class JwtAuthenticationFilter extends OncePerRequestFilter &#123; @Autowired private JWTTokenProvider tokenProvider; @Autowired private UserAuthDetailsService userDetailsService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException &#123; logger.info(\"Validating Token!!!!!\"); try &#123; String jwt = getJwtFromRequest(request); if (StringUtils.hasText(jwt) &amp;&amp; tokenProvider.validateToken(jwt)) &#123; logger.info(\"Token is Valid \"); String userNameFromToken = tokenProvider.getUserNameFromToken(jwt); UserPrincipal userDetails = userDetailsService.loadUserByUsername(userNameFromToken); UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(userDetails, null, userDetails.getAuthorities()); SecurityContextHolder.getContext().setAuthentication(authentication); &#125; &#125; catch (Exception ex) &#123; logger.error(\"Could not set user authentication in security context\", ex); &#125; filterChain.doFilter(request, response); &#125; private String getJwtFromRequest(HttpServletRequest request) &#123; String bearerToken = request.getHeader(\"Authorization\"); if (StringUtils.hasText(bearerToken) &amp;&amp; bearerToken.startsWith(\"Bearer \")) &#123; return bearerToken.substring(7, bearerToken.length()); &#125; return null; &#125;&#125; Token Can be validated like this Jwts.parser().setSigningKey(jwtSecret).parseClaimsJws(jwt) At This point, We are able to Create JWT Token for valid Users. And able to provide access to protected resources based on token. lets go one step further and use roles to grant access at granular level. Step 4: Role Based Access lets Say we want Student Endpoint to be accessible to Users having ADMIN or USER roles. And Subject Endpoint to be accessible to Users having ADMIN role. In order to use method level security, we need to enable this in the security configuration using @EnableGlobalMethodSecurity. Configuration12345678@Configuration@EnableGlobalMethodSecurity( prePostEnabled = true, securedEnabled = true, jsr250Enabled = true)public class MethodSecurityConfig extends GlobalMethodSecurityConfiguration &#123;&#125; The annotations @PreAuthorize and @PostAuthorize support Spring Expression Language (SpEL) and provide expression-based access control.Note: The Roles In Database need to saved with Prefix as ROLE_StudentResource12345678910111213141516@RestController@RequestMapping(\"/Student\")public class StudentResource &#123;private final StudentRepository studentRepository; public StudentResource(StudentRepository studentRepository) &#123; this.studentRepository=studentRepository; &#125; @GetMapping @PreAuthorize(\"hasRole('ADMIN') OR hasRole('USER')\") public List&lt;Student&gt; getAllStudents()&#123; return studentRepository.findAll(); &#125;&#125; SubjectResource123456789101112131415@RestController@RequestMapping(\"/Subject\")public class SubjectResource &#123; private final SubjectRepository subjectRepository; public SubjectResource(SubjectRepository subjectRepository) &#123; this.subjectRepository = subjectRepository; &#125; @GetMapping @PreAuthorize(\"hasRole('ADMIN')\") public List&lt;Subject&gt; getAllSubjects()&#123; return subjectRepository.findAll(); &#125;&#125; The code for this post is available for download here.","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Microservice","slug":"Microservice","permalink":"https://nirajsonawane.github.io/tags/Microservice/"},{"name":"JWT","slug":"JWT","permalink":"https://nirajsonawane.github.io/tags/JWT/"},{"name":"Spring Security","slug":"Spring-Security","permalink":"https://nirajsonawane.github.io/tags/Spring-Security/"}]},{"title":"Setup Monitoring System for your Spring Boot applications Using Spring Boot Admin","slug":"Setup-Monitoring-System-for-your-Spring-Boot-applications-Using-Spring-Boot-Admin","date":"2019-06-08T09:13:22.000Z","updated":"2019-06-10T03:08:56.000Z","comments":true,"path":"2019/06/08/Setup-Monitoring-System-for-your-Spring-Boot-applications-Using-Spring-Boot-Admin/","link":"","permalink":"https://nirajsonawane.github.io/2019/06/08/Setup-Monitoring-System-for-your-Spring-Boot-applications-Using-Spring-Boot-Admin/","excerpt":"","text":"unsplash-logoZdeněk Macháček In past few microservices articles, We discuss different Spring Cloud features.In microservices architecture we have lot of services doing small small tasks. Monitoring all these application becomes very critical and integral part of your technology stack.Spring Boot Admin is Community project provides an admin interface for Spring Boot applications.let check how we can setup and use Spring Boot Admin. The code for this post is available for download here. Setting Up Spring Boot Admin ServerTo Add admin server in project we need to add below spring boot starter dependancy spring boot admin starter server1234 &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt;&lt;/dependency&gt; Add @EnableAdminServer on Main Application.Admin Main Class12345678@SpringBootApplication@EnableAdminServerpublic class SpringBootAdminServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootAdminServerApplication.class, args); &#125;&#125;Now if we Start the application, the admin UI should be available Register clients with admin ServerEach application that wants to register has to include the Spring Boot Admin Client dependancy.Client1234 &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt;&lt;/dependency&gt; And add Admin.client url in application.propertiesspring.boot.admin.client.url=http://localhost:8080/Spring Boot Admin will use spring.application.name property to display the name of application. Your browser does not support the video tag. Our application is registered on Admin Consol, But apart for Status no other information is available Magic of Spring Boot Actuator and Spring Boot Admin Server Spring Boot Admin depends on Actuators endpoints to provide information. let’s enable Actuator endpoints. put below in client application. management.endpoints.web.exposure.include=* Note, Expose only needed endpoints. Your browser does not support the video tag. Tips and tricksDisplay Build InfoTo Display Build Info, Simply add build-info Goal in spring-boot-maven-plugin pluginBuild Info123456789101112131415 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;build-info&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; Display Git Commit infoTo know which commit id is deployed, We can simply use git-commit-id-plugin, git information will be available in info endpoint and will be displayed on admin ui.Build Info12345678910111213141516171819 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;build-info&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;pl.project13.maven&lt;/groupId&gt; &lt;artifactId&gt;git-commit-id-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;LogsBy default the log file is not accessible via actuator endpoints and therefore not visible in Spring Boot Admin. In order to enable the logfile actuator endpoint you need to configure Spring Boot to write a logfile, either by setting logging.path or logging.file.Add below property in Client application.logging.file=target/sample-boot-application.logAt run time we can also change the logs level, Which is useful in lower environments.Multiple InstanceAdmin Will Automatically Group applications based on application names and will show consolidated view.TagsTags are a way to add visual markers per instance, they will appear in the application list as well as in the instance view.spring.boot.admin.client.instance.metadata.tags.environment=QA Your browser does not support the video tag. NotificationBy default Spring Boot Admin will send registered application changes to DOWN or OFFLINE. We can do lot of customizations for Notifications.Below is configurations for sending emails using google smpt server.Use spring-boot-starter-mail dependancy in admin.Email Config in Admin123456spring.mail.host=smtp.gmail.comspring.mail.port=587spring.mail.username=XYZ@gmail.comspring.mail.password=XYZspring.boot.admin.notify.mail.to=XYZspring.mail.properties.mail.smtp.starttls.enable=true Discovery ClientsThe Spring Boot Admin Server can use Spring Clouds DiscoveryClient to discover applications. The advantage is that the clients don’t have to include the spring-boot-admin-starter-client. You just have to add a DiscoveryClient implementation to your admin server - everything else is done by AutoConfiguration. SecurityAs Admin Server is an spring boot application, Securing admin server is same as securing normal spring boot application. ReferenceDocumentationThe code for this post is available for download here.","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/tags/Spring-Cloud/"},{"name":"Microservice","slug":"Microservice","permalink":"https://nirajsonawane.github.io/tags/Microservice/"},{"name":"Spring Boot Admin","slug":"Spring-Boot-Admin","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot-Admin/"}]},{"title":"Service Discovery and Registration Using Spring Cloud Eureka","slug":"Service-Discovery-and-Registration-Using-Spring-Cloud-Eureka","date":"2019-04-20T12:37:32.000Z","updated":"2019-05-01T17:10:12.000Z","comments":true,"path":"2019/04/20/Service-Discovery-and-Registration-Using-Spring-Cloud-Eureka/","link":"","permalink":"https://nirajsonawane.github.io/2019/04/20/Service-Discovery-and-Registration-Using-Spring-Cloud-Eureka/","excerpt":"","text":"unsplash-logoFo Fa In past few microservices articles, We discuss different Spring Cloud features, Like Config Server , OpenFeign and Ribbon. In this Post, Let’s talk about Spring Cloud Netflix – Eureka.Why we need it ? How to configure the Eureka server , How to register service in Registry Server? In cloud based microservices environment, Servers come and go. Unlike the traditional architecture which work with servers with well known IP addresses and host names. In cloud platform, It is not possible to know the IP and Host names of services. Also the containers use dynamic IPs for autoscaling moreover Load balancing requires much more sophistication in registering and de-registering servers for balancing.So we can not have tight coupling between the services based of IP or Host Names. Spring Cloud Netflix – Eureka helps to solve that problem. The code for this post is available for download here. In typical Eureka setup we haveEureka Server: Which acts as service registry.Eureka Client REST services which registers itself at the registry. let’s Setup Eureka Server &amp; Client for our demo application. Demo Application: Our Simple PricingService calculates Price for the Product. Pricing Service gets some dynamic discount details from DiscountService. Setting Up Eureka ServerTo Add Eureka Server in project, we need to use the spring-cloud-starter-netflix-eureka-server artifact id. and use @EnableEurekaServer on main class. Eureka server can also register it’s self as a Eureka client. For the demo we will disable that using registerWithEureka flag. Eureka Server can be configured to read configuration from Config server that we discuss Here. this property can be set using fetchRegistry flag.Eureka Server1234567@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125;Eureka Server Properties123456789101112131415#Server Specificsserver: port: 8761spring: application: name: eureka-server#Eureka Specificseureka: instance: hostname: localhost client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ Start the EurekaServerApplication and you should be able to see Eureka dashboard at http://localhost:8761/ Setting Up Eureka Clients - Discount Servicelet’s Setup Discount Service to register with Eureka Server. To include the Eureka Client in project we need to use spring-cloud-starter-netflix-eureka-client artifact ID.Spring Boot will identify the client jar in classpath and will try to register with Server. We can also use @EnableDiscoveryClient to do that. We need to provide information about the Eureka Server, This can be done using serviceUrl property.Discount service has simple endpoint that returns the discount for product.Discount Service123456789101112131415161718@SpringBootApplication@EnableDiscoveryClient@Slf4jpublic class DiscountServiceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DiscountServiceApplication.class, args); &#125;&#125;@RestController@RequestMapping(\"/discount/&#123;product&#125;\")@Slf4jclass DiscountController&#123; @GetMapping public int getDiscountPercentage(@PathVariable(\"product\") String product)&#123; log.info(\"Getting Discount for Product &#123;&#125;\",product); return 50; &#125;&#125;Discount Service properties12345678910111213spring: application: name: discount-serviceserver: port: 8081 eureka: client: healthcheck: enabled: true serviceUrl: defaultZone: http://localhost:8761/eureka/ Start the DiscountServiceApplication and you should be able to see DiscountService registered on Eureka dashboard http://localhost:8761/Note Application Name is very important as it is used for server for lookups Magic of Registry: Calling Service using Registry &amp; FeignNow Let’s Call DiscountService to calculate price. Now as DiscountService is registered with Registry so we don’t need to know the host details.I have already discusses in details about Feign and how to use to call service in this Post. Feign works with eureka-client and we can call service using application.name. In below code snippet DiscountServiceClient is a FeignClient Which is calling service using registered application name. Pricing Service12345678910111213141516171819202122232425262728@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class PricingServiceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(PricingServiceApplication.class, args); &#125;&#125;@RestController@Slf4jclass ServiceInstanceRestController &#123; @Autowired private DiscountServiceClient discountServiceClient; @GetMapping(\"/price/&#123;product&#125;\") public Int getPriceForProduct(@PathVariable(\"product\") String product) &#123; int discount = discountServiceClient.getDiscountPercentage(\"Test\"); int price = 100; s = 100-discount log.info(\"Discount is &#123;&#125;\",discount); return (s*price)/100; &#125;&#125;@FeignClient(\"discount-service\")interface DiscountServiceClient &#123; @RequestMapping(method = RequestMethod.GET, value = \"/discount/&#123;product&#125;\") int getDiscountPercentage(@PathVariable(\"product\") String product);&#125; Pricing Service properties12345678910111213spring: application: name: pricing-serviceserver: port: 8080 eureka: client: healthcheck: enabled: true serviceUrl: defaultZone: http://localhost:8761/eureka/ What about Load Balancing ?I have already discusses how to use and setup Ribbon for Client-side load balancing in this Post. Feign already uses Ribbon, so, if you use @FeignClient Ribbon will be used along with that. When Eureka is used in conjunction with Ribbon (that is, both are on the classpath), the ribbonServerList is overridden with an extension of DiscoveryEnabledNIWSServerList, which populates the list of servers from Eurekaif we start multiple instances of discount service then Ribbon will discount service in round robin algorithm. Final Architecture of Application will be like this The code for this post is available for download here.","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/tags/Spring-Cloud/"},{"name":"Microservice","slug":"Microservice","permalink":"https://nirajsonawane.github.io/tags/Microservice/"},{"name":"Eureka","slug":"Eureka","permalink":"https://nirajsonawane.github.io/tags/Eureka/"}]},{"title":"Spring Cloud Netflix Ribbon","slug":"Spring-Cloud-Netflix-Ribbon","date":"2019-03-22T20:45:52.000Z","updated":"2019-03-22T17:38:06.000Z","comments":true,"path":"2019/03/22/Spring-Cloud-Netflix-Ribbon/","link":"","permalink":"https://nirajsonawane.github.io/2019/03/22/Spring-Cloud-Netflix-Ribbon/","excerpt":"","text":"What is Ribbon?Ribbon is a client-side load balancer that gives you a lot of control over the behavior of HTTP and TCP clients. Ribbon is aware of multiple instances of a service and chooses a particular instance of it. One advantage of this is client controls the load balancing algorithm. Ribbon Works with Feign That we discussed in last post. The Code for this post is available for download here. Demo ApplicationOur Simple HelloService Returns String Hello Message From Server: {port_number}. We will launch multiple instance of HelloService. Our Ribbon Client will call HelloService in Round-Robin way. HelloService1234567891011@RestController@RequestMapping(\"/helloworld\")public class HelloController &#123; @Autowired private Environment environment; @GetMapping public String getMessage() &#123; String port = environment.getProperty(\"local.server.port\"); return \"Hello Message From Server \" + port; &#125;&#125; Getting Started With Spring Cloud Netflix RibbonTo include Ribbon in project We need to use artifact id spring-cloud-starter-netflix-ribbonnetflix-ribbon Maven1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; Update FeignClient to use Ribbon Load BalancingFeignClient With Ribbon1234567@FeignClient(name = \"hello\", configuration = HelloClientConfig.class)@RibbonClient(name = \"hello\")public interface HelloClient &#123; @RequestMapping(method = RequestMethod.GET, value = \"/helloworld\") String getMessage();&#125; A central concept in Ribbon is that of the named client. We Provide the application name inapplication.properties.application-name.ribbon.listOfServers Property is used to provide list of Servers.application.properties12spring.application.name=hellohello.ribbon.listOfServers: localhost:8080,localhost:8081 Test Application Start HelloService on port 8080 and 8081. Start Client Application on 8083.Then Go to http://localhost:8083/ribbon-test-client/first time it should return message as “Hello Message From Server 8080” and next time as “Hello Message From Server 8081” The Code for this post is available for download here.","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/tags/Spring-Cloud/"},{"name":"Microservice","slug":"Microservice","permalink":"https://nirajsonawane.github.io/tags/Microservice/"},{"name":"Ribbon","slug":"Ribbon","permalink":"https://nirajsonawane.github.io/tags/Ribbon/"}]},{"title":"Simplifying Microservices Communication Using Spring Cloud OpenFeign","slug":"Simplifying-Microservices-Communication-Using-Spring-Cloud-OpenFeign","date":"2019-03-21T19:06:41.000Z","updated":"2019-04-20T05:50:26.000Z","comments":true,"path":"2019/03/21/Simplifying-Microservices-Communication-Using-Spring-Cloud-OpenFeign/","link":"","permalink":"https://nirajsonawane.github.io/2019/03/21/Simplifying-Microservices-Communication-Using-Spring-Cloud-OpenFeign/","excerpt":"","text":"unsplash-logoPavan Trikutam What is Feign?Feign is a Java to HTTP client binder. Feign Simpliffyes the HTTP API Clients using declarative way.Feign is a library for creating REST API clients in a declarative way. it makes writing web service clients easier. Developers can use declarative annotations to call rest servicese instead of writing repetitive boilerplate code. Spring Cloud OpenFeign provides OpenFeign integrations for Spring Boot apps through autoconfiguration and binding to the Spring Environment and other Spring programming model idioms The code for this post is available for download here. Demo ApplicationWe Have Simple User Service that provides crud operations for Users. We will write client to call these rest endpoints. Why Feign?Without Feign, In Spring Boot Applications We will be using RestTemplate to call User service. We need to write code somewhat similar to below. HTTP Client Using RestTemplate123456789101112131415161718192021222324252627282930313233343536373839404142434445@GetMapping public List&lt;User&gt; getAllUsers() &#123; System.out.println(\"Calling User Service using Feign Client!!\"); RestTemplate restTemplate = new RestTemplate(); ResponseEntity&lt;List&lt;User&gt;&gt; response = restTemplate.exchange( \"http://localhost:8080/user/\", HttpMethod.GET, null, new ParameterizedTypeReference&lt;List&lt;User&gt;&gt;() &#123; &#125;); List&lt;User&gt; users = response.getBody(); return users; &#125; @GetMapping(\"&#123;id&#125;\") public User getUserById(@PathVariable(\"id\") int id) &#123; Map&lt;String, String&gt; uriParams = new HashMap&lt;String, String&gt;(); uriParams.put(\"id\", String.valueOf(id)); URI uri = UriComponentsBuilder .fromUriString(\"http://localhost:8080/user/&#123;id&#125;\") .buildAndExpand(uriParams) .toUri(); System.out.println(uri); RestTemplate restTemplate = new RestTemplate(); User forEntity = restTemplate.getForObject(uri, User.class); return forEntity; &#125; @PostMapping public ResponseEntity addUser(@RequestBody User user) &#123; System.out.println(\"Add user\"); System.out.println(user.toString()); RestTemplate restTemplate = new RestTemplate(); HttpEntity&lt;User&gt; request = new HttpEntity&lt;&gt;(user); ResponseEntity exchange = restTemplate .exchange(\"http://localhost:8080/user/\", HttpMethod.POST, request, String.class); return exchange; &#125; @DeleteMapping(\"&#123;id&#125;\") public ResponseEntity deleteUser(@PathVariable int id) &#123; System.out.println(\"delete user\"); Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(); params.put(\"id\", String.valueOf(id)); RestTemplate restTemplate = new RestTemplate(); restTemplate.delete(\"http://localhost:8080/user/&#123;id&#125;\", params); return new ResponseEntity(\"User Deleted successfully\", HttpStatus.OK); &#125; From above code we can easily figure out that most of the code is repetitive and has nothing to do the business logic. Let’s Simplify Above code using Spring Cloud OpenFeign. Getting Started With Spring Cloud OpenFeignTo include Feign in project We need to use artifact id spring-cloud-starter-openfeignopenfeign Maven1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; EnableFeignClientsEnableFeignClients12345678@SpringBootApplication@EnableFeignClientspublic class SpringCloudFeignClientDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudFeignClientDemoApplication.class, args); &#125;&#125; Creating Feign Client With Sensible Defaults.FeignClient123456789101112131415161718@FeignClient(name = \"User\", url = \"http://localhost:8080\")public interface UserClient &#123; @RequestMapping(method = RequestMethod.GET, value = \"/user\") List&lt;User&gt; getAllUsers(); @RequestMapping(method = RequestMethod.GET, value = \"/user/&#123;id&#125;\") User getUser(@PathVariable(\"id\") int id); @RequestMapping(method = RequestMethod.DELETE, value = \"/user/&#123;id&#125;\") ResponseEntity deleteUser(@PathVariable(\"id\") int id); @RequestMapping(method = RequestMethod.POST, value = \"/user/\") ResponseEntity addUser(@RequestBody User user); @RequestMapping(method = RequestMethod.PUT, value = \"/user/\") ResponseEntity updateUser(User user);&#125; The above code is self explanatory. At minimal we just have to specify name = &quot;User&quot; is an arbitrary client name and url.If we compare our UserClient with the code that we have written using RestTemplate, It’s visible that without writing any code specific to calling HTTP Service our UserClient supports all operations. Feign is doing magic under the hood. Overriding Feign default propertiesWe Can provide custom configuration class to Overriding default properties.e.g. let say we want to Log the headers, body, and metadata for both requests and responses.lets Create UserClientConfig class to setup log level.UserClientConfig12345678@Configurationpublic class UserClientConfig &#123; @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.HEADERS; &#125;&#125; Update UserClient To use this config class. Updated FeignClient12345@FeignClient(name = \"User\", url = \"http://localhost:8080\",configuration=UserClientConfig.class)public interface UserClient &#123;&#125; Note : Feign gets integrated with Hystrix, Ribbon and Eureka quite easily. I will cover that in separate Post. The code for this post is available for download here.","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/tags/Spring-Cloud/"},{"name":"Microservice","slug":"Microservice","permalink":"https://nirajsonawane.github.io/tags/Microservice/"},{"name":"OpenFeign","slug":"OpenFeign","permalink":"https://nirajsonawane.github.io/tags/OpenFeign/"}]},{"title":"Update Config Dynamically Using Spring Cloud Bus and Spring Cloud Config","slug":"Update-Configs-Dynamically-Using-Spring-Cloud-Bus-and-Spring-Cloud-Config","date":"2019-02-22T11:56:19.000Z","updated":"2019-02-23T09:36:24.000Z","comments":true,"path":"2019/02/22/Update-Configs-Dynamically-Using-Spring-Cloud-Bus-and-Spring-Cloud-Config/","link":"","permalink":"https://nirajsonawane.github.io/2019/02/22/Update-Configs-Dynamically-Using-Spring-Cloud-Bus-and-Spring-Cloud-Config/","excerpt":"","text":"In The previous post Centralize Configurations Using Spring Cloud Config We Setup config Server and Centralized The Configuration properties in github.In This post, We Will Check different options available to update Config properties in Client applications without restarting Them.The code for this post is available for download here. 1 Restart Endpoint Of Spring Actuator EndpointThe Simplest way to reload the application config without manually restarting it is Using Spring Boot Actuator Restart Endpoint.But this is not the best way to update the config. 2 Refresh Endpoint- @RefreshScope &amp; @ConfigurationPropertiesSpring allows beans to be refreshed dynamically at runtime using @RefreshScope. The Bean That are using @Value to read properties are need to be annotated with @RefreshScope. The Properties loaded by @ConfigurationProperties are automatically reloaded as @ConfigurationProperties are by default @RefreshScopeTo Reload the bean annotated with @RefreshScope Run below post request.$ curl localhost:8090/actuator/refresh -d {} -H &quot;Content-Type: application/json&quot;ProblemBut Again This method has Problem, In a real microservice environment, there will be a large number of independent application services. And It is not practical for the user to manually trigger the refresh event for all the related services whenever a property is changed.Spring Bus Provide Solution For this 3 Spring Cloud BusSpring Cloud Bus links nodes of a distributed system with a lightweight message broker. This can then be used to broadcast state changes, The configuration changes are publised as events to all connected nodes. For the POC We will be using AMQP broker as the transport. Our targeted architecture will look like below Lets update the System we build in The previous post Centralize Configurations Using Spring Cloud Config Setup RabbitMQ with DockerWe will run RabbitMQ as a docker image. Install Docker Then Run below command to install rabbitmqdocker pull rabbitmq:3-management To Run RabbitMQ use below commanddocker run -d --hostname my-rabbit --name some-rabbit -p 15672:15672 -p 5672:5672 rabbitmq:3-managementVerify MQ is running. http://192.168.99.100:15672/#/ (Check What IP was generated for You). Default User name and password is guest/guest. Add Cloud-bus to All Clients1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt; Connect to MQ BusAdd Properties related to MQ1234spring.rabbitmq.host=192.168.99.100spring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest Let’s Test Our Changes Start Config Server Start Multiple Instances of Customer Service.Start Customer Service on 8090,8091,8092 Verify Config Properties http://localhost:8888/customer-service/dev Dev is configured as customer having gmail account as Premium Account. Check for http://localhost:8090/customer/niraj.sonawane@gmail.com We should get response as Premium account. Similar for 8091,8092 Update Config properties in Github and push Changes Verify Updated Config Properties http://localhost:8888/customer-service/dev Now Check for http://localhost:8090/customer/niraj.sonawane@gmail.com We should get response as Premium account. Similar for 8091,8092. (As we have not yet refreshed anything) Send Bus Refresh request on 8090, http://localhost:8090/actuator/bus-refresh Now Check for http://localhost:8090/customer/niraj.sonawane@gmail.com We should get response as Free Account Also Changes will be reflected for other services,Now Check for http://localhost:8091/customer/niraj.sonawane@gmail.com &amp; http://localhost:8092/customer/niraj.sonawane@gmail.com We have Send Bus refresh event only for 8090 But Still Changes are reflected on all nodes. Bus Will take responsibility of Sending refresh event 4 Github WebhookGithub Providers notification Event when changes are made in repository through a webhook. Github uses a POST to the webhook with a JSON body containing a list of commits and a header set to push.Tu use Webhooks We Need to add spring-cloud-config-monitor dependency And Activate /monitor endpoint To Add Webhooks Go to Your ConfigRepo-&gt;Settings-Webhooks. Note, You need Public Domain name for this to work. The code for this post is available for download here. Reference.","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/tags/Spring-Cloud/"},{"name":"Microservice","slug":"Microservice","permalink":"https://nirajsonawane.github.io/tags/Microservice/"},{"name":"Cloud Bus","slug":"Cloud-Bus","permalink":"https://nirajsonawane.github.io/tags/Cloud-Bus/"},{"name":"Cloud Config","slug":"Cloud-Config","permalink":"https://nirajsonawane.github.io/tags/Cloud-Config/"}]},{"title":"Centralize Configurations Using Spring Cloud Config","slug":"Centralize-Configurations-Using-Spring-Cloud-Config","date":"2019-02-17T20:26:15.000Z","updated":"2019-02-19T04:22:16.000Z","comments":true,"path":"2019/02/17/Centralize-Configurations-Using-Spring-Cloud-Config/","link":"","permalink":"https://nirajsonawane.github.io/2019/02/17/Centralize-Configurations-Using-Spring-Cloud-Config/","excerpt":"","text":"unsplash-logoAsh Edmonds In This post we will Create Small POC for Spring Cloud Config and will use different Key Features of Spring Cloud Config. The code for this post is available for download here. And Config files here ProblemIn a typical Microservices Architecture, We have Number of Small,Independent Services working together. Each service will have it’s own configurations in property files &amp; we have multiple instances of each service. Now if we think about different environments like Development, Staging, and Prod etc It makes things more complicated. Each time if we need to change the configuration of a microservice, we need go to the corresponding project, change its configuration and then restart the application for the change to take effect.Managing These Configurations for multiple services across different environments becomes very criticalSpring Cloud Config provide Solutions to all these problems What Is Spring Cloud Config ?Spring Cloud Config provides server-side and client-side support for Externalized Configuration in a distributed system. With the Config Server, you have a central place to manage external properties for applications across all environments. The default implementation of the server storage backend uses git, so it easily supports labelled versions of configuration environments as well as being accessible to a wide range of tooling for managing the content. It is easy to add alternative implementations and plug them in with Spring configuration. POC ApplicationAssume we have Small Application which includes two microservices Customer &amp; Account. Customer service accepts email id of user and identifies if the user is Premium user or not. If the email id contains some keyword, then we will consider that customer as Premium Customer. At present we have defined the keyword in application.propertiese.gFor DEV - customer-service.emailtype=gmail.comFor QA - customer-service.emailtype=github.comFor DEV - customer-service.emailtype=microsoft.com If I run http://localhost:8080/customer/niraj.sonawane@gmail.com in dev environment, I should get response as Premium Account. Before Cloud Config12345678910111213141516171819202122232425262728// Simple RestController which check if email has keyword or not. @RestController public class CustomerProfileController &#123; @Autowired private CustomerServiceConfigurations customerServiceConfigurations; @GetMapping(\"/customer/&#123;email&#125;\") public String getCustomerDetails(@PathVariable String email) &#123; if (email.contains(customerServiceConfigurations.getEmailtype())) &#123; return \"Premium Account\"; &#125; return \"Free Account\"; &#125;&#125;//Configuration Class For loading configs from application.properties.//All properties starting with customer-service will be loaded in this class. @Component@ConfigurationProperties(\"customer-service\")@Datapublic class CustomerServiceConfigurations &#123; private String emailtype;&#125;//application.properties has below properties.customer-service.emailtype=gmail.com Before Cloud Config Our Task is to externalize the Configurations in Git repository using Spring CloudAfter Cloud Config Infographic vector created by freepik - www.freepik.com 1 Spring Cloud Config ServerConfig Server acts as a sort of intermediary between our Spring applications and a typically version-controlled repository of configuration files. All microservices access properties files using config server.We need to add &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; dependency. And need to use @EnableConfigServer annotation.Config Server12345678@SpringBootApplication@EnableConfigServerpublic class SpringCloudConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudConfigServerApplication.class, args); &#125;&#125; Connecting Config Server to version-controlled repositorySpring Cloud Config Server supports Git,SVN, JDBC (relational database) etc as a backend for configuration properties.The default implementation of EnvironmentRepository uses a Git backend. For this POC will use git.We can also use File System based backend for configuration properties using native profile.Config Server application.properties123spring.application.name=spring-cloud-config-serverserver.port=8888spring.cloud.config.server.git.uri=https://github.com/nirajsonawane/Spring-Cloud-Config-Server-Demo-Config-Repo.gitTo Provide path of file based git system file://${user.home}/config-repo. Run the config server and you should be able to access properties of customer-service at http://localhost:8888/customer-service/defaultSimilarly Account service properties will be available at http://localhost:8888/account-service/default 2 Config Client ConfigurationsTo access Configurations through Config Server,Client applications needs to addspring-cloud-starter-config dependency.The properties to configure the Config Client must necessarily be read in before the rest of the application’s configuration is read from the Config Server, during the bootstrap phase. Configure the Config server related properties in bootstrap.propertiesbootstrap.properties12spring.application.name=customer-servicespring.cloud.config.uri=http://localhost:8888/Now If we Start our Customer service, It will start accessing properties files from our config server. In logs we can verity this.[ restartedMain] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888/And If we run http://localhost:8080/customer/niraj.sonawane@gmail.com I should get response as Premium Account. (Will access Default Profile) 3 Managing Profiles, Environment Specific propertiesTo manage environment specific properties, i.e. profiles add profile specific properties in repository. For customer-service we will add below files in our git repository. customer-service-dev.properties customer-service-prod.properties customer-service-qa.properties To set any specific profile we can use spring.profiles.active parameter in bootstrap.properties or using command line argument -Dspring-boot.run.profiles Precedence rules for profiles are also the same as in a regular Spring Boot application: Active profiles take precedence over defaults, and, if there are multiple profiles, the last one wins (similar to adding entries to a Map). 4 RefreshScopeUntil Now, We have Solved the problem of Centralizing the properties and managing different profiles. Now We will focus on how to update properties at run time without application Restart. By default, the configuration values are read on the client’s startup, and not again. We can force a bean to refresh its configuration - to pull updated values from the Config Server - by annotating the Classes that are refering with the Spring Cloud Config @RefreshScope and then by triggering a refresh event.There are other options are also available, I will cover them in next Post. 5 Useful Properties and Other Key Features if client cannot connect to the Config Serve then use spring.cloud.config.fail-fast=true for fail fast. Config Client can Retry if it is not able to connect, use spring.cloud.config.retry.* SSL certificate can be disabled by setting the git.skipSslValidation property to true (default is false). Timeout Can be set on Config server to read properties from git, Use git.timeout property Multiple Repositories can be used by using Pattern Matching Config Server supports the Encryption and Decryption of properties using JCE Config Server supports DiscoveryClient implementation such as Eureka Service Discovery Config Server register with the Discovery Service. The code for this post is available for download here. And Config files here","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://nirajsonawane.github.io/tags/Spring-Cloud/"},{"name":"Microservice","slug":"Microservice","permalink":"https://nirajsonawane.github.io/tags/Microservice/"}]},{"title":"Write Clean Asynchronous Code With CompletableFuture Java-8","slug":"Write-Clean-asynchronous-code-with-CompletableFuture-Java-8","date":"2019-01-27T21:13:44.000Z","updated":"2019-02-02T11:44:10.000Z","comments":true,"path":"2019/01/27/Write-Clean-asynchronous-code-with-CompletableFuture-Java-8/","link":"","permalink":"https://nirajsonawane.github.io/2019/01/27/Write-Clean-asynchronous-code-with-CompletableFuture-Java-8/","excerpt":"","text":"unsplash-logorawpixel Java 8 has introduced a lot of features. With Addition of CompletableFuture . Writing Clean &amp; Readable Asynchronous code has become much more easier. CompletableFuture has more than 50 methods which makes it very useful. The code for this post is available for download here. CompletableFutureCompletableFuture is an implementation of the Future &amp; CompletionStage interface but with a lot of modern Features. It Supports lambdas and takes advantage of non-blocking methods via callbacks and promotes asynchronous reactive programming model. CompletableFuture allows us to write non-blocking code by running a task on a separate thread than the main application thread and notifying the main thread about its Progress, Completion or Failure. CompletableFuture is inspired from ListenableFuture in Guava and Are similar to Promise in java scripts. Why CompletableFuture instead Of Future?Callable and Future were introduced in Java 5. Future is placeholders for a result that hasn’t happened yet.Future Can use a Runnable or Callable instance to complete the submitted task. There are two methods to get actual value from Future.get() : When this method is called, thread will wait for result indefinitely.get(long timeout, TimeUnit unit): When this method is called, thread will wait for result only for specified time.There are multiple problems with FutureBlocking - The get method is blocking and need to wait until the computation is done. Future does not have any method that can notify on completion and does not have capability to attach a callback function.Chaining &amp; Composition - Many times we want to chain multiple future to complete long computation. You need to merger results and send results to another task. It’s Hard to implement such chaining with future.Exception Handling - Future does not provide any construct for Exception Handling.All these issues are addressed by CompletableFuture.lets try different methods provided by CompletableFutureCreate Simple Completeable FutureThe simplest way is to create CompleteableFuture is CompleteableFuture.completedFuture method which returns an a new, finished CompleteableFuture. Creating already Completed CompleteableFuture becomes very useful in many cases.Create Completed CompleteableFuture12345678910@Testvoid simpleComletedCompletableFuture() &#123;CompletableFuture&lt;String&gt; completableFuture = CompletableFuture.completedFuture(\"Some Value\"); assertTrue(completableFuture.isDone()); try &#123; assertEquals(\"Some Value\", completableFuture.get()); &#125; catch (ExecutionException | InterruptedException e) &#123; fail(\"No Exception expected\");&#125;&#125; Note : if we call get method on incomplete CompleteableFuture , the get call will block forever because the Future is never completed.We can use CompletableFuture.complete() method to manually complete a Future. Simple Asynchronous computation using runAsyncIf We want to run some task in background that does not returns any value, then we can use CompletableFuture.runAsync() it takes a Runnable and returns CompletableFuture&lt;Void&gt;Simple Asynchronous computation using runAsync1234567891011 public void process() &#123; System.out.println(Thread.currentThread() + \" Process\"); someStateVaribale.set(100);&#125;@Testvoid completableFutureRunAsync() &#123; CompletableFuture&lt;Void&gt; runAsync = CompletableFuture.runAsync(() -&gt; process()); runAsync.join(); assertEquals(100, someStateVaribale.get());&#125; Simple Asynchronous computation using SupplyAsyncIf we want to run some task in background that Returns Some Value, then we can use CompletableFuture.supplyAsync() it takes a Supplier&lt;T&gt; and returns completableFuture&lt;T&gt;Simple Asynchronous computation using supplyAsync123456789@Testvoid completableFutureSupplyAsync() &#123; CompletableFuture&lt;String&gt; supplyAsync = CompletableFuture.supplyAsync(this::processSomeData); try &#123; assertEquals(\"Some Value\", supplyAsync.get()); //Blocking &#125; catch (ExecutionException | InterruptedException e) &#123; fail(\"No Exception expected\"); &#125;&#125; CompletableFuture with Custom ExecutorYou might be wondering, Which Thread is executing the supplyAsync &amp; runAsync task and Who is creating these Threads? Similar to parallel streams CompletableFuture executes these tasks in a thread obtained from the global ForkJoinPool.commonPool().We Can always provide our custom Executor to CompletableFuture.All the methods in the CompletableFuture API has two variants, With or Without Executor.CompletableFuture with Custom Executor12345678910 @Testvoid completableFutureSupplyAsyncWithExecuto() &#123; ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(2); CompletableFuture&lt;String&gt; supplyAsync = CompletableFuture.supplyAsync(this::processSomeData,newFixedThreadPool); try &#123; assertEquals(\"Some Value\", supplyAsync.get()); &#125; catch (ExecutionException | InterruptedException e) &#123; fail(\"No Exception expected\"); &#125;&#125; CompletableFuture Callbacks and ChainingWe know that CompletableFuture.get() is blocking and we want to avoid this. We should get some notification after Future completes.CompletableFuture provides thenApply(), thenAccept() and thenRun() to attach callbacks thenAccept()If We want to run some code after receiving some value from Future then we can use thenAccept()thenApply()If We want to run some code after receiving value from Future and then want to return some value for this we can use thenAccept()thenRun()If We want to run some code after completion of the Future and dont want to return any value for this we can use thenRun() CompletableFuture thenAccept thenApply thenRun123456789101112131415161718192021222324 @Testpublic void completableFutureThenAccept() &#123; CompletableFuture.supplyAsync(this::process) .thenAccept(this::notify) //Non Blocking,notify method will be called automatically after compilation or process method .join(); assertEquals(100,someStateVaribale.get()); &#125;@Testpublic void completableFutureThenApply() &#123; Integer notificationId = CompletableFuture.supplyAsync(this::process) .thenApply(this::notify)//Non Blocking will return some value .join(); assertEquals(new Integer(1),notificationId); &#125; @Test public void completableFutureThenApply() &#123; CompletableFuture.supplyAsync(this::process) .thenRun(this::notifyMe) .join(); assertEquals(100,someStateVaribale.get()); &#125; Chaining CallbacksIf We have large Asynchronous computation, Then we can continue passing values from one callback to another.Chaining Callbacks12345678 @Testpublic void completableFutureThenApplyAccept() &#123; CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .thenAccept((i)-&gt;notifyByEmail()).join();&#125;async variants of thenApply(),thenAccept() and thenRun()Note In all the previus examples, All methods are executed on Same threads. But If we want them to be run on separate thread then we can use async variants of these methods.Async Variants12345678910111213 @Testpublic void completableFutureApplyAsync() &#123; ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(2); ScheduledExecutorService newSingleThreadScheduledExecutor = Executors.newSingleThreadScheduledExecutor(); CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture .supplyAsync(this::findAccountNumber,newFixedThreadPool)//will run on thread obtain from newFixedThreadPool .thenApplyAsync(this::calculateBalance,newSingleThreadScheduledExecutor) //will run on thread obtain from newSingleThreadScheduledExecutor .thenApplyAsync(this::notifyBalance);//will run on thread obtain from common pool Integer balance = completableFuture.join(); assertEquals(Integer.valueOf(balance), Integer.valueOf(100)); &#125; CompletableFuture thenCompose and thenCombinethenComposeLet’s Say we want to first find Account Number and then calculate Balance for that account and after calculations we want to send notifications.Now All these task are Dependent and methods are returning CompletableFuture , Then We need to use thenCompose Method.This is similar to flatMap in case of Streams.thenCompose123456789101112131415161718192021222324252627282930313233 public CompletableFuture&lt;Integer&gt; findAccountNumber() &#123; sleep(1); System.out.println(Thread.currentThread() + \" findAccountNumber\"); return CompletableFuture.completedFuture(10);&#125;public CompletableFuture&lt;Integer&gt; calculateBalance(int accountNumber) &#123; System.out.println(Thread.currentThread() + \" calculateBalance\"); sleep(1); return CompletableFuture.completedFuture(accountNumber * accountNumber);&#125;public CompletableFuture&lt;Integer&gt; notifyBalance(Integer balance) &#123; System.out.println(Thread.currentThread() + \"Sending Notification\"); sleep(1); return CompletableFuture.completedFuture(balance); &#125;private void sleep(int seconds) &#123; try &#123; TimeUnit.SECONDS.sleep(seconds); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; @Testpublic void completableFutureThenCompose()&#123; Integer join = findAccountNumber() .thenComposeAsync(this::calculateBalance) .thenCompose(this::notifyBalance) .join(); assertEquals(new Integer(100), join);&#125; thenCombineAs name suggest thenCombine is used to merge results of two independent CompletableFuture. Assume that for a person we get first name and last name by calling two different independent methods. To get the Full name we want ot merge results of both the methods then we will use thenCombine.thenCombine123456789101112131415161718192021 public CompletableFuture&lt;String&gt; findFirstName() &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; sleep(1); return \"Niraj\"; &#125;); &#125;public CompletableFuture&lt;String&gt; findLastName() &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; sleep(1); return \"Sonawane\"; &#125;);&#125;@Testpublic void completableFutureThenCombine() &#123; CompletableFuture&lt;String&gt; thenCombine = findFirstName().thenCombine(findLastName(), (firstName, lastname) -&gt; &#123; return firstName + lastname;&#125;); String fullName = thenCombine.join(); assertEquals(\"NirajSonawane\", fullName); &#125; CompletableFuture allOfIn Many scenario we want to run run multiple task in parallel and want to do some processing after all of them are complete. Assume we want to find firstName of five different users and combine the results.The CompletableFuture.allOf static method allows to wait for completion of all of the Futures.The allOf method has limitation that it does not return the combined results of all Futures. We you have to manually combine the results from Futures.allOf123456789101112131415161718192021222324public CompletableFuture&lt;String&gt; findSomeValue() &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; sleep(1); return \"Niraj\"; &#125;);&#125; @Testpublic void completableFutureAllof() &#123; List&lt;CompletableFuture&lt;String&gt;&gt; list = new ArrayList&lt;&gt;(); IntStream.range(0, 5).forEach(num -&gt; &#123; list.add(findSomeValue());&#125;);CompletableFuture&lt;Void&gt; allfuture = CompletableFuture.allOf(list.toArray(new CompletableFuture[list.size()]));//Created All of object CompletableFuture&lt;List&lt;String&gt;&gt; allFutureList = allfuture.thenApply(val -&gt; &#123; return list.stream().map(f -&gt; f.join()).collect(Collectors.toList());&#125;); CompletableFuture&lt;String&gt; futureHavingAllValues = allFutureList.thenApply(fn -&gt; &#123; System.out.println(\"I am here\"); return fn.stream().collect(Collectors.joining());&#125;); String concatenateString = futureHavingAllValues.join(); assertEquals(\"NirajNirajNirajNirajNiraj\", concatenateString);&#125; CompletableFuture Exception HandlingHanding Exceptions in Multithreaded code in Java was always pain. Luckily CompletableFuture has a nice way of handling exceptions.Exception Handling1234CompletableFuture&lt;Integer&gt; thenApply = CompletableFuture .supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance)In Above Code if findAccountNumber method throws the Exception then callback chain calculateBalance and notifyBalance will not be called. Future will be resolved with the exception occurred.Similarly if calculateBalance throws the Exception then after the callback chain will break. Handel Exceptions using exceptionally Exceptionally callback will be called if preceding methods fails with an exception. exceptionally Returns a new CompletableFuture that is completed when this CompletableFuture completes, with the result of the given function of the exception triggering this CompletableFuture’s completion when it completes exceptionally; otherwise, if this CompletableFuture completes normally, then the returned CompletableFuture also completes normally with the same value.exceptionally1234567891011121314 @Test public void completableFutureExceptionally() &#123;CompletableFuture&lt;Integer&gt; thenApply = CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .exceptionally(ex -&gt; &#123; System.out.println(\"Got Some Exception \"+ex.getMessage()); System.out.println(\"Returning some default value\"); return 0; &#125;); Integer join = thenApply.join(); assertEquals(new Integer(0), join); &#125; Handel Exceptions using Handel Method Handel method is more flexible than exceptionally method.As we get both exception as well as Result.Handel1234567891011121314151617@Testpublic void completableFutureHandel()&#123;CompletableFuture&lt;Integer&gt; thenApply = CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .handle((ok, ex) -&gt; &#123; System.out.println(\"Code That we want to run in finally \"); if (ok != null) &#123; System.out.println(\"No Exception !!\"); &#125; else &#123; System.out.println(\"Got Exception \" + ex.getMessage()); return -1; &#125; return ok; &#125;); &#125; Handel Exceptions using WhenComplete MethodWhenComplete12345678@Testpublic void completableFutureWhenComplete()&#123; CompletableFuture.supplyAsync(this::findAccountNumber) .thenApply(this::calculateBalance) .thenApply(this::notifyBalance) .whenComplete((i,t)-&gt;System.out.println(\"finally action\")); &#125; TimeOut java 9 ImprovementWhile Working on Asynchronous Code, We Need to handel timeouts. We Can not wait forever to finish the task. Unfortunately we do not have anything in java 8 for timeouts.Java 9 has added orTimeout and completeOnTimeout methods to handel this. If the task does not complete in given time, a TimeoutException will be thrown. orTimeout123456@Testpublic void completableFutureWhenComplete()&#123; CompletableFuture.supplyAsync(this::findAccountNumber) .orTimeout(1, TimeUnit.MINUTES); &#125; The code for this post is available for download here.","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"}],"tags":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"},{"name":"Java-9","slug":"Java-9","permalink":"https://nirajsonawane.github.io/tags/Java-9/"}]},{"title":"Document Spring Boot RESTful API With Swagger-2.0","slug":"Document-Spring-Boot-RESTful-API-With-Swagger-2-0","date":"2019-01-20T13:10:46.000Z","updated":"2019-01-21T04:28:46.000Z","comments":true,"path":"2019/01/20/Document-Spring-Boot-RESTful-API-With-Swagger-2-0/","link":"","permalink":"https://nirajsonawane.github.io/2019/01/20/Document-Spring-Boot-RESTful-API-With-Swagger-2-0/","excerpt":"","text":"unsplash-logoPuttipol Waipanya Now Days Spring Boot is de facto standard for developing RESTful services.Spring Boot makes it very easy to build RESTful services.In SOAP based web services, you had a WSDL which works as documentation for your API. For Rest Services we do not have WSDL so documentation of API becomes more critical. SwaggerSwagger 2 is an open source framework used to describe and document RESTful APIs.Swagger Can read your API’s structure and automatically build beautiful and interactive API documentation. Swagger makes documenting your RESTful services easy.Check Docs for all Features. The code for this post is available for download here. Swagger + Spring BootSwagger Can easily integrate with Spring Boot. To Integrate Swagger we need to use Swagger UI &amp; SpringFox. Maven Dependency1234567891011 &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; Demo Spring Boot RESTful Applicationlet’s Create documentation for our Demo Spring Boot RESTful Application. Demo Application expose User rest endpoint that allows to perform CURD operations for User. User Endpoint123456789101112131415161718192021222324 @GetMappingpublic List&lt;User&gt; getAllUsers() &#123; return userservice.getAllUsers();&#125;@GetMapping(\"/&#123;id&#125;\")public User getUser(@PathVariable int id) &#123; return userservice.getUser(id);&#125;@PostMappingpublic ResponseEntity addUser(@RequestBody User user) &#123; userservice.addUser(user); return new ResponseEntity(\"User Added successfully\", HttpStatus.OK);&#125;@PutMappingpublic ResponseEntity updateUser(@RequestBody User user) &#123; userservice.updateUser(user); return new ResponseEntity(\"User Updated successfully\", HttpStatus.OK);&#125;@DeleteMapping(\"/&#123;id&#125;\")public ResponseEntity deleteUser(@PathVariable int id) &#123; userservice.deleteUser(id); return new ResponseEntity(\"User Deleted successfully\", HttpStatus.OK);&#125; Swagger ConfigurationWe need to create a Docket bean in a Spring Boot configuration to configure Swagger 2. A Springfox Docket instance provides the primary API configuration with sensible defaults and convenience methods for configuration.@EnableSwagger2 Indicates that Swagger support should be enabled. This should be applied to a Spring java config and should have an accompanying @Configuration annotation. Loads all required beans defined in @SpringSwaggerConfig Below is minimum configuration required for Swagger. SwaggerConfig123456789101112@Configuration@EnableSwagger2public class SwaggerConfig &#123; @Bean public Docket api() &#123; return new Docket(DocumentationType.SWAGGER_2) .select() .apis(RequestHandlerSelectors.any()) .paths(PathSelectors.any()) .build(); &#125;&#125; Now If we run the application and go to http://localhost:8080/swagger-ui.html documentation will be rendered by Swagger UI. Update Swagger Configuration for Customization - ApInfoApiInfo1234567891011private ApiInfo apinfo() &#123; return new ApiInfoBuilder() .title(\"User Management API\") .description(\"Rest API to Perfrom CURD \") .termsOfServiceUrl(\"Some Terms of Services URL\") .version(\"1.0.0\") .license(\"Some License Info\") .licenseUrl(\"Some License URL\") .contact(new Contact(\"Niraj Sonawane\", \"https://nirajsonawane.github.io/\",\"Niraj.Sonawane@gmail.com\")) .build(); &#125; Update Swagger Configuration for Customization - Selecting Specific EndpointsWhen we verify the Generated documentation, We see that in Basic Error Controller along with our User Controller and Model.We can Configure Swagger to generated documentation only for certain endpoints using RequestHandlerSelectors. The Available options for Configurations are RequestHandlerSelectors.basePackage(basePackage) RequestHandlerSelectors.withClassAnnotation(annotation) RequestHandlerSelectors.withMethodAnnotation(annotation) Swagger Annotations On Controller classesSwagger provides annotations that can be applied on Controller classes to provide additional information,We can annotate controllers and their methods and method parameters. @Api describes the whole controller @ApiOperation is used for description on a methods level @ApiResponses is used for description of response codes on a methods level @ApiParam is used for method parameters Swagger Annotations On Controller classes1234567891011@GetMapping(\"/&#123;id&#125;\")@ApiOperation(consumes=\"application/json\", produces=\"application/json\",protocols=\"http\", value = \"getUser\" )@ApiResponses(value = &#123; @ApiResponse(code = 200, message = \"Successfully retrieved User\"), @ApiResponse(code = 401, message = \"The request has not been applied because it lacks valid authentication credentials for the target resource\"), @ApiResponse(code = 403, message = \"The server understood the request but refuses to authorize it\"), @ApiResponse(code = 404, message = \"The resource not found\")&#125;) public User getUser(@ApiParam(\"Id of user, Can not be null\") @PathVariable int id) &#123; return userservice.getUser(id);&#125; Swagger Annotations On Model classesSwagger Core annotations, Can be used to specify additional information about your model Class.e.g User Class annotated with these annotations can look something like this Swagger Annotations On Model classes12345678910111213141516171819@ApiModel(description = \"Class representing User \")public class User &#123; @ApiModelProperty(notes = \"Unique ID for user\", example = \"1\", required = true, position = 0) private int id; @ApiModelProperty(notes = \"First Name of User\", example = \"Niraj\", required = true, position = 1) private String firstName; @ApiModelProperty(notes = \"Last Name of User\", example = \"Sonawane\", required = true, position = 2) private String lastName; @ApiModelProperty(notes = \"Middle Name of User\", example = \"Ashok\", required = false, position = 3) private String middleName; @ApiModelProperty(notes = \"Age of User\", example = \"32\", required = true, position = 4) private Integer age;&#125; Swagger Integration with JSR-303 AnnotationsJSR 303 Bean Validation is the specification of the Java API for JavaBean validation in Java EE and Java SE. This is very popular mechanism for validation and number of projects are using it.JSR 303 Bean Validation12345678910111213141516@Datapublic class User &#123; private int id; @NotBlank @Size(min = 2, max = 10) private String firstName; @NotBlank private String lastName; private String middleName; @NotNull @Min(2) @Max(100) private Integer age;&#125;This is a common practice which is already widely used. Swagger can be easily configured to read these annotations and generate documentation based on such annotations.This makes Swagger very useful as we can utilize what we already have in our project without writing all the constraints manually. Consumers also know what are restrictions on the values and what they should provide to API and what values to expect. Add dependency in pom file12345 &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-bean-validators&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt;&lt;/dependency&gt; Import BeanValidatorPluginsConfiguration12345 @Configuration@EnableSwagger2@Import(BeanValidatorPluginsConfiguration.class)public class SwaggerConfig &#123; After Integration Model will look like below in generated documentation. The code for this post is available for download here.","categories":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/categories/Spring-Boot/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://nirajsonawane.github.io/tags/Spring-Boot/"},{"name":"Swagger","slug":"Swagger","permalink":"https://nirajsonawane.github.io/tags/Swagger/"},{"name":"Rest","slug":"Rest","permalink":"https://nirajsonawane.github.io/tags/Rest/"}]},{"title":"Junit 5 : Write Powerful Unit Test Cases Using Parameterized Tests","slug":"Junit-5-Write-Powerful-Unit-Test-Cases-Using-Parameterized-Tests","date":"2018-12-30T13:27:02.000Z","updated":"2018-12-30T12:50:00.000Z","comments":true,"path":"2018/12/30/Junit-5-Write-Powerful-Unit-Test-Cases-Using-Parameterized-Tests/","link":"","permalink":"https://nirajsonawane.github.io/2018/12/30/Junit-5-Write-Powerful-Unit-Test-Cases-Using-Parameterized-Tests/","excerpt":"","text":"unsplash-logoWellington Rodrigues JUnit 5Unlike previous versions of JUnit. JUnit 5 is complete rewrite and has lot of interesting architecture changes. JUnit 5 is not Single project but compose from three sub-projects: Jupiter, Vintage, and Platform. JUnit 5 = JUnit Platform + JUnit Jupiter + JUnit Vintage Check JUnit 5 User Guide For more details. You can find all code samples in on my GitHub Account In this post We will discuss Parameterized Tests in JUnit 5. Parameterized TestsJUnit 5 Parameterized Test are very powerful. With the help of Parameterized Test We can remove the duplication in test cases.Parameterized test cases can also help us to cleanup the test code and remove the cluter.As Name suggest Parameterized tests make it possible to run a test multiple times with different arguments. They are declared just like regular @Test methods but use the @ParameterizedTest annotation instead. In addition, you must declare at least one source that will provide the arguments for each invocation and then consume the arguments in the test method. Simple ParameterizedTestThe following example demonstrates a parameterized test that uses the @ValueSource annotation to specify a String array as the source of arguments. Test Case will be called 2 times with parameter Hello and World.Framework will be responsible for injecting parameter values Simple ParameterizedTest1234567 @ParameterizedTest @ValueSource(strings = &#123; \"Hello\", \"World\" &#125;) void withSomeValues(String word) &#123; System.out.println(word); assertNotNull(word);&#125; Display Names For ParameterizedTestJUnit 5 has added new annotation @DisplayName, Which helps to provide more readable names to test classes and methods.These names will be displayed by test runners and test reporting. Display Names12345678 @DisplayName(\"String should not be null\") @ParameterizedTest @ValueSource(strings = &#123; \"Hello\", \"World\" &#125;) void withSomeValues(String word) &#123; System.out.println(word); assertNotNull(word);&#125; But in case of Parameterized Test,Sometimes we might need to name test cases based on arguments. JUnit 5 provides index and arguments variable for thisDisplay Names For ParameterizedTest12345678 @ParameterizedTest(name = \"Null Check Test #&#123;index&#125; with [&#123;arguments&#125;]\") @ParameterizedTest @ValueSource(strings = &#123; \"Hello\", \"World\" &#125;) void withSomeValues(String word) &#123; System.out.println(word); assertNotNull(word);&#125; Sources of Arguments Out of the box, JUnit Jupiter provides number of Argument Source providers. @ValueSource @EnumSource @MethodSource @CsvSource @CsvFileSource @ArgumentsSource Let’s try one by one @EnumSource@EnumSource provides a convenient way to use Enum constants. This annotation provides an optional names parameter that lets you specify which constants shall be used. If omitted, all constants will be used like in the following example. EnumSource1234567 @ParameterizedTest(name = \"withSomeName #&#123;index&#125; with Value [&#123;arguments&#125;]\") @EnumSource(MyTestEnum.class) void withSomeEnum(MyTestEnum myEnum) &#123; System.out.println(myEnum); assertNotNull(myEnum);&#125; @MethodSource@MethodSource allows you to refer one or more factory methods of the test class or external classes. Method Source in Same class Factory methods within the test class must be static. Each factory method must generate a stream of arguments. MethodSource in Same Class1234567891011 @ParameterizedTest @MethodSource(\"createWordsWithLength\") void withMethodSource(String word, int length) &#123; System.out.println(\"withMethodSource\"); assertNotNull(word);&#125; private static Stream&lt;Arguments&gt; createWordsWithLength() &#123; return Stream.of(Arguments.of(\"Hello\", 5), Arguments.of(\"JUnit 5\", 7)); &#125; Method Source in Other class Factory methods in external classes must be static. Each factory method must generate a stream of arguments. Factory methods must not accept any arguments.MethodSource in external classes12345678910 @ParameterizedTest @MethodSource(\"com.niraj.MethodSource#stringProvider\") void withMethodSource(String word, int length) &#123; System.out.println(\"withMethodSource\"); assertNotNull(word);&#125;private static Stream&lt;Arguments&gt; createWordsWithLength() &#123; return Stream.of(Arguments.of(\"Hello\", 5), Arguments.of(\"JUnit 5\", 7));&#125; @CsvSourceAs name suggest @CsvSource allows you to express argument lists as comma-separated values (i.e., String literals).CsvSource12345 @ParameterizedTest @CsvSource(&#123; \"Hello, 5\", \"World, 5\", \"test,4\" &#125;) void withCsvSource(String word, int length) &#123; assertEquals(word.length(), length);&#125; @CsvFileSourceSimilar to @CsvSource We can also provide csv values using file from classpath @CsvFileSource. CsvFileSource12345 @ParameterizedTest @CsvFileSource(resources = \"/testdata.csv\") void withCsvFileSource(String word, int length) &#123; assertEquals(word.length(), length);&#125; ArgumentsSourceIf any of the above Source provider does not meet your requirement, then you can use your custom Argument Source provider. You will need to implement ArgumentsProvider Interface. ArgumentsSource123456 @ParameterizedTest @ArgumentsSource(StringArgumentsProvider.class) void testWithArgumentsSource(String argument) &#123; assertNotNull(argument); &#125; &#125; StringArgumentsProvider123456public class StringArgumentsProvider implements ArgumentsProvider &#123; @Override public Stream&lt;? extends Arguments&gt; provideArguments(ExtensionContext context) &#123; return Stream.of(\"Hello\", \"world\").map(Arguments::of); &#125; Argument Conversion In all above Test cases you might have observed that the arguments are getting converted to method parameter types. In all examples, arguments are getting converted to String. Who is converting these arguments ? What if we change it to int or any other types? What happens if incase we want to use any User Defined object ? Widening ConversionJUnit Jupiter supports Widening Primitive Conversion for arguments supplied to a @ParameterizedTest. For example, a parameterized test annotated with @ValueSource(ints = { 1, 2, 3 }) can be declared to accept not only an argument of type int but also an argument of type long, float, or double. Explicit ConversionWe Can Specify ArgumentConverter to convert to any user define object. In below example i wanted to convert String “niraj,sonawane” to Person object. ArgumentConverter12345678910111213141516171819202122 @ParameterizedTest @ValueSource(strings =&#123;\"niraj,sonawane\"&#125;) void withCustomConverter(@ConvertWith(PersonConverter.class) Person person) &#123; assertEquals(Person.getFirstName(),\"niraj\"); assertEquals(Person.getLastName(),\"sonawane\"); &#125; //Convert class public class PersonConverter implements ArgumentConverter &#123; @Override public Object convert(Object source, ParameterContext context) throws ArgumentConversionException &#123; if (source instanceof String) try &#123; String[] split = ((String) source).split(\",\"); return new Emp(split[0], split[1]); &#125; catch (NumberFormatException ex) &#123; String message = source + \" is no correct string representation of a Emp.\"; throw new ArgumentConversionException(message, ex); &#125; throw new ArgumentConversionException(source + \" is no valid point\"); &#125;&#125;","categories":[{"name":"Unit Testing","slug":"Unit-Testing","permalink":"https://nirajsonawane.github.io/categories/Unit-Testing/"}],"tags":[{"name":"JUnit-5","slug":"JUnit-5","permalink":"https://nirajsonawane.github.io/tags/JUnit-5/"},{"name":"Unit Testing","slug":"Unit-Testing","permalink":"https://nirajsonawane.github.io/tags/Unit-Testing/"}]},{"title":"Applying Reactive Programing to Existing Batch Application- RXJava2","slug":"Applying-Reactive-Programing-to-Existing-Batch-Application-RXJava2","date":"2018-12-06T09:40:55.000Z","updated":"2018-12-11T15:45:32.000Z","comments":true,"path":"2018/12/06/Applying-Reactive-Programing-to-Existing-Batch-Application-RXJava2/","link":"","permalink":"https://nirajsonawane.github.io/2018/12/06/Applying-Reactive-Programing-to-Existing-Batch-Application-RXJava2/","excerpt":"Today, I will share my experience of migrating our existing Spring batch application to reactive programing model using ReactiveX extensions.The goal is to explain, What is ReactiveX-RXjava2 and demonstrating Working example. What is ReactiveX And RxJavaReactiveX Is An API for asynchronous programming with observable streams.ReactiveX is a combination of the best ideas from the Observer pattern, the Iterator pattern, and functional programming. RxJava is the Java implementation of ReactiveX. RxJava provides Java API for asynchronous programming with observable streams.ReactiveX Why Reactive programming? For Me Reactive Programming is a development model focus around Asynchronous Data Streams. In Reactive programming, Data streams are the center part of your application. Mesages ,Events, Errors ,Event chains ,call etc are going to be conveyed As a data stream. Reactive programming provides a simple way of asynchronous programming. Migration Story","text":"Today, I will share my experience of migrating our existing Spring batch application to reactive programing model using ReactiveX extensions.The goal is to explain, What is ReactiveX-RXjava2 and demonstrating Working example. What is ReactiveX And RxJavaReactiveX Is An API for asynchronous programming with observable streams.ReactiveX is a combination of the best ideas from the Observer pattern, the Iterator pattern, and functional programming. RxJava is the Java implementation of ReactiveX. RxJava provides Java API for asynchronous programming with observable streams.ReactiveX Why Reactive programming? For Me Reactive Programming is a development model focus around Asynchronous Data Streams. In Reactive programming, Data streams are the center part of your application. Mesages ,Events, Errors ,Event chains ,call etc are going to be conveyed As a data stream. Reactive programming provides a simple way of asynchronous programming. Migration Story The Batch application was very traditional use case of file processing. Processing includes Multiple complex Steps.To Stimulate Similar processing with less complexity, I have created small Spring-Batch application that process csv file containing FirstName,LastName and Age. Processing includes below Steps. Validations - Age Should not be more than 100 years. Enrichment 1 - Upper Case First Name. Enrichment 2 - Upper Case Last Name. Segregation - Based on Age, Categories Person As Teenager, YoungAdult or Senior Citizens. Database Insert- Based on Age Group insert person in associate table. The complete source code Spring-Batch ImplementationThe complete source code RXJava2 Implementation Let’s Start with RXJava2 ImplementationBuilding blocks for RxJavaObservables Representing sources of dataSubscribers or observers listening to the observablesOperators Operators create Observables Or Transform data or operate on an Observable and return an Observable set of methods for modifying and composing the data. Step 1 : Creating Observable on Input FileObServable is Responsible for reading data from file and passing it to Subscriber.There are multiple ways by which we create Observable. For reading data from file we will use defer() operator.The defer() operator does not create the Observable until the observer subscribes, and create a fresh Observable for each observer. Create Observable1234567891011121314151617181920212223242526272829 Observable&lt;Person&gt; observable = Observable.defer(() -&gt; new CsvFileObservableSource(filePath))public class CsvFileObservableSource implements ObservableSource&lt;Person&gt; &#123; private static final Logger log = LoggerFactory.getLogger(CsvFileObservableSource.class); private final String filename; CsvFileObservableSource(String filename) &#123; this.filename = filename; &#125; @Override public void subscribe(Observer&lt;? super Person&gt; observer) &#123; try &#123; Files.lines(Paths.get(filename)).forEach(inputLine -&gt; &#123; String[] split = inputLine.split(\",\"); //Send data observer.onNext( Person.builder() .firstName(split[0]) .lastName(split[1]) .age(Integer.parseInt(split[2])) .build()); &#125;); observer.onComplete(); // No more data to be send &#125; catch (IOException e) &#123; observer.onError(e); // Some error , send error information to subscriber. &#125; &#125;&#125; Step 2 : Subscribe to Observableobservable.subscribe(onNext,onError,onComplete);Provide onNext,onError,onComplete consumersThe Subscriber will print the values line by line read from file.12345observable.subscribe( person -&gt; System.out::println, Throwable::printStackTrace, () -&gt; System.out::println(\"I am Done\"); ); Step 3 : Add Processing logic using OperatorsNow Process the elements read from the file using operators like filter &amp; map This is similar to java 8 stream.123456final Observable&lt;List&lt;Person&gt;&gt; observable = Observable.defer(() -&gt; new CsvFileObservableSource(filePath)) .filter(ValidationProcessor::process) .map(FirstNameProcessor::process) .map(LastNameProcessor::process) .map(AgeProcessor::process) .buffer(chunkSize);Note If you observe,Observable is of Type List&lt;Person&gt; instead of &lt;Person&gt; . This is because we want to process data in chunk and not as individual data item. This capability is provided by buffer operator. Bufferperiodically gather items emitted by an Observable into bundles and emit these bundles rather than emitting the items one at a time. Step 4 : Group Person elements and Insert in different TablesNow Based on Age, We want to Categories Person As Teenager, YoungAdult or Senior Citizens.GroupBy OperatorDivide an Observable into a set of Observables that each emit a different subset of items from the original Observable.123456789101112131415161718192021 Observable&lt;GroupedObservable&lt;String, Person&gt;&gt; groupObservable = Observable .defer(() -&gt; new CsvFileObservableSource(filePath)) .filter(ValidationProcessor::process) .map(FirstNameProcessor::process) .map(LastNameProcessor::process) .map(AgeProcessor::process) .groupBy(Person::getAgeGroup);groupObservable.subscribe(s -&gt; &#123; if (\"TEENAGER\".equals(s.getKey())) &#123; s.buffer(chunkSize).subscribe(daoServiceImpl::insertTeenagerList); &#125; if (\"YOUNGADULT\".equals(s.getKey())) &#123; s.buffer(chunkSize).subscribe(daoServiceImpl::insertYoungadultList); &#125; if (\"SENIORCITIZENS\".equals(s.getKey())) &#123; s.buffer(chunkSize).subscribe(daoServiceImpl::insertSeniorcitizensList); &#125; &#125;, Throwable::printStackTrace, () -&gt; &#123; System.out.println(\"File Processing Complited\"); &#125;);The complete source code RXJava2 Implementation There are other important aspect like Error Handling, Backpressure and Multithreading are not in scope of this article. I will try to cover them in upcoming articles.","categories":[{"name":"RXJava-2","slug":"RXJava-2","permalink":"https://nirajsonawane.github.io/categories/RXJava-2/"}],"tags":[{"name":"RXjava","slug":"RXjava","permalink":"https://nirajsonawane.github.io/tags/RXjava/"},{"name":"ReactiveX","slug":"ReactiveX","permalink":"https://nirajsonawane.github.io/tags/ReactiveX/"},{"name":"Functional Programming","slug":"Functional-Programming","permalink":"https://nirajsonawane.github.io/tags/Functional-Programming/"},{"name":"Reactive Programming","slug":"Reactive-Programming","permalink":"https://nirajsonawane.github.io/tags/Reactive-Programming/"},{"name":"Streams","slug":"Streams","permalink":"https://nirajsonawane.github.io/tags/Streams/"}]},{"title":"Spring Batch - Process Multiple Files Parallel","slug":"Spring-Batch-Process-Multiple-Files-Parallel","date":"2018-11-08T16:17:22.000Z","updated":"2018-12-11T15:49:44.000Z","comments":true,"path":"2018/11/08/Spring-Batch-Process-Multiple-Files-Parallel/","link":"","permalink":"https://nirajsonawane.github.io/2018/11/08/Spring-Batch-Process-Multiple-Files-Parallel/","excerpt":"Photo Credit Pixabay Today, We will discuss how we can Process Multiple Files Concurrently using Spring Batch. Prerequisite Basic knowledge of Spring &amp; Spring Batch Framework is Required. BackgroundSpring Batch is a lightweight, comprehensive batch framework designed to enable the development of robust batch applications vital for the daily operations of enterprise systems. Spring Batch builds upon the characteristics of the Spring Framework that people have come to expect (productivity, POJO-based development approach, and general ease of use), while making it easy for developers to access and leverage more advance enterprise services when necessary. Scaling and Parallel Processing Spring Batch Offers Multiple options for Scaling and Parallel Processing. At very high level these are separated in below categories. Multi-threaded Step Parallel Steps Remote Chunking Partitioning For Processing Multiple Files we will be using Partitioning. PartitioningThe Job is executing on the left hand side as a sequence of Steps, and one of the Steps is labelled as a Master. The Slaves in this picture are all identical instances of a Step, which could in fact take the place of the Master resulting in the same outcome for the Job. The Slaves are typically going to be remote services, but could also be local threads of execution. The messages sent by the Master to the Slaves in this pattern do not need to be durable, or have guaranteed delivery: Spring Batch meta-data in the JobRepository will ensure that each Slave is executed once and only once for each Job execution.If required, we can pass data from the master to the slave. The meta data (i.e. the JobRepository), makes sure that every slave is executed only once in a single execution of the Job.","text":"Photo Credit Pixabay Today, We will discuss how we can Process Multiple Files Concurrently using Spring Batch. Prerequisite Basic knowledge of Spring &amp; Spring Batch Framework is Required. BackgroundSpring Batch is a lightweight, comprehensive batch framework designed to enable the development of robust batch applications vital for the daily operations of enterprise systems. Spring Batch builds upon the characteristics of the Spring Framework that people have come to expect (productivity, POJO-based development approach, and general ease of use), while making it easy for developers to access and leverage more advance enterprise services when necessary. Scaling and Parallel Processing Spring Batch Offers Multiple options for Scaling and Parallel Processing. At very high level these are separated in below categories. Multi-threaded Step Parallel Steps Remote Chunking Partitioning For Processing Multiple Files we will be using Partitioning. PartitioningThe Job is executing on the left hand side as a sequence of Steps, and one of the Steps is labelled as a Master. The Slaves in this picture are all identical instances of a Step, which could in fact take the place of the Master resulting in the same outcome for the Job. The Slaves are typically going to be remote services, but could also be local threads of execution. The messages sent by the Master to the Slaves in this pattern do not need to be durable, or have guaranteed delivery: Spring Batch meta-data in the JobRepository will ensure that each Slave is executed once and only once for each Job execution.If required, we can pass data from the master to the slave. The meta data (i.e. the JobRepository), makes sure that every slave is executed only once in a single execution of the Job.Demo Application For processing Multiple Files Concurrently We will extend the Spring Batch Sample Application provided on Getting Stated guide Here Sample Application : Sample application imports data from a CSV spreadsheet, transforms it with custom code, and stores the final results in a database. We will add the capability of Processing Multiple Files Concurrently Step by Step. Defining Partitioner bean using MultiResourcePartitionerMultiResourcePartitioner is Implementation of Partitioner that locates multiple resources and associates their file names with execution context keys. Creates an ExecutionContext per resource, and labels them as {partition0, partition1, …, partitionN}.MultiResourcePartitioner Bean Configuration12345678910111213141516 @Bean(\"partitioner\")@StepScopepublic Partitioner partitioner() &#123; log.info(\"In Partitioner\"); MultiResourcePartitioner partitioner = new MultiResourcePartitioner(); ResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); Resource[] resources = null; try &#123; resources = resolver.getResources(\"/*.csv\"); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; partitioner.setResources(resources); partitioner.partition(10); return partitioner;&#125;Configuration of Master StepMaster Step & TaskExcecutor Configuration12345678910111213141516171819@Bean @Qualifier(\"masterStep\") public Step masterStep() &#123; return stepBuilderFactory.get(\"masterStep\") .partitioner(\"step1\", partitioner()) .step(step1()) .taskExecutor(taskExecutor()) .build(); &#125; @Bean public ThreadPoolTaskExecutor taskExecutor() &#123; ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor(); taskExecutor.setMaxPoolSize(10); taskExecutor.setCorePoolSize(10); taskExecutor.setQueueCapacity(10); taskExecutor.afterPropertiesSet(); return taskExecutor; &#125;Binding Input Data to Steps: Passing File NameThis can be done using StepScope feature of Spring Batch.StepScope Allows the late binding.We need to Read filename from the stepExecutionContext as shown below.FlatFileItemReader Configuration123456789101112131415161718 @Bean@StepScope@Qualifier(\"personItemReader\")public FlatFileItemReader&lt;Person&gt; personItemReader(@Value(\"#&#123;stepExecutionContext['fileName']&#125;\") String filename) throws MalformedURLException &#123; log.info(\"In Reader\"); return new FlatFileItemReaderBuilder&lt;Person&gt;() .name(\"personItemReader\") .delimited() .names(new String[] &#123; \"firstName\", \"lastName\" &#125;) .fieldSetMapper(new BeanWrapperFieldSetMapper&lt;Person&gt;() &#123; &#123; setTargetType(Person.class); &#125; &#125;) .resource(new UrlResource(filename)) .build();&#125;Configuration of slave StepSlave Step Configuration123456789 @Beanpublic Step step1() &#123; return stepBuilderFactory.get(\"step1\") .&lt;Person, Person&gt;chunk(10) .processor(processor()) .writer(writer) .reader(personItemReader) .build();&#125;Now if we Launch the application, In logs we can see each file is getting process by separate thread. References Spring Batch getting Started Scaling and Parallel ProcessingPartitioningGithub Link of Solution","categories":[{"name":"Spring-Batch","slug":"Spring-Batch","permalink":"https://nirajsonawane.github.io/categories/Spring-Batch/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://nirajsonawane.github.io/tags/Spring/"},{"name":"Spring-Batch","slug":"Spring-Batch","permalink":"https://nirajsonawane.github.io/tags/Spring-Batch/"}]},{"title":"Angular Material Tabs with Router","slug":"Angular-Material-Tabs-with-Router","date":"2018-10-27T07:58:55.000Z","updated":"2018-12-11T15:48:20.000Z","comments":true,"path":"2018/10/27/Angular-Material-Tabs-with-Router/","link":"","permalink":"https://nirajsonawane.github.io/2018/10/27/Angular-Material-Tabs-with-Router/","excerpt":"In this article, I will show you how to Use Angular Material Tab Component with Angular Routing. The Article is based on Angular 6.We will Create small application using angular cli and will add needed component step by step. Step 1: Create Angular 6 ProjectRun the command in angular cli1ng new angular-material-tab-router Step 2: Add Angular material to projectRun the command in angular cli1npm install --save @angular/material @angular/cdk @angular/animations Step 3: Add Angular PreBuild Theme to project.We will be using indigo-pink Theme.styless.css1@import \"~@angular/material/prebuilt-themes/indigo-pink.css\";","text":"In this article, I will show you how to Use Angular Material Tab Component with Angular Routing. The Article is based on Angular 6.We will Create small application using angular cli and will add needed component step by step. Step 1: Create Angular 6 ProjectRun the command in angular cli1ng new angular-material-tab-router Step 2: Add Angular material to projectRun the command in angular cli1npm install --save @angular/material @angular/cdk @angular/animations Step 3: Add Angular PreBuild Theme to project.We will be using indigo-pink Theme.styless.css1@import \"~@angular/material/prebuilt-themes/indigo-pink.css\"; Step 4: Add BrowserAnimationsModuleapp.module.ts1import &#123;BrowserAnimationsModule&#125; from '@angular/platform-browser/animations'; Step 5: Add Angular Material Toolbar &amp; Tabs.In the most situations, a Material toolbar will be placed at the top of your application and will only have a single row that includes the title of your application. app.component.html1234&lt;mat-toolbar color=\"primary\"&gt;&lt;span&gt; Angular Material App With Tab and Routing &lt;/span&gt;&lt;span class=\"example-fill-remaining-space\"&gt;&lt;/span&gt; &lt;/mat-toolbar&gt; Angular Material Tabs organize content into separate views where only one view can be visible at a time. Each tab’s label is shown in the tab header and the active tab’s label is designated with the animated ink bar. When the list of tab labels exceeds the width of the header, pagination controls appear to let the user scroll left and right across the labels.app.component.html12345&lt;mat-tab-group&gt;&lt;mat-tab label=&quot;First&quot;&gt; Content 1 &lt;/mat-tab&gt;&lt;mat-tab label=&quot;Second&quot;&gt; Content 2 &lt;/mat-tab&gt;&lt;mat-tab label=&quot;Third&quot;&gt; Content 3 &lt;/mat-tab&gt;&lt;/mat-tab-group&gt; Add corresponding imports in app.module.tsapp.module.ts123456789101112import &#123;MatToolbarModule&#125; from &apos;@angular/material/toolbar&apos;;import &#123;MatTabsModule&#125; from &apos;@angular/material/tabs&apos;;import &#123;BrowserAnimationsModule&#125; from &apos;@angular/platform-browser/animations&apos;; imports: [ BrowserModule, MatToolbarModule, MatTabsModule, BrowserAnimationsModule, AppRoutingModule, ], Now we have integrated Material MatTabsModule in our application. Start applicationng serve Step 6: Add Routing module to applicationAn Angular best practice is to load and configure the router in a separate, top-level module that is dedicated to routing and imported by the root AppModule.By convention, the module class name is AppRoutingModule and it belongs in the app-routing.module.ts in the src/app folder.Run the command in angular cli1234567ng generate module app-routing --flat --module=app//Also generate some test component using cli ng generate component componenet1ng generate component componenet2ng generate component componenet3 Step 7: Initialize and Add RoutesRoutes tell the router which view to display when a user clicks a link or pastes a URL into the browser address bar.A typical Angular Route has two properties: Path: a string that matches the URL in the browser address bar. Component: the component that the router should create when navigating to this route. This is how the app-routing.module.ts will look like after adding routes.app-routing.module.ts12345678910111213141516171819202122import &#123; NgModule &#125; from '@angular/core';import &#123; CommonModule &#125; from '@angular/common';import &#123; RouterModule, Routes &#125; from '@angular/router';import &#123; Componenet1Component &#125; from './componenet1/componenet1.component';import &#123; Componenet2Component &#125; from './componenet2/componenet2.component';import &#123; Componenet3Component &#125; from './componenet3/componenet3.component';const routes: Routes = [ &#123; path: '', redirectTo: '/first', pathMatch: 'full' &#125;, &#123; path: 'first', component: Componenet1Component&#125;, &#123; path: 'second', component: Componenet2Component&#125;, &#123; path: 'third', component: Componenet3Component&#125;,];export const appRouting = RouterModule.forRoot(routes);@NgModule(&#123; imports: [ RouterModule.forRoot(routes), CommonModule ], exports: [ RouterModule ], declarations: []&#125;)export class AppRoutingModule &#123; &#125; Step 7 : Tabs and NavigationWhile &lt;mat-tab-group&gt; is used to switch between views within a single route, &lt;nav mat-tab-nav-bar&gt; provides a tab-like UI for navigating between routes.let’s update &lt;mat-tab-group&gt; to &lt;nav mat-tab-nav-bar&gt; app.component.html12345678910&lt;nav mat-tab-nav-bar&gt;&lt;a mat-tab-link*ngFor=\"let link of navLinks\"[routerLink]=\"link.link\"routerLinkActive #rla=\"routerLinkActive\"[active]=\"rla.isActive\"&gt;&lt;/a&gt;&lt;/nav&gt;&lt;router-outlet&gt;&lt;/router-outlet&gt; Setup navLinks In the app.component.ts , I have initialized navLinks with a routeLinks array in the constructor. Also note that ngOnInit() function is responsible to maintaining Tab selection. AppComponent.ts1234567891011121314151617181920212223242526272829303132333435import &#123; Component &#125; from '@angular/core';import &#123;MatToolbarModule&#125; from '@angular/material/toolbar';import &#123; Router &#125; from '@angular/router';@Component(&#123; selector: 'app-root', templateUrl: './app.component.html', styleUrls: ['./app.component.css']&#125;)export class AppComponent &#123; title = 'angular-material-tab-router'; navLinks: any[]; activeLinkIndex = -1; constructor(private router: Router) &#123; this.navLinks = [ &#123; label: 'First', link: './first', index: 0 &#125;, &#123; label: 'Second', link: './second', index: 1 &#125;, &#123; label: 'Third', link: './third', index: 2 &#125;, ];&#125;ngOnInit(): void &#123; this.router.events.subscribe((res) =&gt; &#123; this.activeLinkIndex = this.navLinks.indexOf(this.navLinks.find(tab =&gt; tab.link === '.' + this.router.url)); &#125;);&#125;&#125; Working application will look like below References Material ComponentsAngular Github Link of Solution","categories":[{"name":"Angular","slug":"Angular","permalink":"https://nirajsonawane.github.io/categories/Angular/"}],"tags":[{"name":"Angular6","slug":"Angular6","permalink":"https://nirajsonawane.github.io/tags/Angular6/"},{"name":"Material","slug":"Material","permalink":"https://nirajsonawane.github.io/tags/Material/"},{"name":"Navigation","slug":"Navigation","permalink":"https://nirajsonawane.github.io/tags/Navigation/"},{"name":"Routing","slug":"Routing","permalink":"https://nirajsonawane.github.io/tags/Routing/"}]},{"title":"Java 8 Custom Collector","slug":"Java-8-Custom-Collector","date":"2018-09-11T06:22:10.000Z","updated":"2018-12-11T15:48:56.000Z","comments":true,"path":"2018/09/11/Java-8-Custom-Collector/","link":"","permalink":"https://nirajsonawane.github.io/2018/09/11/Java-8-Custom-Collector/","excerpt":"In this Article , we’ll Discuss How we can Create our own Custom Collector in java 8 and above.For this article, We will implement Summary Statistics For BigDecimal number. Java 8 Summary StatisticsJava 8 Provides Summary Statistics for Long,Int &amp; Double. These Summary classes will help you to get count, min, max, sum, and average values. LongSummaryStatistics IntSummaryStatistics DoubleSummaryStatistics IntSummaryStatistics ExampleIn below example we are trying to calculate count, min, max, sum, and average of 1 to 100 Integer. Calculate Sum,Min,Max,Count & Average12345IntSummaryStatistics summaryStatistics = IntStream.range(1, 101) .summaryStatistics(); System.out.println(summaryStatistics);","text":"In this Article , we’ll Discuss How we can Create our own Custom Collector in java 8 and above.For this article, We will implement Summary Statistics For BigDecimal number. Java 8 Summary StatisticsJava 8 Provides Summary Statistics for Long,Int &amp; Double. These Summary classes will help you to get count, min, max, sum, and average values. LongSummaryStatistics IntSummaryStatistics DoubleSummaryStatistics IntSummaryStatistics ExampleIn below example we are trying to calculate count, min, max, sum, and average of 1 to 100 Integer. Calculate Sum,Min,Max,Count & Average12345IntSummaryStatistics summaryStatistics = IntStream.range(1, 101) .summaryStatistics(); System.out.println(summaryStatistics); implementing SummaryStatistics for Big Decimal numbersJava does not provides inbuilt Summary Statistics class for BigDecimal Number. Lets try to implement our own BigDecimal SummaryStatistics. Step 1 : Create Collector Calculate Sum,Min,Max,Count & Average123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112import java.math.BigDecimal;import java.util.function.Consumer;import java.util.stream.Collector;public class MyBigDecimalSummaryCollector implements Consumer&lt;BigDecimal&gt; &#123; public static final int ROUND_HALF_UP = BigDecimal.ROUND_HALF_UP; public static final Integer TRANSACTIONS_SCALE = 2; private BigDecimal sum = BigDecimal.ZERO.setScale(TRANSACTIONS_SCALE, ROUND_HALF_UP); private BigDecimal minimum = BigDecimal.ZERO.setScale(TRANSACTIONS_SCALE, ROUND_HALF_UP); private BigDecimal maximum = BigDecimal.ZERO.setScale(TRANSACTIONS_SCALE, ROUND_HALF_UP); private int count; public static Collector&lt;BigDecimal, ?, MyBigDecimalSummaryCollector&gt; myBigDecimalSummaryStatistics() &#123; return Collector.of(MyBigDecimalSummaryCollector::new, MyBigDecimalSummaryCollector::accept, MyBigDecimalSummaryCollector::merge); &#125; @Override public void accept(BigDecimal t) &#123; if (count == 0) &#123; firstElementSetup(t); &#125; else &#123; sum = sum.add(t); minimum = minimum.min(t); maximum = maximum.max(t); count++; &#125; &#125; public MyBigDecimalSummaryCollector merge(MyBigDecimalSummaryCollector s) &#123; if (s.count &gt; 0) &#123; if (count == 0) &#123; setupFirstElement(s); &#125; else &#123; sum = sum.add(s.sum); minimum = minimum.min(s.minimum); maximum = maximum.max(s.maximum); count += s.count; &#125; &#125; return this; &#125; private void setupFirstElement(MyBigDecimalSummaryCollector s) &#123; count = s.count; sum = s.sum; minimum = s.minimum; maximum = s.maximum; &#125; private void firstElementSetup(BigDecimal t) &#123; count = 1; sum = t; minimum = t; maximum = t; &#125; public BigDecimal getAverage() &#123; if (count == 0) &#123; return BigDecimal.ZERO.setScale(TRANSACTIONS_SCALE, ROUND_HALF_UP); &#125; return sum.divide(BigDecimal.valueOf(count), TRANSACTIONS_SCALE, ROUND_HALF_UP); &#125; public BigDecimal getSum() &#123; return sum; &#125; public void setSum(BigDecimal sum) &#123; this.sum = sum; &#125; public BigDecimal getMinimum() &#123; return minimum; &#125; public void setMinimum(BigDecimal minimum) &#123; this.minimum = minimum; &#125; public BigDecimal getMaximum() &#123; return maximum; &#125; public void setMaximum(BigDecimal maximum) &#123; this.maximum = maximum; &#125; public int getCount() &#123; return count; &#125; public void setCount(int count) &#123; this.count = count; &#125; @Override public String toString() &#123; return \"MyBigDecimalSummaryCollector [sum=\" + sum + \", minimum=\" + minimum + \", maximum=\" + maximum + \", count=\" + count + \"]\"; &#125;&#125; Step 2 : Use Collector1234567MyBigDecimalSummaryCollector collect = IntStream.range(1, 101) .mapToObj(number -&gt; BigDecimal.valueOf(number)) .collect(MyBigDecimalSummaryCollector.myBigDecimalSummaryStatistics()); System.out.println(collect);","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"Collector","slug":"Java-8/Collector","permalink":"https://nirajsonawane.github.io/categories/Java-8/Collector/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Java-9","slug":"Java-9","permalink":"https://nirajsonawane.github.io/tags/Java-9/"},{"name":"Collector","slug":"Collector","permalink":"https://nirajsonawane.github.io/tags/Collector/"},{"name":"Bigdecimal","slug":"Bigdecimal","permalink":"https://nirajsonawane.github.io/tags/Bigdecimal/"},{"name":"Summary Statistics","slug":"Summary-Statistics","permalink":"https://nirajsonawane.github.io/tags/Summary-Statistics/"}]},{"title":"Sort Map by Value using Custom Comparator","slug":"Sort-Map-by-Value-using-Custom-Comparator","date":"2018-09-10T12:03:33.000Z","updated":"2018-09-10T22:46:48.000Z","comments":true,"path":"2018/09/10/Sort-Map-by-Value-using-Custom-Comparator/","link":"","permalink":"https://nirajsonawane.github.io/2018/09/10/Sort-Map-by-Value-using-Custom-Comparator/","excerpt":"","text":"In this Article , we’ll Discuss How we can Sort map by Value using Comparator in java 8. Name class as key of HashMap12345public class Name &#123; private String firstName; private String lastName; //builder &#125; Name class as key of HashMap123456 public class Age &#123; private Integer year; private Integer month; //builder&#125; We want to sort Map by Age.Year. Sort map by value using Comparator123456789101112131415161718192021222324252627282930 Map&lt;Name, Age&gt; map = new HashMap&lt;&gt;();Name name0 = Name.builder().firstName(\"Zendor\").lastName(\"Sonawane\").build();Name name1 = Name.builder().firstName(\"Niraj\").lastName(\"Sonawane\").build();Name name2 = Name.builder().firstName(\"Pratik\").lastName(\"Sonawane\").build();Name name3 = Name.builder().firstName(\"Jeetesh\").lastName(\"Sonawane\").build();Name name4 = Name.builder().firstName(\"Rahul\").lastName(\"Sonawane\").build();Name name5 = Name.builder().firstName(\"Amit\").lastName(\"Sonawane\").build();Age age0 = Age.builder().year(30).month(5).build();Age age1 = Age.builder().year(66).month(3).build();Age age2 = Age.builder().year(17).month(6).build();Age age3 = Age.builder().year(3).month(5).build();Age age4 = Age.builder().year(50).month(5).build();Age age5 = Age.builder().year(80).month(12).build();map.put(name0,age0);map.put(name1,age1);map.put(name2,age2);map.put(name3,age3);map.put(name4,age4);map.put(name5,age5);Comparator&lt;Age&gt; byAge = (Age obj1,Age obj2) -&gt; obj1.getYear().compareTo(obj2.getYear());LinkedHashMap&lt;Name, Age&gt; sortedMap = map.entrySet().stream() .sorted(Map.Entry.&lt;Name,Age&gt;comparingByValue(byAge)) .collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue,(e1,e2)-&gt;e1,LinkedHashMap::new)); Source Code Github Link","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"Stream","slug":"Java-8/Stream","permalink":"https://nirajsonawane.github.io/categories/Java-8/Stream/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Stream","slug":"Stream","permalink":"https://nirajsonawane.github.io/tags/Stream/"},{"name":"Map","slug":"Map","permalink":"https://nirajsonawane.github.io/tags/Map/"},{"name":"Sorting","slug":"Sorting","permalink":"https://nirajsonawane.github.io/tags/Sorting/"},{"name":"Comparator","slug":"Comparator","permalink":"https://nirajsonawane.github.io/tags/Comparator/"}]},{"title":"Sort Map by key using Custom Comparator","slug":"Sort-Map-by-key-using-Custom-Comparator","date":"2018-09-10T12:03:18.000Z","updated":"2018-09-10T22:16:34.000Z","comments":true,"path":"2018/09/10/Sort-Map-by-key-using-Custom-Comparator/","link":"","permalink":"https://nirajsonawane.github.io/2018/09/10/Sort-Map-by-key-using-Custom-Comparator/","excerpt":"","text":"In this Article , we’ll Discuss How we can Sort map by Custom key or Comparator in java 8. We want to sort below Map by FirstName. Name object is used as key for Map. Name class as key of HashMap12345public class Name &#123; private String firstName; private String lastName; //builder &#125; Sort map by Key using Comparator123456789101112131415 Map&lt;Name, Integer&gt; map = new HashMap&lt;&gt;();Name name0 = Name.builder().firstName(\"Zendor\").lastName(\"Sonawane\").build();Name name1 = Name.builder().firstName(\"Niraj\").lastName(\"Sonawane\").build();Name name2 = Name.builder().firstName(\"Pratik\").lastName(\"Sonawane\").build();Name name3 = Name.builder().firstName(\"Jeetesh\").lastName(\"Sonawane\").build();Name name4 = Name.builder().firstName(\"Rahul\").lastName(\"Sonawane\").build();Name name5 = Name.builder().firstName(\"Amit\").lastName(\"Sonawane\").build();map.put(name0,55);map.put(name1,1);map.put(name2,2);map.put(name3,3);map.put(name4,4);map.put(name5,5); This is how we can do that Sort map by Key using Comparator123456Comparator&lt;Name&gt; byName = (Name o1, Name o2)-&gt; o1.getFirstName().compareTo(o2.getFirstName()); LinkedHashMap&lt;Name, Integer&gt; sortedMap = map.entrySet().stream() .sorted(Map.Entry.&lt;Name,Integer&gt;comparingByKey(byName)) .collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue,(e1,e2)-&gt;e1,LinkedHashMap::new)); Source Code Github Link","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"Stream","slug":"Java-8/Stream","permalink":"https://nirajsonawane.github.io/categories/Java-8/Stream/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Stream","slug":"Stream","permalink":"https://nirajsonawane.github.io/tags/Stream/"},{"name":"Map","slug":"Map","permalink":"https://nirajsonawane.github.io/tags/Map/"},{"name":"Sorting","slug":"Sorting","permalink":"https://nirajsonawane.github.io/tags/Sorting/"},{"name":"Comparator","slug":"Comparator","permalink":"https://nirajsonawane.github.io/tags/Comparator/"}]},{"title":"Java Stream - Sort map by value","slug":"Java-Stream-Sort-map-by-value","date":"2018-09-09T21:55:43.000Z","updated":"2018-09-10T21:56:46.000Z","comments":true,"path":"2018/09/09/Java-Stream-Sort-map-by-value/","link":"","permalink":"https://nirajsonawane.github.io/2018/09/09/Java-Stream-Sort-map-by-value/","excerpt":"","text":"In this Article , we’ll Discuss How we can Sort map by Value in java 8. We want to sort below Map by ValueSort map by Value1234567Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); map.put(\"Niraj\", 6); map.put(\"Rahul\", 43); map.put(\"Ram\", 44); map.put(\"Sham\", 33); map.put(\"Pratik\", 5); map.put(\"Ashok\", 5); Map Sorting using comparingByValue in Ascending orderSort map by Value Ascending order1234Map&lt;String, Integer&gt; sortedMapByValueAscending = map.entrySet().stream() .sorted(Map.Entry.comparingByValue()) .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, (e1, e2) -&gt; e1,LinkedHashMap::new)); Map Sorting using comparingByValue in Descending order. For Descending order you need to use reversed()Sort map by Value Descending order1234Map&lt;String, Integer&gt; sortedMapByValueDescending = map.entrySet().stream() .sorted(Map.Entry.&lt;String,Integer&gt;comparingByValue().reversed()) .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, (e1, e2) -&gt; e1 ,LinkedHashMap::new)); Source Code Github Link","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"Stream","slug":"Java-8/Stream","permalink":"https://nirajsonawane.github.io/categories/Java-8/Stream/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Stream","slug":"Stream","permalink":"https://nirajsonawane.github.io/tags/Stream/"},{"name":"Map","slug":"Map","permalink":"https://nirajsonawane.github.io/tags/Map/"},{"name":"Sorting","slug":"Sorting","permalink":"https://nirajsonawane.github.io/tags/Sorting/"}]},{"title":"Java Stream - Sort map by key","slug":"Java-Stream-Sort-map-by-key","date":"2018-09-09T21:55:24.000Z","updated":"2018-10-30T07:38:20.000Z","comments":true,"path":"2018/09/09/Java-Stream-Sort-map-by-key/","link":"","permalink":"https://nirajsonawane.github.io/2018/09/09/Java-Stream-Sort-map-by-key/","excerpt":"","text":"Photo by Anton Lecock on UnsplashIn this Article , we’ll Discuss How we can Sort map by key in java 8.We want to sort below Map by keySort map by Key1234567Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); map.put(\"Niraj\", 6); map.put(\"Rahul\", 43); map.put(\"Ram\", 44); map.put(\"Sham\", 33); map.put(\"Pratik\", 5); map.put(\"Ashok\", 5); Map Sorting using comparingByKey in Ascending orderSort map by Key Ascending order1234Map&lt;String, Integer&gt; sortedMapByValueAscending = map.entrySet() .stream().sorted(Map.Entry.comparingByKey()) .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, (e1, e2) -&gt; e1,LinkedHashMap::new)); Map Sorting using comparingByKey in Descending order. For Descending order you need to use reversed()Sort map by Key Descending order1234Map&lt;String, Integer&gt; sortedMapByValueDescending = map.entrySet() .stream().sorted(Map.Entry.&lt;String,Integer&gt;comparingByKey().reversed()) .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue, (e1, e2) -&gt; e1 ,LinkedHashMap::new)); Source Code Github Link","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"Stream","slug":"Java-8/Stream","permalink":"https://nirajsonawane.github.io/categories/Java-8/Stream/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Stream","slug":"Stream","permalink":"https://nirajsonawane.github.io/tags/Stream/"},{"name":"Map","slug":"Map","permalink":"https://nirajsonawane.github.io/tags/Map/"},{"name":"Sorting","slug":"Sorting","permalink":"https://nirajsonawane.github.io/tags/Sorting/"}]},{"title":"Angular pipes","slug":"Angular-pipes","date":"2018-08-05T18:03:17.000Z","updated":"2018-10-27T22:49:40.000Z","comments":true,"path":"2018/08/05/Angular-pipes/","link":"","permalink":"https://nirajsonawane.github.io/2018/08/05/Angular-pipes/","excerpt":"","text":"Angular Pipes are used to transforms texts.A pipe takes in data as input and transforms it to a desired output LowerCase PipeTransforms text to all lower case. It is used as follows. {{value_expression | lowercase }} UpperCase PipeTransforms text to all Upper case. It is used as follows. {{ value_expression | uppercase }} TitleCasePipeTransforms text to title case. Capitalizes the first letter of each word, and transforms the rest of the word to lower case. Words are delimited by any whitespace character, such as a space, tab, or line-feed character. {{ value_expression | titlecase }} Date PipeConverts the Date to human-friendly date CurrencyPipeTransforms a number to a currency string, formatted according to locale rules that determine group sizing and separator, decimal-point character, and other locale-specific configurations.","categories":[{"name":"Angular","slug":"Angular","permalink":"https://nirajsonawane.github.io/categories/Angular/"}],"tags":[{"name":"Angular6","slug":"Angular6","permalink":"https://nirajsonawane.github.io/tags/Angular6/"},{"name":"Pipes","slug":"Pipes","permalink":"https://nirajsonawane.github.io/tags/Pipes/"}]},{"title":"Kotlin Smart Casts","slug":"Kotlin-Smart-Casts","date":"2018-07-30T20:16:36.000Z","updated":"2018-07-31T13:59:46.000Z","comments":true,"path":"2018/07/30/Kotlin-Smart-Casts/","link":"","permalink":"https://nirajsonawane.github.io/2018/07/30/Kotlin-Smart-Casts/","excerpt":"","text":"Many times while working we need to check if an object is of certain type at runtime. In java we have instanceof operator to check whether the object is an instance of the specified type. instanceof Java Example123456public class InstanceofExample &#123; public static void main(String[] args) &#123; MyClass obj=new MyClass(); System.out.println(obj instanceof MyClass);//true &#125;&#125; In Kotlin, You can check whether an object is of a certain type at runtime by using the is operator. is operator Kotlin Example123456789if (obj is String) &#123; print(obj.length)&#125;if (obj !is String) &#123; // same as !(obj is String)print(\"Not a String\")&#125;else &#123;print(obj.length)&#125; Smart CastsKotlin Complier is quite smart and help us to avoid boilerplate code. In many cases we do not need to use explicit cast operators , because the compiler tracks the is -checks and explicit casts for immutable values and inserts (safe) casts automatically when needed: Smart Casts Kotlin Example12345fun demo(x: Any) &#123; if (x is String) &#123; print(x.length) // x is automatically cast to String &#125;&#125; The compiler is smart enough to know a cast to be safe if a negative check leads to a return:Smart Casts Kotlin Example12if (x !is String) return print(x.length) // x is automatically cast to String Such smart casts work for when-expressions and while-loops as well:Smart Casts Kotlin Example12345when (x) &#123; is Int -&gt; print(x + 1) is String -&gt; print(x.length + 1) is IntArray -&gt; print(x.sum()) &#125;","categories":[{"name":"Kotlin","slug":"Kotlin","permalink":"https://nirajsonawane.github.io/categories/Kotlin/"}],"tags":[{"name":"Kotlin","slug":"Kotlin","permalink":"https://nirajsonawane.github.io/tags/Kotlin/"},{"name":"Smart Casts","slug":"Smart-Casts","permalink":"https://nirajsonawane.github.io/tags/Smart-Casts/"},{"name":"Kotlin Types","slug":"Kotlin-Types","permalink":"https://nirajsonawane.github.io/tags/Kotlin-Types/"}]},{"title":"Remove Optional Empty/Null values from list","slug":"Remove-Optional-Empty-null-values-from-list","date":"2018-06-21T09:49:10.000Z","updated":"2018-07-31T06:09:44.000Z","comments":true,"path":"2018/06/21/Remove-Optional-Empty-null-values-from-list/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/21/Remove-Optional-Empty-null-values-from-list/","excerpt":"","text":"In this Article , we’ll Discuss, How we can Convert Stream of Optional elements to a Stream of present value elements. Java 8 has added Optional type to avoid null pointer exception. lets say we have List&lt;Optional&lt;String&gt;&gt; and for further processing we want List&lt;Strings&gt;.In This case we need to remove the null and empty elements from stream and convert it into a Stream of present value elements. Convert Stream of Optional elements to a Stream of present value elements123456789101112131415161718//Input List List&lt;Optional&lt;String&gt;&gt; list = new ArrayList&lt;&gt;();list.add(Optional.empty());list.add(Optional.of(\"Str1\"));list.add(Optional.of(\"Str2\"));list.add(Optional.empty());list.add(Optional.ofNullable(null));//Using FilterList&lt;String&gt; listWithoutNull = list.stream() .filter(Optional::isPresent) .map(obj -&gt;obj.get()) .collect(Collectors.toList());//Using removeIf (if that list supports removal ) list.removeIf(iteam-&gt;!iteam.isPresent()); Java 9In java 9 We can easily convert Stream of optionals to a stream of present values.Using newly addded Optional::stream API java 9123List&lt;String&gt; listWithoutNull = list.stream() .flatMap(Optional::stream) .collect(Collectors.toList());","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"Stream","slug":"Java-8/Stream","permalink":"https://nirajsonawane.github.io/categories/Java-8/Stream/"},{"name":"Filter","slug":"Java-8/Stream/Filter","permalink":"https://nirajsonawane.github.io/categories/Java-8/Stream/Filter/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Java-9","slug":"Java-9","permalink":"https://nirajsonawane.github.io/tags/Java-9/"},{"name":"Optional","slug":"Optional","permalink":"https://nirajsonawane.github.io/tags/Optional/"},{"name":"Filter","slug":"Filter","permalink":"https://nirajsonawane.github.io/tags/Filter/"}]},{"title":"Exchanger","slug":"Exchanger","date":"2018-06-18T16:05:57.000Z","updated":"2018-06-20T15:43:16.000Z","comments":true,"path":"2018/06/18/Exchanger/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/18/Exchanger/","excerpt":"","text":"This Article is part of Series of Articles on Java 8 Concurrency Tutorial.In this article, we’ll focus on a the concept of Exchanger in the Java language. ExchangerThe exchanger class provides a kind of point for two threads, where threads can exchange their objects with other threads.An Exchanger may be viewed as a bidirectional form of a SynchronousQueue. Exchangers may be useful in applications such as genetic algorithms and pipeline designs.When a thread arrives at an exchange point, it is necessary to wait for another thread to arrive. When other partners come in threads, two threads go forward to exchange threads. In below example two threads are passing Integer values to each others. Both the Thread will wait until they receive the Information Exchanger Example12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class FirstThread implements Runnable &#123; private Exchanger&lt;Integer&gt; exchanger; public FirstThread(Exchanger&lt;Integer&gt; exchanger) &#123; this.exchanger = exchanger; &#125; @Override public void run() &#123; try &#123; System.out.println(\"Passing information form FirstThread\"); Integer exchange = exchanger.exchange(99); System.out.println(\"Information Sent From FirstThread\"); System.out.println(\"Received information from Second Thread.\" + exchange); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class SecondThread implements Runnable &#123; private Exchanger&lt;Integer&gt; exchanger; public SecondThread(Exchanger&lt;Integer&gt; exchanger) &#123; this.exchanger = exchanger; &#125; @Override public void run() &#123; System.out.println(\"Receiving information from First Thread.\"); try &#123; Integer exchange = exchanger.exchange(2); System.out.println(\"Received information from first Thread.\" + exchange); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;public class ExchangerExample &#123; public static void main(String[] args) &#123; Exchanger&lt;Integer&gt; exchanger = new Exchanger&lt;&gt;(); ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(2); newFixedThreadPool.submit(new FirstThread(exchanger)); newFixedThreadPool.submit(new SecondThread(exchanger)); newFixedThreadPool.shutdown(); &#125;&#125;","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"BlockingQueue","slug":"BlockingQueue","date":"2018-06-18T13:27:41.000Z","updated":"2018-06-19T01:55:18.000Z","comments":true,"path":"2018/06/18/BlockingQueue/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/18/BlockingQueue/","excerpt":"","text":"This Article is part of Series of Articles on Java 8 Concurrency Tutorial.In this article, we’ll focus on a the concept of BlockingQueue in the Java language. BlockingQueueA Queue that additionally supports operations that wait for the queue to become non-empty when retrieving an element, and wait for space to become available in the queue when storing an element. A BlockingQueue may be capacity bounded. At any given time it may have a remainingCapacity beyond which no additional elements can be put without blocking. A BlockingQueue without any intrinsic capacity constraints always reports a remaining capacity of Integer.MAX_VALUE. BlockingQueue implementations are thread-safe. All queuing methods achieve their effects atomically using internal locks or other forms of concurrency control. However, the bulk Collection operations addAll, containsAll, retainAll and removeAll are not necessarily performed atomically unless specified otherwise in an implementation. So it is possible, for example, for addAll(c) to fail (throwing an exception) after adding only some of the elements in c. let’s implement Producer and Consumer Problem using BlockingQueue BlockingQueue Example1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class BlockingQueueProducer implements Runnable&#123; private BlockingQueue&lt;Integer&gt; blockingQueue; private Random random; public BlockingQueueProducer(BlockingQueue&lt;Integer&gt; blockingQueue) &#123; this.blockingQueue=blockingQueue; this.random = new Random(); &#125; @Override public void run() &#123; while(true) &#123; System.out.println(\"BlockingQueueProducer - Adding Elements\"); try &#123; blockingQueue.put(random.nextInt(3000)); System.out.println(\"Added Element : Current Size of Q \" + blockingQueue.size()); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;class BlockingQueueConsumer implements Runnable&#123; BlockingQueue&lt;Integer&gt; blockingQueue; public BlockingQueueConsumer(BlockingQueue&lt;Integer&gt; blockingQueue) &#123; this.blockingQueue=blockingQueue; &#125; @Override public void run() &#123; while (true) &#123; try &#123; System.out.println(\"BlockingQueueConsumer : iteam recived from Q \" + blockingQueue.take() ); Thread.sleep(2500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;public class BlockingQueueExample &#123; public static void main(String[] args) &#123; BlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(5); ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(2); newFixedThreadPool.submit(new BlockingQueueConsumer(blockingQueue)); newFixedThreadPool.submit(new BlockingQueueProducer(blockingQueue)); newFixedThreadPool.shutdown(); &#125;&#125; Key Pointsput(E e)Inserts the specified element into this queue, waiting if necessary for space to become available. take()Retrieves and removes the head of this queue, waiting if necessary until an element becomes available. poll()Retrieves and removes the head of this queue, waiting up to the specified wait time if necessary for an element to become available.","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"CyclicBarrier","slug":"CyclicBarrier","date":"2018-06-18T08:27:26.000Z","updated":"2018-06-18T23:22:20.000Z","comments":true,"path":"2018/06/18/CyclicBarrier/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/18/CyclicBarrier/","excerpt":"","text":"This Article is part of Series of Articles on Java 8 Concurrency Tutorial.In this article, we’ll focus on a the concept of CyclicBarrier in the Java language. CyclicBarrierCyclicBarrier allows a set of threads to all wait for each other to reach a common barrier point. CyclicBarriers are useful in programs involving a fixed sized party of threads that must occasionally wait for each other. The barrier is called cyclic because it can be re-used after the waiting threads are released. CyclicBarrier are Similar to CountDownLatch but CyclicBarrier provide some additional features likeReseting CyclicBarrier &amp; Supports an optional Runnable command that is run once per barrier point. CyclicBarrier Example123456789101112131415161718192021222324252627282930313233343536class CyclicBarrierWorker implements Runnable&#123; private CyclicBarrier cyclicBarrier; private int workerId; private Random random; public CyclicBarrierWorker(CyclicBarrier cyclicBarrier ,int id) &#123; this.cyclicBarrier=cyclicBarrier; this.workerId=id; this.random = new Random(); &#125; @Override public void run() &#123; System.out.println(\"Starting worker ID \" + this.workerId); try &#123; Thread.sleep(random.nextInt(4000)); System.out.println(\"Worker \" + workerId + \" Completed it's work, Reducing count of cyclicBarrier \" ); cyclicBarrier.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; &#125;public class CyclicBarrierExample &#123; public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(5, ()-&gt;System.out.println(\"Barrier point reach ::: All Task Completed\")); ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(10); IntStream.range(1,6) .forEach(cnt-&gt;&#123;newFixedThreadPool.submit(new CyclicBarrierWorker(cyclicBarrier, cnt)); &#125;); System.out.println(\"All Task Submited\"); newFixedThreadPool.shutdown(); &#125; &#125;&#125; Key PointsCyclicBarrier(int parties, Runnable barrierAction) :Creates a new CyclicBarrier that will trip when the given number of parties (threads) are waiting upon it, and which will execute the given barrier action when the barrier is tripped, performed by the last thread entering the barrier. getNumberWaiting()Returns the number of parties currently waiting at the barrier. resetResets the barrier to its initial state.","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"CountDownLatch","slug":"CountDownLatch","date":"2018-06-17T16:02:44.000Z","updated":"2018-06-21T19:52:38.000Z","comments":true,"path":"2018/06/17/CountDownLatch/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/17/CountDownLatch/","excerpt":"","text":"This Article is part of Series of Articles on Java 8 Concurrency Tutorial.In this article, we’ll focus on a the concept of CountDownLatch in the Java language. CountDownLatchCountDownLatch enables a java thread to wait until other set of threads completes their tasks. A CountDownLatch is initialized with a given count.The await methods block until the current count reaches zero due to invocations of the countDown() method, after which all waiting threads are released and any subsequent invocations of await return immediately.This is a one-shot phenomenon – the count cannot be reset. If you need a version that resets the count, consider using a CyclicBarrier. e.g. Assume we have divided one task in 5 small independent task.Now main thread should wait, till other 5 Threads finish there work.In these scenarios CountDownLatch can be used. CountDownLatch Example1234567891011121314151617181920212223242526272829303132333435class CountDownLatchWorker implements Runnable&#123; private CountDownLatch countDownLatch; private int workerId; public CountDownLatchWorker(CountDownLatch countDownLatch ,int workerId) &#123; this.countDownLatch=countDownLatch; this.workerId=workerId; &#125; @Override public void run() &#123; System.out.println(\"Worker \" + workerId + \" Started\" ); try &#123; Thread.sleep(workerId*1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"Worker \" + workerId + \" Completed it's work, Reducing count of countDownLatch \" ); countDownLatch.countDown(); &#125; &#125;public class CountDownLatchExample &#123; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(5); ExecutorService newCachedThreadPool = Executors.newCachedThreadPool(); IntStream.range(1, 6) .forEach(cnt -&gt; &#123; newCachedThreadPool.submit(new CountDownLatchWorker(countDownLatch, cnt)); &#125;); System.out.println(\"Main Thread is wating for workers to finish!!!!!!\"); countDownLatch.await(); System.out.println(\"Work of All Worker is Completed\"); newCachedThreadPool.shutdown(); &#125;&#125; Key Pointsawait MethodCauses the current thread to wait until the latch has counted down to zero, unless the thread is interrupted.If the current count is zero then this method returns immediately.If the current count is greater than zero then the current thread becomes disabled for thread scheduling purposes and lies dormant until one of two things happen: countDown MethodDecrements the count of the latch, releasing all waiting threads if the count reaches zero.If the current count is greater than zero then it is decremented. If the new count is zero then all waiting threads are re-enabled for thread scheduling purposes.If the current count equals zero then nothing happens.","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"Callable and Future","slug":"Callable-and-Future","date":"2018-06-17T10:27:03.000Z","updated":"2018-06-18T01:52:26.000Z","comments":true,"path":"2018/06/17/Callable-and-Future/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/17/Callable-and-Future/","excerpt":"","text":"This Article is part of Series of Articles on Java 8 Concurrency Tutorial.In this quick article, we’ll focus on a the concept of Callable &amp; Future in the Java language. CallableThe Callable interface represents a thread that can return the value. It’s the same as the Runnable interface but can return the value.The callable interface can be used to Compute the value and return it to invoking thread. FutureFutureis generic interface that represents value which will be returned by callable interface.There are two methods to get actual value from Future.get() : When this method is called, thread will wait for result indefinitely.V get(long timeout, TimeUnit unit) : When this method is called, thread will wait for result only for specified time. Callable Example12345678910111213141516171819202122232425class CallableWorkerExample implements Callable&lt;String&gt;&#123; private String someReturnValue; public CallableWorkerExample(String someValue) &#123; this.someReturnValue=someValue; &#125; @Override public String call() throws Exception &#123; System.out.println(\"Working on call\"); Thread.sleep(3000); return this.someReturnValue; &#125; &#125;public class CallableAndFuture &#123; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; CallableWorkerExample worker= new CallableWorkerExample(\"Some Value\"); ExecutorService newSingleThreadExecutor = Executors.newSingleThreadExecutor(); Future&lt;String&gt; submit = newSingleThreadExecutor.submit(worker); System.out.println(\"Task Submited\"); String returnValue = submit.get(); System.out.println(\"Return value from Callable \" +returnValue); &#125;&#125; Key PointsException HandlingRunnable.run method does not throws exceptions but Callable.call method throws exception.ExecutorServiceExecutorService.submit Submits a value-returning task for execution and returns a Future representing the pending results of the task.submitMethod can take Callable and Runnable task as input.But the execute Method Discussed in ExecutorServiceAndThreadPools only takes Runnable task as input.","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"ExecutorServiceAndThreadPools","slug":"ExecutorServiceAndThreadPools","date":"2018-06-15T20:56:51.000Z","updated":"2018-06-16T08:34:40.000Z","comments":true,"path":"2018/06/15/ExecutorServiceAndThreadPools/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/15/ExecutorServiceAndThreadPools/","excerpt":"","text":"This Article is part of Series of Articles on Java 8 Concurrency Tutorial. In this quick article, we’ll focus on a the concept of ExecutorService Framework in the Java language. ExecutorService is a framework simplifies the task of creating threads and managing thread life cycle. ExecutorService is an interface, We need its implementations in order to make any use of it. ThreadPoolExecutor &amp; ScheduledThreadPoolExecutor implementations are available in java concurrent package. Creating an ExecutorService:Executors factory methods are available for creating ExecutorService. ExecutorService executorService1 = Executors.newSingleThreadExecutor();ExecutorService executorService2 = Executors.newFixedThreadPool(10);ExecutorService executorService3 = Executors.newCachedThreadPool(); newCachedThreadPoolnewCachedThreadPool method creates an executor having an expandable thread pool.Whenever a thread is needed, pool returns a thread from cache and if not available, a new thread is created for a short time. When the timeout of thread is over, that thread is vanished. In below example 10 Threds will run Simultaneously newCachedThreadPool Example123456789101112131415161718192021222324 class MyWorker implements Runnable&#123; private int id; public MyWorker(int id) &#123; this.id=id; &#125; @Override public void run() &#123; System.out.println(\"MyWorker id \" + id + \" IS Working\" + \"Start Time \" + System.currentTimeMillis()); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;public class ExecutorServiceExample &#123; public static void main(String[] args) &#123; ExecutorService newCachedThreadPool = Executors.newCachedThreadPool(); IntStream.range(0, 10) .forEach(cnt-&gt;newCachedThreadPool.execute(new MyWorker(cnt))); newCachedThreadPool.shutdown(); &#125;&#125; newFixedThreadPoolnewFixedThreadPool method Creates a thread pool that reuses a fixed number of threads operating off a shared unbounded queue.. In below example 5 Threds will run Simultaneously. After Complition of task same 5 threds will be used for next 5 taks newFixedThreadPool Example123456789101112131415161718192021222324 class MyWorker implements Runnable&#123; private int id; public MyWorker(int id) &#123; this.id=id; &#125; @Override public void run() &#123; System.out.println(\"MyWorker id \" + id + \" IS Working\" + \"Start Time \" + System.currentTimeMillis()); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;public class ExecutorServiceExample &#123; public static void main(String[] args) &#123; ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(5); IntStream.range(0, 10) .forEach(cnt-&gt;newFixedThreadPool.execute(new MyWorker(cnt))); newFixedThreadPool.shutdown(); &#125;&#125; newSingleThreadExecutornewSingleThreadExecutor method Creates an Executor that uses a single worker thread operating off an unbounded queue. In below example 1 Thread will run Simultaneously. After Complition of task same threds will be used for next 10 taks newSingleThreadExecutor Example123456789101112131415161718192021222324 class MyWorker implements Runnable&#123; private int id; public MyWorker(int id) &#123; this.id=id; &#125; @Override public void run() &#123; System.out.println(\"MyWorker id \" + id + \" IS Working\" + \"Start Time \" + System.currentTimeMillis()); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;public class ExecutorServiceExample &#123; public static void main(String[] args) &#123; ExecutorService newSingleThreadExecutor = Executors.newSingleThreadExecutor(); IntStream.range(0, 10) .forEach(cnt-&gt;newSingleThreadExecutor.execute(new MyWorker(cnt))); newSingleThreadExecutor.shutdown(); &#125;&#125; Key Pointsshutdown()An ExecutorService can be shut down, which will cause it to reject new tasks. Two different methods are provided for shutting down an ExecutorService.The shutdown() method will allow previously submitted tasks to execute before terminating, while the shutdownNow() method prevents waiting tasks from starting and attempts to stop currently executing tasks. execute()Executes the given command at some time in the future. The command may execute in a new thread, in a pooled thread, or in the calling thread, at the discretion of the Executor implementation.execute method only takes runnable task.","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"Semaphores","slug":"Semaphores","date":"2018-06-15T16:17:27.000Z","updated":"2018-06-16T03:45:28.000Z","comments":true,"path":"2018/06/15/Semaphores/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/15/Semaphores/","excerpt":"","text":"Semaphores are a really simple concept, invented by the famous Dutch computer scientist Edsger Dijkstra. Basically a semaphore is a counter (integer) that allows a thread to get into a critical region.What the counter is counting are permits that allow access to the shared resource. Thus, to access the resource, a thread must be granted a permit from the semaphore. If the value of the counter is greater than 0 then thread get the permit otherwise waits for the permit.Once thread leaves the critical region increments the counter so that other thread can access the critical section. Most of the time we use semaphores to limit the number of concurrent threads accessing a specific resource. Examplelet consider, We want to limit connections to some resources to some max limit.Similar to connection pool.In below example 10 threads are trying to get connection at same time.But we should not allow more than 5 connections Semaphore Example12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.nirajsonawane;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Semaphore;import java.util.stream.IntStream;class ConnectionPool &#123; private Semaphore connectionSemaphore; public ConnectionPool(int poolsize) &#123; this.connectionSemaphore = new Semaphore(poolsize); &#125; public void getConnectionFromPool() &#123; if (connectionSemaphore.availablePermits() &gt; 0) &#123; connectionSemaphore.tryAcquire(); System.out.println(\"Get the connection\"); &#125; else &#123; System.out.println(\"Max active connection limit reach!! try again\"); &#125; &#125; public void releaseConnection() &#123; connectionSemaphore.release(); &#125;&#125;class ConnectionService implements Runnable &#123; private ConnectionPool connectionPool; public ConnectionService(ConnectionPool connectionPool) &#123; this.connectionPool = connectionPool; &#125; @Override public void run() &#123; connectionPool.getConnectionFromPool(); &#125;&#125;public class Semaphores &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); ConnectionPool connectionPool = new ConnectionPool(5); ConnectionService service = new ConnectionService(connectionPool); IntStream.range(0, 10) .forEach((cnt) -&gt; executorService.execute(service)); &#125;&#125;&#125; Out of 10 threds only 5 was able to get the connection. Key Points tryAcquire()– Return true if a permit is available immediately and acquire it otherwise return false, acquire()- Acquires a permit and blocking until one is available. release() – Release a permit availablePermits() – Return number of current permits available","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"Wait-Notify-And-Notifyall","slug":"Wait-Notify-And-Notifyall","date":"2018-06-15T12:37:17.000Z","updated":"2018-06-16T01:06:58.000Z","comments":true,"path":"2018/06/15/Wait-Notify-And-Notifyall/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/15/Wait-Notify-And-Notifyall/","excerpt":"","text":"This is Sixth Article in Series of Articles on Java 8 Concurrency Tutorial. In this article, we will look at one of the most basic methods of Java-thread synchronization. Object Class in Java has three final methods to allow threads to communicate about the lock status of the threads. These methods are wait(), notify() and notifyAll().wait()Causes the current thread to wait until another thread invokes the notify() method or the notifyAll() method for this object. notify()Wakes up a single thread that is waiting on this object’s monitor. notifyAll()Wakes up all threads that are waiting on this object’s monitor. Let’s try to implement Producer &amp; Consumer problem using wait(),notify()&amp; notifyAll();Producer will add number in List. List can have maximum 5 numbers . Consumer will remove elements from list until it becomes empty. Volatile Keyword Example1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768 package com.nirajsonawane;import java.util.ArrayList;import java.util.List;import java.util.Random;class Processor &#123; private List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); private Random random = new Random(); public synchronized void producer() &#123; while (true) &#123; try &#123; Thread.sleep(1000); if (list.size() == 5) &#123; System.out.println(\"List is full Notifying Consumer &amp; Releasing Lock\"); notifyAll(); wait(); &#125; while (list.size() &lt; 5) &#123; System.out.println(\"Adding items\"); list.add(random.nextInt()); &#125; &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125; public synchronized void consumner() &#123; while (true) &#123; try &#123; Thread.sleep(1000); if (list.isEmpty()) &#123; System.out.println(\"List is Empty :Notifying Publisher &amp; Releasing Lock\"); notifyAll(); wait(); &#125; else &#123; System.out.println(\"Size of list \" + list.size() + \" Removed Number is \" + list.remove(0)); &#125; &#125; catch (Exception e) &#123; // TODO: handle exception &#125; &#125; &#125;&#125;public class WaitNotifyNotifyAllExample &#123; public static void main(String[] args) throws InterruptedException &#123; Processor p = new Processor(); Thread t1 = new Thread(() -&gt; p.producer()); Thread t2 = new Thread(() -&gt; p.consumner()); t1.start(); t2.start(); t1.join(); t2.join(); &#125;&#125;","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"Volatile","slug":"Volatile","date":"2018-06-15T12:10:37.000Z","updated":"2018-06-15T22:24:46.000Z","comments":true,"path":"2018/06/15/Volatile/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/15/Volatile/","excerpt":"","text":"This is Fifth Article in Series of Articles on Java 8 Concurrency Tutorial. In this quick article, we’ll focus on a the concept of volatile keyword in the Java language. Every read of a volatile variable will be read from the RAM so from the main memory and not from cache. Usually variables are cached for performance reasons. Using volatile variables reduces the risk of memory consistency errors, because any write to a volatile variable establishes a happens-before relationship with subsequent reads of that same variable. This means that changes to a volatile variable are always visible to other thread. Volatile Keyword Example1private static volatile int COUNT = 0;","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"Intrinsic Locks","slug":"Intrinsic-Locks","date":"2018-06-13T05:38:33.000Z","updated":"2018-06-13T15:52:18.000Z","comments":true,"path":"2018/06/13/Intrinsic-Locks/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/13/Intrinsic-Locks/","excerpt":"","text":"This is Fourth Article in Series of Articles on Java 8 Concurrency Tutorial. Intrinsic LocksSynchronization is built around an internal entity known as the intrinsic lock or monitor lock. Intrinsic locks play a role in both aspects of synchronization: enforcing exclusive access to an object’s state and establishing happens-before relationships that are essential to visibility. Every object has an intrinsic lock associated with it. By convention, a thread that needs exclusive and consistent access to an object’s fields has to acquire the object’s intrinsic lock before accessing them, and then release the intrinsic lock when it’s done with them. As long as a thread owns an intrinsic lock, no other thread can acquire the same lock. The other thread will block when it attempts to acquire the lock. Locks In Synchronized MethodsWe have discussed Synchronized Methods in previous Article Synchronization.When a thread invokes a synchronized method, it automatically acquires the intrinsic lock for that method’s object and releases it when the method returns. The lock release occurs even if the return was caused by an uncaught exception. Locks In Synchronized Static MethodsAs a static method is associated with a class, not an object. In this case, the thread acquires the intrinsic lock for the Class object associated with the class. Thus access to class’s static fields is controlled by a lock that’s disti","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"Synchronization","slug":"Synchronization","date":"2018-06-13T04:40:27.000Z","updated":"2018-06-13T15:33:02.000Z","comments":true,"path":"2018/06/13/Synchronization/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/13/Synchronization/","excerpt":"","text":"This is Third Article in Series of Articles on Java 8 Concurrency Tutorial. SynchronizationThreads communicate primarily by sharing access to fields and the objects reference fields refer to. This form of communication is extremely efficient, but makes two kinds of errors possible: thread interference and memory consistency errors. The tool needed to prevent these errors is synchronization. There are many situations in which multiple threads must share access to common objects.And There may be a situation when multiple threads try to access the same resource, Then they can produce inconsistent result due to concurrency issues. e.g In below example two Threads are trying to increment counter by 1000, So after end of execution. Vlaue of counter should be 2000, but that not the case. Inconsistent result due to concurrency - Without Synchronization123456789101112131415161718192021222324252627282930313233343536373839public class SynchronizedMethodExample &#123; private static int counter= 0; private static void increment() &#123; counter = counter+1; &#125; public static void main(String[] args) throws InterruptedException &#123; System.out.println(\"Main start!!\"); Thread t1 = new Thread(new Runnable() &#123; public void run() &#123; for (int i = 0; i &lt; 1000; i++) &#123; increment(); &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; public void run() &#123; for (int i = 0; i &lt; 1000; i++) &#123; increment(); &#125; &#125; &#125;); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(\"Counter \" + counter); System.out.println(\"Main End\"); &#125;&#125; If you check output , The value of Conter is not exactly equal to 2000. Synchronization idiomsThe Java programming language provides two basic synchronization idioms: synchronized methods and synchronized statements. Synchronized MethodsTo make a method synchronized, simply add the synchronized keyword to its declaration.Synchronized method is used to lock an object for any shared resource. When a thread invokes a synchronized method, it automatically acquires the lock for that object and releases it when the thread completes its task. If in above exapmle we make increment method as Synchronized, then has two effects: First, it is not possible for two invocations of synchronized methods on the same object to interleave. When one thread is executing a synchronized method for an object, all other threads that invoke synchronized methods for the same object block (suspend execution) until the first thread is done with the object. Second, when a synchronized method exits, it automatically establishes a happens-before relationship with any subsequent invocation of a synchronized method for the same object. This guarantees that changes to the state of the object are visible to all threads. Synchronized Method Example1234567891011121314151617181920212223242526272829303132333435363738public class SynchronizedMethodExample &#123; private static int counter= 0; private static synchronized void increment() &#123; counter = counter+1; &#125; public static void main(String[] args) throws InterruptedException &#123; System.out.println(\"Main start!!\"); Thread t1 = new Thread(new Runnable() &#123; public void run() &#123; for (int i = 0; i &lt; 1000; i++) &#123; increment(); &#125; &#125; &#125;); Thread t2 = new Thread(new Runnable() &#123; public void run() &#123; for (int i = 0; i &lt; 1000; i++) &#123; increment(); &#125; &#125; &#125;); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(\"Counter \" + counter); System.out.println(\"Main End\"); &#125;&#125; Synchronized BlocksEach time We do not have to synchronize a whole method. Sometimes it is preferable to synchronize only part of a method. Java synchronized blocks inside methods makes this possible.The increment method Can implemented by using Synchronized BlocksSynchronized Block Example1234567 private void increment()&#123; synchronized(this)&#123; counter = counter+1; &#125;&#125; It is better to use Synchronized Blocks using private object, rather than putting it on a method. Putting it on the method means you are using the lock of the object itself to provide thread safety. With this kind of mechanism, it is possible for a malicious user of your code to also obtain the lock on your object, and hold it forever, effectively blocking other threads. A non-malicious user can effectively do the same thing inadvertently. If you use the lock of a private data member, you can prevent this, since it is impossible for a malicious user to obtain the lock on your private object. Synchronized Block Example123456789 private final Object lockObject = new Object(); private void increment()&#123; synchronized(lockObject)&#123; counter = counter+1; &#125;&#125;","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"Join Method","slug":"Join-Method","date":"2018-06-10T15:10:23.000Z","updated":"2018-06-11T01:41:52.000Z","comments":true,"path":"2018/06/10/Join-Method/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/10/Join-Method/","excerpt":"","text":"This is Second Article in Series of Articles on Java 8 Concurrency Tutorial. The join method allows one thread to wait for the completion of another. If t is a Thread object whose thread is currently executing, t.join();causes the current thread to pause execution until t’s thread terminates. Overloads of join allow the programmer to specify a waiting period. However, as with sleep, join is dependent on the OS for timing, so you should not assume that join will wait exactly as long as you specify. join responds to an interrupt by exiting with an InterruptedException Join Method Example1234567891011121314public class JoinMethodExample &#123; public static void main(String[] args) &#123; System.out.println(\"Main Method Start\"); Thread t1 = new Thread(()-&gt;System.out.println(\"Thread Number 1\")); Thread t2 = new Thread(()-&gt;System.out.println(\"Thread Number 2\")); t1.start(); t2.start(); System.out.println(\"Main Method End\"); &#125;&#125; If you check output , The main Thread ends before T2 Thread. If you want to wait for Completion of T2 then we need to call join method. Join Method Example12345678910111213141516public class JoinMethodExample &#123; public static void main(String[] args) &#123; System.out.println(\"Main Method Start\"); Thread t1 = new Thread(()-&gt;System.out.println(\"Thread Number 1\")); Thread t2 = new Thread(()-&gt;System.out.println(\"Thread Number 2\")); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(\"Main Method End\"); &#125;&#125;","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"Creating Threads in Java","slug":"Creating-Threads","date":"2018-06-10T13:47:39.000Z","updated":"2018-06-11T01:39:22.000Z","comments":true,"path":"2018/06/10/Creating-Threads/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/10/Creating-Threads/","excerpt":"","text":"This is First Article in Series of Articles on Java 8 Concurrency Tutorial. Threads can be Created using below ways.Extending Thread classThe First way is to extend the Thread class, and override the run()The extending class must override run() method which is the entry point of new thread. Extending Thread class1234567891011121314151617181920212223242526class ThreadRunner extends Thread&#123; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(\"ThreadRunner : \" + i); &#125; &#125; &#125;public class CreatingThreadsExample &#123; public static void main(String[] args) &#123; System.out.println(\"Main Method Start\"); Thread t1= new ThreadRunner(); t1.start(); System.out.println(\"Main Method End\"); &#125;&#125; Implementing the Runnable InterfaceWe Can pass an implementation of the Runnable interface to the constructor of Thread, then call start() Implementing the Runnable Interface12345678910111213141516171819202122232425class ThreadRunner implements Runnable&#123; public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(\"ThreadRunner1 : \" + i); &#125; &#125; &#125;public class CreatingThreadsExample &#123; public static void main(String[] args) &#123; System.out.println(\"Main Method Start\"); Thread t1= new Thread(new ThreadRunner()); t1.start(); System.out.println(\"Main Method End\"); &#125;&#125; Threads Using Anonymous ClassesAnonymous Inner class is an inner class that is declared without any class name and that’s why it’s called anonymous. You can define an anonymous inner class within a method or even within an argument to a method. Anonymous class can be used to -Extend an class and override its method.Implement an interface and provide an implementation of its method. Threads Using Anonymous Classes1234567891011121314151617public class CreatingThreadsExample &#123; public static void main(String[] args) &#123; System.out.println(\"Main Method Start\"); new Thread(new Runnable() &#123; public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(\"ThreadRunner : \" + i); &#125; &#125; &#125;).start(); &#125;&#125; Threads Using Java 8 LambdaRunnable is a functional interface and we can use lambda expressions to provide it’s implementation rather than using anonymous class. Threads Using Anonymous Classes12345678910public class CreatingThreadsExample &#123; public static void main(String[] args) &#123; Runnable task = () -&gt; &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(\"ThreadRunner2 : \" + i); &#125; &#125;; new Thread(task).start(); &#125;&#125; Next Join Method. in Series of Articles on Java 8 Concurrency Tutorial.","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"Java 8 Concurrency Tutorial","slug":"Concurrency-1-0","date":"2018-06-10T13:26:34.000Z","updated":"2018-06-21T19:56:36.000Z","comments":true,"path":"2018/06/10/Concurrency-1-0/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/10/Concurrency-1-0/","excerpt":"","text":"Welcome to Java Concurrency tutorials. These articles will describe you the Java Concurrency concepts in the context of Java 8 with easily understood code examples. The majority of concepts shown in these articles are also available in older versions of Java.However, my code samples focus on Java 8 and make heavy use of lambda expressions and other new features. Topics Creating Threads in Java Join Method Synchronization Intrinsic Locks Volatile Wait-Notify-And-Notifyall ExecutorServiceAndThreadPools Callable and Future Semaphores CountDownLatch CyclicBarrier BlockingQueue Exchanger Check The First Article in Series of Java Concurrency tutorials Creating Threads in Java.","categories":[{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/categories/Multithreading/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"},{"name":"Concurrency","slug":"Concurrency","permalink":"https://nirajsonawane.github.io/tags/Concurrency/"},{"name":"Multithreading","slug":"Multithreading","permalink":"https://nirajsonawane.github.io/tags/Multithreading/"}]},{"title":"Watching a Directory for Changes","slug":"Watching-a-Directory-for-Changes","date":"2018-06-01T04:42:32.000Z","updated":"2018-06-10T08:35:34.000Z","comments":true,"path":"2018/06/01/Watching-a-Directory-for-Changes/","link":"","permalink":"https://nirajsonawane.github.io/2018/06/01/Watching-a-Directory-for-Changes/","excerpt":"","text":"The java.nio.file package provides a file change notification API, called the Watch Service API. This API enables you to register a directory (or directories) with the watch service. When registering, you tell the service which types of events you are interested in:1:File creation.2:File deletion.3:File Modification. When the service detects an event of interest, it is forwarded to the registered process. The registered process has a thread (or a pool of threads) dedicated to watching for any events it has registered for. When an event comes in, it is handled as needed. Creating watcher serviceThe first step is to create a new WatchService by using the newWatchService method in the FileSystem class, as follows: WatchService watcher = FileSystems.getDefault().newWatchService() Registering for EventsWe Can register one or more objects with the watch service.Any object that implements the Watchable interface can be registered.The Path class implements the Watchable interface, so each directory to be monitored is registered as a Path object. When registering an object with the watch service, you specify the types of events that you want to monitor. The supported StandardWatchEventKinds event types follow: ENTRY_CREATE – A directory entry is created. ENTRY_DELETE – A directory entry is deleted. ENTRY_MODIFY – A directory entry is modified. Registering for Events123WatchService watcher = FileSystems.getDefault().newWatchService()Path dir = Paths.get(\"C:\\\\data\\\\temp\\\\mydir\\\\\");dir.register(watcher, ENTRY_CREATE, ENTRY_DELETE, ENTRY_MODIFY); Directory Watching ExamplePutting all above together. We can now go ahead and look at a complete and practical example. In below example we are going to watch directory for all the changes and will process the events. Directory Watching Example1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import static java.nio.file.StandardWatchEventKinds.ENTRY_CREATE;import static java.nio.file.StandardWatchEventKinds.ENTRY_DELETE;import static java.nio.file.StandardWatchEventKinds.ENTRY_MODIFY;import java.io.IOException;import java.nio.file.FileSystems;import java.nio.file.Path;import java.nio.file.Paths;import java.nio.file.WatchEvent;import java.nio.file.WatchKey;import java.nio.file.WatchService; public class DirectoryChangeListeners &#123; public static void main(String[] args) throws InterruptedException &#123; try &#123; WatchService watcher = FileSystems.getDefault().newWatchService(); Path dir = Paths.get(\"C:\\\\data\\\\temp\\\\\"); dir.register(watcher, ENTRY_CREATE, ENTRY_DELETE, ENTRY_MODIFY); System.out.println(\"Watch Service registered for dir: \" + dir.getFileName()); WatchKey key; while ((key = watcher.take())!=null) &#123; for (WatchEvent&lt;?&gt; event : key.pollEvents()) &#123; WatchEvent.Kind&lt;?&gt; kind = event.kind(); @SuppressWarnings(\"unchecked\") WatchEvent&lt;Path&gt; ev = (WatchEvent&lt;Path&gt;) event; Path fileName = ev.context(); if(kind==ENTRY_CREATE) &#123; System.out.println(\"New File Added, file Name \" + fileName); &#125; if(kind==ENTRY_DELETE) &#123; System.out.println(\"File Deleted \" + fileName); &#125; if (kind == ENTRY_MODIFY ) &#123; System.out.println(\"File Modified \" + fileName); &#125; &#125; boolean valid = key.reset(); if (!valid) &#123; break; &#125; &#125; &#125; catch (IOException ex) &#123; System.err.println(ex); &#125; &#125;&#125; Key PointsThree methods are available for Retrieving events : poll – Returns a queued key, if available. Returns immediately with a null value, if unavailable. poll(long, TimeUnit) – Returns a queued key, if one is available. If a queued key is not immediately available, the program waits until the specified time. The TimeUnit argument determines whether the specified time is nanoseconds, milliseconds, or some other unit of time. take – Returns a queued key. If no queued key is available, this method waits. Reset keyAfter the events for the key have been processed, you need to put the key back into a ready state by invoking reset. If this method returns false, the key is no longer valid and the loop can exit. This step is very important. If you fail to invoke reset, this key will not receive any further events. When to Use and Not Use This APIThe Watch Service API is designed for applications that need to be notified about file change events. It is well suited for any application, like an editor or IDE, that potentially has many open files and needs to ensure that the files are synchronized with the file system. It is also well suited for an application server that watches a directory, perhaps waiting for .jsp or .jar files to drop, in order to deploy them. This API is not designed for indexing a hard drive. Most file system implementations have native support for file change notification. The Watch Service API takes advantage of this support where available. However, when a file system does not support this mechanism, the Watch Service will poll the file system, waiting for events.","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"File","slug":"Java-8/File","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"}]},{"title":"Java 8 File Operations - Copy,Delete,Move","slug":"java-8-File-Operations-Copy-Delete-Move","date":"2018-05-30T04:52:00.000Z","updated":"2018-06-10T08:37:08.000Z","comments":true,"path":"2018/05/30/java-8-File-Operations-Copy-Delete-Move/","link":"","permalink":"https://nirajsonawane.github.io/2018/05/30/java-8-File-Operations-Copy-Delete-Move/","excerpt":"","text":"Deleting a File or DirectoryThe Files class provides two deletion methods. 1 : The delete(Path) method deletes the file or throws an exception if the deletion fails 2 : The deleteIfExists(Path) method also deletes the file, but if the file does not exist, no exception is thrown. Delete File12345678910111213public static void main(String[] args) &#123; Path path = Paths.get(\"C:\\\\data\\\\temp\\\\temp.txt\"); try &#123; Files.delete(path); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; Delete Empty Directory12345678910111213public static void main(String[] args) &#123; Path path = Paths.get(\"C:\\\\data\\\\temp\\\\\"); try &#123; Files.delete(path); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; Trying to delete Non Empty Directory will throw DirectoryNotEmptyException.So, First we need to delete all files inside a particular non-empty directory: Delete Non Empty Directory1234567891011public static void main(String[] args) &#123; Path path = Paths.get(\"C:\\\\data\\\\temp\\\\\"); Files.walk(path) .sorted(Comparator.reverseOrder()) .map(Path::toFile) .forEach(File::delete); &#125; Copying a File or DirectoryYou can copy a file or directory by using thecopy(Path, Path, CopyOption...) method. The copy fails if the target file exists, unless the REPLACE_EXISTING option is specified. This method takes a varargs argument. The following StandardCopyOption and LinkOption enums are supported: REPLACE_EXISTING – replace a file if it existsCOPY_ATTRIBUTES – copy metadata to the new fileNOFOLLOW_LINKS – shouldn’t follow symbolic links Copy File12345678public static void main(String[] args) &#123; Path sourcepath = Paths.get(\"C:\\\\data\\\\temp\\\\temp.txt\"); Path destinationepath = Paths.get(\"C:\\\\data\\\\temp\\\\destination.txt\"); Files.copy(sourcepath, destinationepath, StandardCopyOption.REPLACE_EXISTING); &#125; Copy Empty Directory12345678public static void main(String[] args) &#123; Path sourcepath = Paths.get(\"C:\\\\data\\\\temp\\\\mydir\"); Path destinationepath = Paths.get(\"C:\\\\data\\\\temp\\\\destinationDir\"); Files.copy(sourcepath, destinationepath, StandardCopyOption.REPLACE_EXISTING); &#125; Copy Non empty DirectoryDirectories can be copied. However, files inside the directory are not copied, so the new directory is empty even when the original directory contains files. Copy Non Empty Directory recursively12345678910111213141516public static void main(String[] args) &#123; Path sourcepath = Paths.get(\"C:\\\\data\\\\temp\\\\mydir\"); Path destinationepath = Paths.get(\"C:\\\\data\\\\temp\\\\destinationDir\"); Files.walk(sourcepath) .forEach(source -&gt; copy(source, destinationepath.resolve(sourcepath.relativize(source)))); &#125; static void copy(Path source, Path dest) &#123; try &#123; Files.copy(source, dest, StandardCopyOption.REPLACE_EXISTING); &#125; catch (Exception e) &#123; throw new RuntimeException(e.getMessage(), e); &#125; &#125; Moving a File or DirectoryYou can move a file or directory by using the move(Path, Path, CopyOption...) method.The move fails if the target file exists, unless the REPLACE_EXISTING option is specified. Empty directories can be moved. If the directory is not empty, the move is allowed when the directory can be moved without moving the contents of that directory. On UNIX systems, moving a directory within the same partition generally consists of renaming the directory. In that situation, this method works even when the directory contains files. This method takes a varargs argument – the following StandardCopyOption enums are supported: REPLACE_EXISTING – Performs the move even when the target file already exists. If the target is a symbolic link, the symbolic link is replaced but what it points to is not affected.ATOMIC_MOVE – Performs the move as an atomic file operation. If the file system does not support an atomic move, an exception is thrown. With an ATOMIC_MOVE you can move a file into a directory and be guaranteed that any process watching the directory accesses a complete file. Move File12345678public static void main(String[] args) &#123; Path sourcepath = Path sourcepath = Paths.get(\"C:\\\\data\\\\temp\\\\temp.txt\"); Path destinationepath = Paths.get(\"C:\\\\data\\\\temp\\\\mydir\\\\temp.txtr\");Files.move(sourcepath, destinationepath, StandardCopyOption.REPLACE_EXISTING); &#125; Move Empty Directory12345678public static void main(String[] args) &#123; Path sourcepath = Paths.get(\"C:\\\\data\\\\temp\\\\copyme\"); Path destinationepath = Paths.get(\"C:\\\\data\\\\temp\\\\mydir\\\\copyme\"); Files.move(sourcepath, destinationepath, StandardCopyOption.REPLACE_EXISTING); &#125; Move Non Empty Directory1234567public static void main(String[] args) &#123; Path sourcepath = Paths.get(\"C:\\\\data\\\\temp\\\\copyme\"); Path destinationepath = Paths.get(\"C:\\\\data\\\\temp\\\\mydir\\\\copyme\"); Files.move(sourcepath, destinationepath, StandardCopyOption.REPLACE_EXISTING); &#125;","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"File","slug":"Java-8/File","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"}]},{"title":"Java 8 List all Files in Directory and Subdirectories","slug":"Java-8-List-all-Files-in-Directory-and-Subdirectories","date":"2018-05-29T05:40:02.000Z","updated":"2018-06-10T08:37:30.000Z","comments":true,"path":"2018/05/29/Java-8-List-all-Files-in-Directory-and-Subdirectories/","link":"","permalink":"https://nirajsonawane.github.io/2018/05/29/Java-8-List-all-Files-in-Directory-and-Subdirectories/","excerpt":"","text":"List All Files in Directory and SubdirectoriesFiles.walk Return a Stream that is lazily populated with Path by walking the file tree rooted at a given starting file. Files.list Method Return a lazily populated Stream for the current directory only,Files.walk can be used to get list of files from Directory &amp; Subdirectories . Example 1: List All Files in Directory and SubdirectoriesList All Files in Directory and Subdirectories123456789101112131415public static void main(String[] args) throws IOException &#123; Path start = Paths.get(\"C:\\\\data\\\\\"); try (Stream&lt;Path&gt; stream = Files.walk(start, Integer.MAX_VALUE)) &#123; List&lt;String&gt; collect = stream .map(String::valueOf) .sorted() .collect(Collectors.toList()); collect.forEach(System.out::println); &#125; &#125; NoteFiles.walk method takes int maxDepth as parameter. The maxDepth parameter is the maximum number of levels of directories to visit.MAX_VALUE may be used to indicate that all levels should be visited. Value 1 can be used to list files in current Directory. Example 2: List All Files in Current Directory onlyList All Files in Current Directory only12345678910111213141516public static void main(String[] args) throws IOException &#123; Path start = Paths.get(\"C:\\\\data\\\\\"); try (Stream&lt;Path&gt; stream = Files.walk(start, 1)) &#123; List&lt;String&gt; collect = stream .map(String::valueOf) .sorted() .collect(Collectors.toList()); collect.forEach(System.out::println); &#125; &#125;","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"File","slug":"Java-8/File","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"}]},{"title":"Java 8 Read File With try-with-resources","slug":"Java-8-Read-File-With-try-with-resources","date":"2018-05-24T05:28:00.000Z","updated":"2018-05-24T06:46:30.000Z","comments":true,"path":"2018/05/24/Java-8-Read-File-With-try-with-resources/","link":"","permalink":"https://nirajsonawane.github.io/2018/05/24/Java-8-Read-File-With-try-with-resources/","excerpt":"","text":"You might have noticed that In the previous post about files we have not closed any file stream. Streams implement AutoCloseable and in this case, we need to close stream explicitly. We can use try-with-resources to close the stream. Sample CodeClose BufferedReader123456789101112public static void main(String[] args) throws IOException &#123; String filePath = \"C:\\\\data\\\\demo\\\\sample.txt\"; try(BufferedReader reader = Files.newBufferedReader(Paths.get(filePath))) &#123; reader.lines().forEach(System.out::println); &#125; catch (Exception e) &#123; // TODO: handle exception &#125;&#125; Close Stream1234567891011public static void main(String[] args) throws IOException &#123; String filePath = \"C:\\\\data\\\\demo\\\\sample.txt\"; try(Stream&lt;String&gt; lines = Files.lines(Paths.get((filePath)))) &#123; lines.forEach(System.out::println); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; &#125;","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"File","slug":"Java-8/File","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/"},{"name":"5.0 -Read File With try-with-resources","slug":"Java-8/File/5-0-Read-File-With-try-with-resources","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/5-0-Read-File-With-try-with-resources/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"}]},{"title":"Java 8 List All Files in Directory","slug":"java-8-List-All-Files-in-Directory","date":"2018-05-23T21:02:00.000Z","updated":"2018-05-24T08:18:22.000Z","comments":true,"path":"2018/05/23/java-8-List-All-Files-in-Directory/","link":"","permalink":"https://nirajsonawane.github.io/2018/05/23/java-8-List-All-Files-in-Directory/","excerpt":"","text":"List All Files in DirectoryFiles.list Method Return a lazily populated Stream, the elements of which are the entries in the directory. We Can use the stream operations to find Specific Files, List file matching certain criteria, List filenames in sorted order etc. Example 1: List All Files in DirectoryList All Files in Directory12345678public static void main(String[] args) throws IOException &#123; try(Stream&lt;Path&gt; list = Files.list(Paths.get(\"C:\\\\Program Files\\\\\"));) &#123; list.forEach(System.out::println); &#125; &#125; Example 2: List All Files in Directory Starting with AList All Files in Directory Starting with A1234567891011121314public static void main(String[] args) throws IOException &#123; try (Stream&lt;Path&gt; list = Files.list(Paths.get(\"C:\\\\Program Files\\\\\"))) &#123; List&lt;String&gt; fileList = list.map(path -&gt; path.getFileName() .toString()) .filter(name -&gt; name.startsWith(\"A\")) .sorted() .collect(Collectors.toList()); fileList.forEach(System.out::println); &#125; &#125; Example 3: List Files OnlyList Files Only123456789101112public static void main(String[] args) throws IOException &#123; try (Stream&lt;Path&gt; list = Files.list(Paths.get(\"C:\\\\Program Files\\\\\"))) &#123; List&lt;String&gt; fileList = list.filter(path-&gt;path.toFile().isFile()) .map(path -&gt; path.getFileName().toString()) .collect(Collectors.toList()); fileList.forEach(System.out::println); &#125; &#125; Example 4: List Directory OnlyList Directory Only123456789101112public static void main(String[] args) throws IOException &#123; try (Stream&lt;Path&gt; list = Files.list(Paths.get(\"C:\\\\Program Files\\\\\"))) &#123; List&lt;String&gt; fileList = list.filter(path-&gt;path.toFile().isDirectory()) .map(path -&gt; path.getFileName().toString()) .collect(Collectors.toList()); fileList.forEach(System.out::println); &#125; &#125; Example 5: List Hidden files OnlyList Hidden files Only123456789101112public static void main(String[] args) throws IOException &#123; try (Stream&lt;Path&gt; list = Files.list(Paths.get(\"C:\\\\Program Files\\\\\"))) &#123; List&lt;String&gt; fileList = list.filter(path-&gt;path.toFile().isHidden()) .map(path -&gt; path.getFileName().toString()) .collect(Collectors.toList()); fileList.forEach(System.out::println); &#125; &#125; NoteFiles.list Method Return a lazily populated Stream for the directory.It does not return Stream for the nested directory. For that, we Can use File.walk . Will discuss that in next chapter.","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"File","slug":"Java-8/File","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/"},{"name":"6.0 - List All Files in Directory","slug":"Java-8/File/6-0-List-All-Files-in-Directory","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/6-0-List-All-Files-in-Directory/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"}]},{"title":"Java 8 Read File Using Buffered Reader","slug":"Java-8-Read-File-Using-Buffered-Reader","date":"2018-05-23T05:28:08.000Z","updated":"2018-05-24T06:52:36.000Z","comments":true,"path":"2018/05/23/Java-8-Read-File-Using-Buffered-Reader/","link":"","permalink":"https://nirajsonawane.github.io/2018/05/23/Java-8-Read-File-Using-Buffered-Reader/","excerpt":"","text":"Finally, Java 8 has made Reading &amp; Writing a text file a simple task. If we need more fine-grained control on reading we can use new Files.newBufferedReader() Read File Using Buffered Reader12345678910111213141516import java.io.IOException;import java.nio.file.Files;import java.nio.file.Paths;import java.util.stream.Stream; public class Java8ReadUsingBufferedReader &#123; public static void main(String[] args) throws IOException &#123; String filePath = \"C:\\\\data\\\\demo\\\\sample.txt\"; BufferedReader reader = Files.newBufferedReader(Paths.get(filePath)); reader.lines().forEach(System.out::println); &#125; &#125; Sample.txt file1234567public final class Files extends ObjectThis class consists exclusively of static methods that operate on files, directories, or other types of files.In most cases, the methods defined here will delegate to the associated file system provider to perform the file operations.Since:1.7","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"File","slug":"Java-8/File","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/"},{"name":"4.0 -Read File Using Buffered Reader","slug":"Java-8/File/4-0-Read-File-Using-Buffered-Reader","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/4-0-Read-File-Using-Buffered-Reader/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"}]},{"title":"Java 8 Read File As Single String","slug":"Java-8-Read-File-As-Single-String","date":"2018-05-22T05:28:08.000Z","updated":"2018-05-24T06:02:32.000Z","comments":true,"path":"2018/05/22/Java-8-Read-File-As-Single-String/","link":"","permalink":"https://nirajsonawane.github.io/2018/05/22/Java-8-Read-File-As-Single-String/","excerpt":"","text":"Java 8 has added Files.lines() method, which can be used to read the file as Stream. Joining Collector Can be used to convert Stream to Single String. Read file as a stream12345678910111213141516import java.io.IOException;import java.nio.file.Files;import java.nio.file.Paths;import java.util.stream.Stream; public class Java8ReadFileAsString &#123; public static void main(String[] args) throws IOException &#123; String filePath = \"C:\\\\data\\\\demo\\\\sample.txt\"; Stream&lt;String&gt; lines = Files.lines(Paths.get((filePath))); String fileAsString = lines.collect(Collectors.joining()); System.out.println(fileAsString); &#125; &#125; Sample.txt file for testing.1234567public final class Files extends ObjectThis class consists exclusively of static methods that operate on files, directories, or other types of files.In most cases, the methods defined here will delegate to the associated file system provider to perform the file operations.Since:1.7","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"File","slug":"Java-8/File","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/"},{"name":"3.0 -Read File As Single String","slug":"Java-8/File/3-0-Read-File-As-Single-String","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/3-0-Read-File-As-Single-String/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"}]},{"title":"Java 8 Read File As A Stream","slug":"Java-8-Read-File-As-A-Stream","date":"2018-05-21T05:28:08.000Z","updated":"2018-05-24T06:03:30.000Z","comments":true,"path":"2018/05/21/Java-8-Read-File-As-A-Stream/","link":"","permalink":"https://nirajsonawane.github.io/2018/05/21/Java-8-Read-File-As-A-Stream/","excerpt":"","text":"Java 8 has added Files.lines() method, which can be used to read the file as Stream. Read file as a stream1234567891011121314151617import java.io.IOException;import java.nio.file.Files;import java.nio.file.Paths;import java.util.stream.Stream; public class Java8ReadFileAsStream &#123; public static void main(String[] args) throws IOException &#123; String filePath = \"C:\\\\data\\\\demo\\\\sample.txt\"; Stream&lt;String&gt; lines = Files.lines(Paths.get((filePath))); lines.forEach(System.out::println); &#125; &#125; sample.txt for testing.1234567public final class Files extends ObjectThis class consists exclusively of static methods that operate on files, directories, or other types of files.In most cases, the methods defined here will delegate to the associated file system provider to perform the file operations.Since:1.7 Output:","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"File","slug":"Java-8/File","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/"},{"name":"2.0 -Read File As A Stream","slug":"Java-8/File/2-0-Read-File-As-A-Stream","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/2-0-Read-File-As-A-Stream/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"}]},{"title":"Java 8 Read File Line By Line","slug":"Java-8-Read-File-Line-By-Line","date":"2018-05-20T05:28:08.000Z","updated":"2018-05-24T05:41:16.000Z","comments":true,"path":"2018/05/20/Java-8-Read-File-Line-By-Line/","link":"","permalink":"https://nirajsonawane.github.io/2018/05/20/Java-8-Read-File-Line-By-Line/","excerpt":"","text":"Java 8 has addded Files.readAllLines() method ,which can be used to read file as List of Strings. Read file as a List of Strings1234567891011public class Java8ReadFileAsListOfStrings &#123; public static void main(String[] args) throws IOException &#123; String filePath = \"C:\\\\data\\\\demo\\\\sample.txt\"; List&lt;String&gt; readAllLines = Files.readAllLines(Paths.get((filePath))); readAllLines.forEach(System.out::println); &#125; &#125; Text file sample.txt for testing. 1234567public final class Files extends ObjectThis class consists exclusively of static methods that operate on files, directories, or other types of files.In most cases, the methods defined here will delegate to the associated file system provider to perform the file operations.Since:1.7 Output:","categories":[{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/categories/Java-8/"},{"name":"File","slug":"Java-8/File","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/"},{"name":"1.0 -Read File Line by Line","slug":"Java-8/File/1-0-Read-File-Line-by-Line","permalink":"https://nirajsonawane.github.io/categories/Java-8/File/1-0-Read-File-Line-by-Line/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-8","slug":"Java-8","permalink":"https://nirajsonawane.github.io/tags/Java-8/"}]},{"title":"Java Process Builder","slug":"Java-Process-Builder","date":"2018-05-19T22:05:48.000Z","updated":"2021-02-07T17:22:53.907Z","comments":true,"path":"2018/05/20/Java-Process-Builder/","link":"","permalink":"https://nirajsonawane.github.io/2018/05/20/Java-Process-Builder/","excerpt":"","text":"The ProcessBuilder class is used to create separate operating system processes. There are many scenarios, Where we need to launch separate operating system processes form java program. Before JDK 5.0, We need to use the exec() method of the java.lang.Runtime class to start new process.JDK 5.0 has added ProcessBuilder to Start new OS process. Note:ProcessBuilder is not synchronized. If multiple threads access a ProcessBuilder instance concurrently, and at least one of the threads modifies one of the attributes structurally, it must be synchronized externally. Starting a new process which uses the default working directory and the environment is easy: 123Process p = new ProcessBuilder(\"myCommand\", \"myArg\").start(); The ProcessBuilder class defines two constructors, such as:12345ProcessBuilder(List&lt;String&gt; command);//Constructs a process builder with the specified operating system program and arguments.ProcessBuilder(String... command);//Constructs a process builder with the specified operating system program and arguments ProcessBuilder Examples.1:Run External bat file/sh file.In this example, we will try to run demo.bat file. The demo.bat file is at src/ root location.The out put of process builder will be printed on consol. 1234567891011121314151617181920212223242526272829303132333435public class ProcessBuilderExample &#123; public static void main(String[] args) &#123; try &#123; System.out.println(\"ProcessBuilderExample.Start!!\"); final File batchFile = new File(\"src\\\\demo.bat\"); ProcessBuilder processBuilder = new ProcessBuilder(batchFile.getAbsolutePath()); Process process = processBuilder.start(); int resposneCode = process.waitFor(); if (resposneCode == 0) &#123; System.out.println(\"Process executed successfully\"); InputStream inputStream = process.getInputStream(); String result = readInputStreamData(inputStream); System.out.println(result); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static String readInputStreamData(InputStream input) throws IOException &#123; try (BufferedReader buffer = new BufferedReader(new InputStreamReader(input))) &#123; return buffer.lines() .collect(Collectors.joining(\"\\n\")); &#125; &#125;&#125; demo.bat File1echo &quot;Hello World&quot;","categories":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/categories/Java/"},{"name":"Java Process Builder","slug":"Java/Java-Process-Builder","permalink":"https://nirajsonawane.github.io/categories/Java/Java-Process-Builder/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://nirajsonawane.github.io/tags/Java/"},{"name":"Java-9","slug":"Java-9","permalink":"https://nirajsonawane.github.io/tags/Java-9/"}]}]}